{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.33258970068786,
  "eval_steps": 200,
  "global_step": 43000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005809630042758877,
      "grad_norm": 1.1574279069900513,
      "learning_rate": 6e-06,
      "loss": 2.4036,
      "step": 25
    },
    {
      "epoch": 0.0011619260085517754,
      "grad_norm": 2.7331340312957764,
      "learning_rate": 1.225e-05,
      "loss": 2.3727,
      "step": 50
    },
    {
      "epoch": 0.001742889012827663,
      "grad_norm": 1.0052663087844849,
      "learning_rate": 1.85e-05,
      "loss": 2.5275,
      "step": 75
    },
    {
      "epoch": 0.0023238520171035507,
      "grad_norm": 2.332030773162842,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 2.4499,
      "step": 100
    },
    {
      "epoch": 0.0029048150213794384,
      "grad_norm": 1.7691184282302856,
      "learning_rate": 3.1e-05,
      "loss": 1.9869,
      "step": 125
    },
    {
      "epoch": 0.003485778025655326,
      "grad_norm": 1.0624743700027466,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 1.5886,
      "step": 150
    },
    {
      "epoch": 0.004066741029931214,
      "grad_norm": 2.480600595474243,
      "learning_rate": 4.35e-05,
      "loss": 1.7184,
      "step": 175
    },
    {
      "epoch": 0.0046477040342071015,
      "grad_norm": 1.241445541381836,
      "learning_rate": 4.975e-05,
      "loss": 1.9188,
      "step": 200
    },
    {
      "epoch": 0.0046477040342071015,
      "eval_loss": 1.625802993774414,
      "eval_runtime": 29.7592,
      "eval_samples_per_second": 134.412,
      "eval_steps_per_second": 33.603,
      "step": 200
    },
    {
      "epoch": 0.00522866703848299,
      "grad_norm": 1.1765204668045044,
      "learning_rate": 4.99719835636907e-05,
      "loss": 1.8682,
      "step": 225
    },
    {
      "epoch": 0.005809630042758877,
      "grad_norm": 2.517817974090576,
      "learning_rate": 4.994279977586851e-05,
      "loss": 1.9228,
      "step": 250
    },
    {
      "epoch": 0.006390593047034765,
      "grad_norm": 2.5653114318847656,
      "learning_rate": 4.9913615988046325e-05,
      "loss": 1.983,
      "step": 275
    },
    {
      "epoch": 0.006971556051310652,
      "grad_norm": 1.4664952754974365,
      "learning_rate": 4.9884432200224135e-05,
      "loss": 1.6753,
      "step": 300
    },
    {
      "epoch": 0.00755251905558654,
      "grad_norm": 2.3260107040405273,
      "learning_rate": 4.9855248412401946e-05,
      "loss": 1.6872,
      "step": 325
    },
    {
      "epoch": 0.008133482059862428,
      "grad_norm": 1.419249415397644,
      "learning_rate": 4.9826064624579756e-05,
      "loss": 1.8362,
      "step": 350
    },
    {
      "epoch": 0.008714445064138316,
      "grad_norm": 1.3928102254867554,
      "learning_rate": 4.9796880836757566e-05,
      "loss": 1.4484,
      "step": 375
    },
    {
      "epoch": 0.009295408068414203,
      "grad_norm": 1.387879490852356,
      "learning_rate": 4.976769704893538e-05,
      "loss": 1.0845,
      "step": 400
    },
    {
      "epoch": 0.009295408068414203,
      "eval_loss": 1.313382625579834,
      "eval_runtime": 23.086,
      "eval_samples_per_second": 173.265,
      "eval_steps_per_second": 43.316,
      "step": 400
    },
    {
      "epoch": 0.009876371072690092,
      "grad_norm": 1.843277931213379,
      "learning_rate": 4.973851326111319e-05,
      "loss": 1.1481,
      "step": 425
    },
    {
      "epoch": 0.01045733407696598,
      "grad_norm": 2.2242016792297363,
      "learning_rate": 4.9709329473291e-05,
      "loss": 0.9883,
      "step": 450
    },
    {
      "epoch": 0.011038297081241866,
      "grad_norm": 1.3218977451324463,
      "learning_rate": 4.968014568546881e-05,
      "loss": 2.2257,
      "step": 475
    },
    {
      "epoch": 0.011619260085517754,
      "grad_norm": 1.5081666707992554,
      "learning_rate": 4.965096189764662e-05,
      "loss": 2.1077,
      "step": 500
    },
    {
      "epoch": 0.012200223089793643,
      "grad_norm": 1.4934189319610596,
      "learning_rate": 4.9621778109824435e-05,
      "loss": 2.1773,
      "step": 525
    },
    {
      "epoch": 0.01278118609406953,
      "grad_norm": 1.7659885883331299,
      "learning_rate": 4.9592594322002245e-05,
      "loss": 1.9566,
      "step": 550
    },
    {
      "epoch": 0.013362149098345417,
      "grad_norm": 1.119239091873169,
      "learning_rate": 4.9563410534180055e-05,
      "loss": 1.5212,
      "step": 575
    },
    {
      "epoch": 0.013943112102621304,
      "grad_norm": 1.4935626983642578,
      "learning_rate": 4.9534226746357866e-05,
      "loss": 1.4317,
      "step": 600
    },
    {
      "epoch": 0.013943112102621304,
      "eval_loss": 1.2353984117507935,
      "eval_runtime": 23.2228,
      "eval_samples_per_second": 172.245,
      "eval_steps_per_second": 43.061,
      "step": 600
    },
    {
      "epoch": 0.014524075106897193,
      "grad_norm": 1.1877799034118652,
      "learning_rate": 4.9505042958535676e-05,
      "loss": 1.6983,
      "step": 625
    },
    {
      "epoch": 0.01510503811117308,
      "grad_norm": 1.8614327907562256,
      "learning_rate": 4.947585917071349e-05,
      "loss": 1.4366,
      "step": 650
    },
    {
      "epoch": 0.015686001115448968,
      "grad_norm": 1.9756118059158325,
      "learning_rate": 4.94466753828913e-05,
      "loss": 1.5545,
      "step": 675
    },
    {
      "epoch": 0.016266964119724857,
      "grad_norm": 1.7174655199050903,
      "learning_rate": 4.941749159506911e-05,
      "loss": 1.5463,
      "step": 700
    },
    {
      "epoch": 0.016847927124000742,
      "grad_norm": 1.4418439865112305,
      "learning_rate": 4.938830780724692e-05,
      "loss": 1.0701,
      "step": 725
    },
    {
      "epoch": 0.01742889012827663,
      "grad_norm": 1.701746940612793,
      "learning_rate": 4.935912401942473e-05,
      "loss": 0.8134,
      "step": 750
    },
    {
      "epoch": 0.01800985313255252,
      "grad_norm": 1.3555389642715454,
      "learning_rate": 4.9329940231602545e-05,
      "loss": 1.02,
      "step": 775
    },
    {
      "epoch": 0.018590816136828406,
      "grad_norm": 1.2080013751983643,
      "learning_rate": 4.9300756443780355e-05,
      "loss": 0.9305,
      "step": 800
    },
    {
      "epoch": 0.018590816136828406,
      "eval_loss": 1.1996500492095947,
      "eval_runtime": 21.1619,
      "eval_samples_per_second": 189.019,
      "eval_steps_per_second": 47.255,
      "step": 800
    },
    {
      "epoch": 0.019171779141104295,
      "grad_norm": 1.3180181980133057,
      "learning_rate": 4.9271572655958165e-05,
      "loss": 1.0469,
      "step": 825
    },
    {
      "epoch": 0.019752742145380184,
      "grad_norm": 1.39739191532135,
      "learning_rate": 4.9242388868135975e-05,
      "loss": 1.0857,
      "step": 850
    },
    {
      "epoch": 0.02033370514965607,
      "grad_norm": 2.2635607719421387,
      "learning_rate": 4.9213205080313786e-05,
      "loss": 1.096,
      "step": 875
    },
    {
      "epoch": 0.02091466815393196,
      "grad_norm": 1.5344843864440918,
      "learning_rate": 4.91840212924916e-05,
      "loss": 1.2619,
      "step": 900
    },
    {
      "epoch": 0.021495631158207844,
      "grad_norm": 3.584841251373291,
      "learning_rate": 4.915483750466941e-05,
      "loss": 1.1476,
      "step": 925
    },
    {
      "epoch": 0.022076594162483733,
      "grad_norm": 1.2936928272247314,
      "learning_rate": 4.9125653716847217e-05,
      "loss": 2.1634,
      "step": 950
    },
    {
      "epoch": 0.022657557166759622,
      "grad_norm": 1.6170541048049927,
      "learning_rate": 4.909646992902503e-05,
      "loss": 1.3737,
      "step": 975
    },
    {
      "epoch": 0.023238520171035507,
      "grad_norm": 1.1514708995819092,
      "learning_rate": 4.906728614120284e-05,
      "loss": 1.19,
      "step": 1000
    },
    {
      "epoch": 0.023238520171035507,
      "eval_loss": 1.189098596572876,
      "eval_runtime": 21.501,
      "eval_samples_per_second": 186.038,
      "eval_steps_per_second": 46.509,
      "step": 1000
    },
    {
      "epoch": 0.023819483175311396,
      "grad_norm": 1.3726128339767456,
      "learning_rate": 4.9038102353380654e-05,
      "loss": 1.0825,
      "step": 1025
    },
    {
      "epoch": 0.024400446179587285,
      "grad_norm": 1.870491862297058,
      "learning_rate": 4.9008918565558465e-05,
      "loss": 1.345,
      "step": 1050
    },
    {
      "epoch": 0.02498140918386317,
      "grad_norm": 1.5425297021865845,
      "learning_rate": 4.8979734777736275e-05,
      "loss": 1.1683,
      "step": 1075
    },
    {
      "epoch": 0.02556237218813906,
      "grad_norm": 2.223724126815796,
      "learning_rate": 4.8950550989914085e-05,
      "loss": 1.2315,
      "step": 1100
    },
    {
      "epoch": 0.02614333519241495,
      "grad_norm": 2.561875104904175,
      "learning_rate": 4.8921367202091895e-05,
      "loss": 1.2899,
      "step": 1125
    },
    {
      "epoch": 0.026724298196690834,
      "grad_norm": 1.8169324398040771,
      "learning_rate": 4.889218341426971e-05,
      "loss": 1.2929,
      "step": 1150
    },
    {
      "epoch": 0.027305261200966723,
      "grad_norm": 1.3997777700424194,
      "learning_rate": 4.886299962644752e-05,
      "loss": 0.8742,
      "step": 1175
    },
    {
      "epoch": 0.02788622420524261,
      "grad_norm": 1.7901997566223145,
      "learning_rate": 4.883381583862533e-05,
      "loss": 0.5956,
      "step": 1200
    },
    {
      "epoch": 0.02788622420524261,
      "eval_loss": 1.2259327173233032,
      "eval_runtime": 21.3659,
      "eval_samples_per_second": 187.214,
      "eval_steps_per_second": 46.804,
      "step": 1200
    },
    {
      "epoch": 0.028467187209518498,
      "grad_norm": 1.0227675437927246,
      "learning_rate": 4.8804632050803137e-05,
      "loss": 0.4714,
      "step": 1225
    },
    {
      "epoch": 0.029048150213794387,
      "grad_norm": 2.0762698650360107,
      "learning_rate": 4.877544826298095e-05,
      "loss": 1.4092,
      "step": 1250
    },
    {
      "epoch": 0.029629113218070272,
      "grad_norm": 2.254347562789917,
      "learning_rate": 4.874626447515876e-05,
      "loss": 1.5232,
      "step": 1275
    },
    {
      "epoch": 0.03021007622234616,
      "grad_norm": 2.328569173812866,
      "learning_rate": 4.8717080687336574e-05,
      "loss": 1.4952,
      "step": 1300
    },
    {
      "epoch": 0.03079103922662205,
      "grad_norm": 1.9481532573699951,
      "learning_rate": 4.8687896899514385e-05,
      "loss": 1.5411,
      "step": 1325
    },
    {
      "epoch": 0.031372002230897936,
      "grad_norm": 2.4081180095672607,
      "learning_rate": 4.8658713111692195e-05,
      "loss": 1.4112,
      "step": 1350
    },
    {
      "epoch": 0.031952965235173825,
      "grad_norm": 1.3975896835327148,
      "learning_rate": 4.8629529323870005e-05,
      "loss": 1.0599,
      "step": 1375
    },
    {
      "epoch": 0.032533928239449714,
      "grad_norm": 1.2812409400939941,
      "learning_rate": 4.8600345536047815e-05,
      "loss": 1.0062,
      "step": 1400
    },
    {
      "epoch": 0.032533928239449714,
      "eval_loss": 1.151672124862671,
      "eval_runtime": 21.1316,
      "eval_samples_per_second": 189.29,
      "eval_steps_per_second": 47.323,
      "step": 1400
    },
    {
      "epoch": 0.0331148912437256,
      "grad_norm": 1.5144401788711548,
      "learning_rate": 4.857116174822563e-05,
      "loss": 1.3464,
      "step": 1425
    },
    {
      "epoch": 0.033695854248001485,
      "grad_norm": 1.1603689193725586,
      "learning_rate": 4.854197796040344e-05,
      "loss": 1.2747,
      "step": 1450
    },
    {
      "epoch": 0.034276817252277374,
      "grad_norm": 1.4532597064971924,
      "learning_rate": 4.8512794172581246e-05,
      "loss": 1.1873,
      "step": 1475
    },
    {
      "epoch": 0.03485778025655326,
      "grad_norm": 1.344788670539856,
      "learning_rate": 4.8483610384759057e-05,
      "loss": 1.089,
      "step": 1500
    },
    {
      "epoch": 0.03543874326082915,
      "grad_norm": 1.1305749416351318,
      "learning_rate": 4.845442659693687e-05,
      "loss": 1.0857,
      "step": 1525
    },
    {
      "epoch": 0.03601970626510504,
      "grad_norm": 1.347874402999878,
      "learning_rate": 4.8425242809114684e-05,
      "loss": 1.2954,
      "step": 1550
    },
    {
      "epoch": 0.03660066926938092,
      "grad_norm": 1.6135414838790894,
      "learning_rate": 4.8396059021292494e-05,
      "loss": 1.0827,
      "step": 1575
    },
    {
      "epoch": 0.03718163227365681,
      "grad_norm": 1.1226927042007446,
      "learning_rate": 4.8366875233470304e-05,
      "loss": 1.0059,
      "step": 1600
    },
    {
      "epoch": 0.03718163227365681,
      "eval_loss": 1.1409331560134888,
      "eval_runtime": 21.8925,
      "eval_samples_per_second": 182.711,
      "eval_steps_per_second": 45.678,
      "step": 1600
    },
    {
      "epoch": 0.0377625952779327,
      "grad_norm": 1.179620623588562,
      "learning_rate": 4.8337691445648115e-05,
      "loss": 0.8327,
      "step": 1625
    },
    {
      "epoch": 0.03834355828220859,
      "grad_norm": 1.539459228515625,
      "learning_rate": 4.8308507657825925e-05,
      "loss": 1.081,
      "step": 1650
    },
    {
      "epoch": 0.03892452128648448,
      "grad_norm": 1.7998228073120117,
      "learning_rate": 4.827932387000374e-05,
      "loss": 1.6492,
      "step": 1675
    },
    {
      "epoch": 0.03950548429076037,
      "grad_norm": 1.6299173831939697,
      "learning_rate": 4.825014008218155e-05,
      "loss": 1.2998,
      "step": 1700
    },
    {
      "epoch": 0.04008644729503625,
      "grad_norm": 2.319143056869507,
      "learning_rate": 4.822095629435936e-05,
      "loss": 0.9577,
      "step": 1725
    },
    {
      "epoch": 0.04066741029931214,
      "grad_norm": 1.4808423519134521,
      "learning_rate": 4.8191772506537166e-05,
      "loss": 0.9796,
      "step": 1750
    },
    {
      "epoch": 0.04124837330358803,
      "grad_norm": 1.1701589822769165,
      "learning_rate": 4.8162588718714977e-05,
      "loss": 1.3994,
      "step": 1775
    },
    {
      "epoch": 0.04182933630786392,
      "grad_norm": 1.1016221046447754,
      "learning_rate": 4.8133404930892794e-05,
      "loss": 1.2285,
      "step": 1800
    },
    {
      "epoch": 0.04182933630786392,
      "eval_loss": 1.1357449293136597,
      "eval_runtime": 20.6688,
      "eval_samples_per_second": 193.528,
      "eval_steps_per_second": 48.382,
      "step": 1800
    },
    {
      "epoch": 0.042410299312139806,
      "grad_norm": 1.9840794801712036,
      "learning_rate": 4.8104221143070604e-05,
      "loss": 1.6747,
      "step": 1825
    },
    {
      "epoch": 0.04299126231641569,
      "grad_norm": 1.7402782440185547,
      "learning_rate": 4.8075037355248414e-05,
      "loss": 1.5419,
      "step": 1850
    },
    {
      "epoch": 0.04357222532069158,
      "grad_norm": 1.7879407405853271,
      "learning_rate": 4.8045853567426224e-05,
      "loss": 1.3863,
      "step": 1875
    },
    {
      "epoch": 0.044153188324967466,
      "grad_norm": 1.881221055984497,
      "learning_rate": 4.8016669779604035e-05,
      "loss": 1.2218,
      "step": 1900
    },
    {
      "epoch": 0.044734151329243355,
      "grad_norm": 1.307775855064392,
      "learning_rate": 4.798748599178185e-05,
      "loss": 1.433,
      "step": 1925
    },
    {
      "epoch": 0.045315114333519244,
      "grad_norm": 1.3760582208633423,
      "learning_rate": 4.795830220395966e-05,
      "loss": 1.2748,
      "step": 1950
    },
    {
      "epoch": 0.04589607733779513,
      "grad_norm": 1.1905790567398071,
      "learning_rate": 4.792911841613747e-05,
      "loss": 1.3797,
      "step": 1975
    },
    {
      "epoch": 0.046477040342071015,
      "grad_norm": 1.8422640562057495,
      "learning_rate": 4.789993462831528e-05,
      "loss": 1.3537,
      "step": 2000
    },
    {
      "epoch": 0.046477040342071015,
      "eval_loss": 1.118580937385559,
      "eval_runtime": 20.7806,
      "eval_samples_per_second": 192.487,
      "eval_steps_per_second": 48.122,
      "step": 2000
    },
    {
      "epoch": 0.047058003346346904,
      "grad_norm": 1.7413554191589355,
      "learning_rate": 4.7870750840493086e-05,
      "loss": 1.1513,
      "step": 2025
    },
    {
      "epoch": 0.04763896635062279,
      "grad_norm": 2.91964054107666,
      "learning_rate": 4.78415670526709e-05,
      "loss": 1.3852,
      "step": 2050
    },
    {
      "epoch": 0.04821992935489868,
      "grad_norm": 1.9971911907196045,
      "learning_rate": 4.7812383264848714e-05,
      "loss": 1.272,
      "step": 2075
    },
    {
      "epoch": 0.04880089235917457,
      "grad_norm": 1.3901506662368774,
      "learning_rate": 4.7783199477026524e-05,
      "loss": 1.8714,
      "step": 2100
    },
    {
      "epoch": 0.04938185536345045,
      "grad_norm": 1.4936423301696777,
      "learning_rate": 4.7754015689204334e-05,
      "loss": 1.3231,
      "step": 2125
    },
    {
      "epoch": 0.04996281836772634,
      "grad_norm": 1.8938801288604736,
      "learning_rate": 4.7724831901382144e-05,
      "loss": 1.5602,
      "step": 2150
    },
    {
      "epoch": 0.05054378137200223,
      "grad_norm": 1.6383793354034424,
      "learning_rate": 4.769564811355996e-05,
      "loss": 1.5,
      "step": 2175
    },
    {
      "epoch": 0.05112474437627812,
      "grad_norm": 1.5463298559188843,
      "learning_rate": 4.766646432573777e-05,
      "loss": 1.4383,
      "step": 2200
    },
    {
      "epoch": 0.05112474437627812,
      "eval_loss": 1.0888488292694092,
      "eval_runtime": 21.8884,
      "eval_samples_per_second": 182.745,
      "eval_steps_per_second": 45.686,
      "step": 2200
    },
    {
      "epoch": 0.05170570738055401,
      "grad_norm": 2.1277599334716797,
      "learning_rate": 4.763728053791558e-05,
      "loss": 1.4322,
      "step": 2225
    },
    {
      "epoch": 0.0522866703848299,
      "grad_norm": 1.1489728689193726,
      "learning_rate": 4.760809675009339e-05,
      "loss": 1.5923,
      "step": 2250
    },
    {
      "epoch": 0.05286763338910578,
      "grad_norm": 1.6299686431884766,
      "learning_rate": 4.75789129622712e-05,
      "loss": 1.1864,
      "step": 2275
    },
    {
      "epoch": 0.05344859639338167,
      "grad_norm": 1.664975643157959,
      "learning_rate": 4.754972917444901e-05,
      "loss": 1.5693,
      "step": 2300
    },
    {
      "epoch": 0.05402955939765756,
      "grad_norm": 1.9215940237045288,
      "learning_rate": 4.752054538662682e-05,
      "loss": 1.9476,
      "step": 2325
    },
    {
      "epoch": 0.054610522401933446,
      "grad_norm": 1.270696759223938,
      "learning_rate": 4.7491361598804634e-05,
      "loss": 1.7122,
      "step": 2350
    },
    {
      "epoch": 0.055191485406209335,
      "grad_norm": 1.7242587804794312,
      "learning_rate": 4.7462177810982444e-05,
      "loss": 1.5062,
      "step": 2375
    },
    {
      "epoch": 0.05577244841048522,
      "grad_norm": 1.771925687789917,
      "learning_rate": 4.7432994023160254e-05,
      "loss": 1.3975,
      "step": 2400
    },
    {
      "epoch": 0.05577244841048522,
      "eval_loss": 1.0860276222229004,
      "eval_runtime": 21.3895,
      "eval_samples_per_second": 187.008,
      "eval_steps_per_second": 46.752,
      "step": 2400
    },
    {
      "epoch": 0.056353411414761106,
      "grad_norm": 1.3615336418151855,
      "learning_rate": 4.740381023533807e-05,
      "loss": 1.3454,
      "step": 2425
    },
    {
      "epoch": 0.056934374419036995,
      "grad_norm": 1.3221983909606934,
      "learning_rate": 4.737462644751588e-05,
      "loss": 1.0712,
      "step": 2450
    },
    {
      "epoch": 0.057515337423312884,
      "grad_norm": 1.9498568773269653,
      "learning_rate": 4.734544265969369e-05,
      "loss": 1.3899,
      "step": 2475
    },
    {
      "epoch": 0.05809630042758877,
      "grad_norm": 1.7844136953353882,
      "learning_rate": 4.73162588718715e-05,
      "loss": 1.3695,
      "step": 2500
    },
    {
      "epoch": 0.058677263431864655,
      "grad_norm": 1.7080130577087402,
      "learning_rate": 4.728707508404931e-05,
      "loss": 1.4428,
      "step": 2525
    },
    {
      "epoch": 0.059258226436140544,
      "grad_norm": 1.7229169607162476,
      "learning_rate": 4.725789129622712e-05,
      "loss": 1.8065,
      "step": 2550
    },
    {
      "epoch": 0.05983918944041643,
      "grad_norm": 1.4934630393981934,
      "learning_rate": 4.722870750840493e-05,
      "loss": 1.6102,
      "step": 2575
    },
    {
      "epoch": 0.06042015244469232,
      "grad_norm": 1.4745358228683472,
      "learning_rate": 4.719952372058274e-05,
      "loss": 1.1445,
      "step": 2600
    },
    {
      "epoch": 0.06042015244469232,
      "eval_loss": 1.086714267730713,
      "eval_runtime": 21.6882,
      "eval_samples_per_second": 184.432,
      "eval_steps_per_second": 46.108,
      "step": 2600
    },
    {
      "epoch": 0.06100111544896821,
      "grad_norm": 1.6775412559509277,
      "learning_rate": 4.7170339932760554e-05,
      "loss": 1.1432,
      "step": 2625
    },
    {
      "epoch": 0.0615820784532441,
      "grad_norm": 1.190610408782959,
      "learning_rate": 4.7141156144938364e-05,
      "loss": 1.4183,
      "step": 2650
    },
    {
      "epoch": 0.06216304145751998,
      "grad_norm": 1.5786958932876587,
      "learning_rate": 4.711197235711618e-05,
      "loss": 1.3706,
      "step": 2675
    },
    {
      "epoch": 0.06274400446179587,
      "grad_norm": 1.6067029237747192,
      "learning_rate": 4.708278856929399e-05,
      "loss": 1.434,
      "step": 2700
    },
    {
      "epoch": 0.06332496746607176,
      "grad_norm": 2.9095137119293213,
      "learning_rate": 4.70536047814718e-05,
      "loss": 1.1895,
      "step": 2725
    },
    {
      "epoch": 0.06390593047034765,
      "grad_norm": 1.1288095712661743,
      "learning_rate": 4.702442099364961e-05,
      "loss": 1.0491,
      "step": 2750
    },
    {
      "epoch": 0.06448689347462354,
      "grad_norm": 2.0377559661865234,
      "learning_rate": 4.699523720582742e-05,
      "loss": 1.4546,
      "step": 2775
    },
    {
      "epoch": 0.06506785647889943,
      "grad_norm": 1.6748833656311035,
      "learning_rate": 4.696605341800523e-05,
      "loss": 1.5092,
      "step": 2800
    },
    {
      "epoch": 0.06506785647889943,
      "eval_loss": 1.0697005987167358,
      "eval_runtime": 21.83,
      "eval_samples_per_second": 183.234,
      "eval_steps_per_second": 45.808,
      "step": 2800
    },
    {
      "epoch": 0.06564881948317532,
      "grad_norm": 1.366931438446045,
      "learning_rate": 4.693686963018304e-05,
      "loss": 1.2981,
      "step": 2825
    },
    {
      "epoch": 0.0662297824874512,
      "grad_norm": 2.060088872909546,
      "learning_rate": 4.690768584236085e-05,
      "loss": 1.3084,
      "step": 2850
    },
    {
      "epoch": 0.06681074549172708,
      "grad_norm": 1.9068289995193481,
      "learning_rate": 4.687850205453866e-05,
      "loss": 1.5771,
      "step": 2875
    },
    {
      "epoch": 0.06739170849600297,
      "grad_norm": 1.993111491203308,
      "learning_rate": 4.6849318266716473e-05,
      "loss": 1.3859,
      "step": 2900
    },
    {
      "epoch": 0.06797267150027886,
      "grad_norm": 2.3345727920532227,
      "learning_rate": 4.6820134478894284e-05,
      "loss": 1.6312,
      "step": 2925
    },
    {
      "epoch": 0.06855363450455475,
      "grad_norm": 1.7446587085723877,
      "learning_rate": 4.67909506910721e-05,
      "loss": 1.6073,
      "step": 2950
    },
    {
      "epoch": 0.06913459750883064,
      "grad_norm": 2.1844286918640137,
      "learning_rate": 4.676176690324991e-05,
      "loss": 1.6274,
      "step": 2975
    },
    {
      "epoch": 0.06971556051310653,
      "grad_norm": 2.2407732009887695,
      "learning_rate": 4.673258311542772e-05,
      "loss": 1.4878,
      "step": 3000
    },
    {
      "epoch": 0.06971556051310653,
      "eval_loss": 1.0749379396438599,
      "eval_runtime": 21.5125,
      "eval_samples_per_second": 185.939,
      "eval_steps_per_second": 46.485,
      "step": 3000
    },
    {
      "epoch": 0.07029652351738241,
      "grad_norm": 1.3749090433120728,
      "learning_rate": 4.670339932760553e-05,
      "loss": 1.3885,
      "step": 3025
    },
    {
      "epoch": 0.0708774865216583,
      "grad_norm": 1.8112199306488037,
      "learning_rate": 4.667421553978334e-05,
      "loss": 1.5226,
      "step": 3050
    },
    {
      "epoch": 0.07145844952593419,
      "grad_norm": 4.659392356872559,
      "learning_rate": 4.664503175196115e-05,
      "loss": 1.3639,
      "step": 3075
    },
    {
      "epoch": 0.07203941253021008,
      "grad_norm": 2.5436668395996094,
      "learning_rate": 4.661584796413896e-05,
      "loss": 1.2428,
      "step": 3100
    },
    {
      "epoch": 0.07262037553448597,
      "grad_norm": 2.1263535022735596,
      "learning_rate": 4.658666417631677e-05,
      "loss": 1.1476,
      "step": 3125
    },
    {
      "epoch": 0.07320133853876185,
      "grad_norm": 1.8256995677947998,
      "learning_rate": 4.655748038849458e-05,
      "loss": 1.2703,
      "step": 3150
    },
    {
      "epoch": 0.07378230154303773,
      "grad_norm": 1.234460711479187,
      "learning_rate": 4.6528296600672393e-05,
      "loss": 1.8022,
      "step": 3175
    },
    {
      "epoch": 0.07436326454731362,
      "grad_norm": 2.777848720550537,
      "learning_rate": 4.649911281285021e-05,
      "loss": 1.4021,
      "step": 3200
    },
    {
      "epoch": 0.07436326454731362,
      "eval_loss": 1.066347599029541,
      "eval_runtime": 22.8501,
      "eval_samples_per_second": 175.054,
      "eval_steps_per_second": 43.764,
      "step": 3200
    },
    {
      "epoch": 0.07494422755158951,
      "grad_norm": 1.3683143854141235,
      "learning_rate": 4.646992902502802e-05,
      "loss": 0.8512,
      "step": 3225
    },
    {
      "epoch": 0.0755251905558654,
      "grad_norm": 2.133596658706665,
      "learning_rate": 4.644074523720583e-05,
      "loss": 0.9034,
      "step": 3250
    },
    {
      "epoch": 0.07610615356014129,
      "grad_norm": 2.59794282913208,
      "learning_rate": 4.641156144938364e-05,
      "loss": 0.71,
      "step": 3275
    },
    {
      "epoch": 0.07668711656441718,
      "grad_norm": 0.9142504930496216,
      "learning_rate": 4.638237766156145e-05,
      "loss": 1.5409,
      "step": 3300
    },
    {
      "epoch": 0.07726807956869307,
      "grad_norm": 1.8561592102050781,
      "learning_rate": 4.635319387373926e-05,
      "loss": 0.7929,
      "step": 3325
    },
    {
      "epoch": 0.07784904257296896,
      "grad_norm": 1.7679829597473145,
      "learning_rate": 4.632401008591707e-05,
      "loss": 1.3017,
      "step": 3350
    },
    {
      "epoch": 0.07843000557724485,
      "grad_norm": 1.9436218738555908,
      "learning_rate": 4.629482629809488e-05,
      "loss": 1.494,
      "step": 3375
    },
    {
      "epoch": 0.07901096858152074,
      "grad_norm": 2.5071802139282227,
      "learning_rate": 4.626564251027269e-05,
      "loss": 1.3009,
      "step": 3400
    },
    {
      "epoch": 0.07901096858152074,
      "eval_loss": 1.0717191696166992,
      "eval_runtime": 21.5055,
      "eval_samples_per_second": 185.999,
      "eval_steps_per_second": 46.5,
      "step": 3400
    },
    {
      "epoch": 0.07959193158579661,
      "grad_norm": 2.8310511112213135,
      "learning_rate": 4.62364587224505e-05,
      "loss": 1.9822,
      "step": 3425
    },
    {
      "epoch": 0.0801728945900725,
      "grad_norm": 2.434807300567627,
      "learning_rate": 4.620727493462832e-05,
      "loss": 1.507,
      "step": 3450
    },
    {
      "epoch": 0.08075385759434839,
      "grad_norm": 1.6274675130844116,
      "learning_rate": 4.617809114680613e-05,
      "loss": 1.2082,
      "step": 3475
    },
    {
      "epoch": 0.08133482059862428,
      "grad_norm": 1.8778514862060547,
      "learning_rate": 4.614890735898394e-05,
      "loss": 1.2226,
      "step": 3500
    },
    {
      "epoch": 0.08191578360290017,
      "grad_norm": 1.76759934425354,
      "learning_rate": 4.611972357116175e-05,
      "loss": 1.0113,
      "step": 3525
    },
    {
      "epoch": 0.08249674660717606,
      "grad_norm": 1.748321533203125,
      "learning_rate": 4.609053978333956e-05,
      "loss": 1.0111,
      "step": 3550
    },
    {
      "epoch": 0.08307770961145194,
      "grad_norm": 3.2753994464874268,
      "learning_rate": 4.606135599551737e-05,
      "loss": 1.2936,
      "step": 3575
    },
    {
      "epoch": 0.08365867261572783,
      "grad_norm": 2.380000591278076,
      "learning_rate": 4.603217220769518e-05,
      "loss": 1.3907,
      "step": 3600
    },
    {
      "epoch": 0.08365867261572783,
      "eval_loss": 1.054880142211914,
      "eval_runtime": 21.3626,
      "eval_samples_per_second": 187.243,
      "eval_steps_per_second": 46.811,
      "step": 3600
    },
    {
      "epoch": 0.08423963562000372,
      "grad_norm": 1.3804851770401,
      "learning_rate": 4.600298841987299e-05,
      "loss": 1.9227,
      "step": 3625
    },
    {
      "epoch": 0.08482059862427961,
      "grad_norm": 1.2075951099395752,
      "learning_rate": 4.59738046320508e-05,
      "loss": 0.8049,
      "step": 3650
    },
    {
      "epoch": 0.0854015616285555,
      "grad_norm": 1.6367359161376953,
      "learning_rate": 4.594462084422861e-05,
      "loss": 0.6554,
      "step": 3675
    },
    {
      "epoch": 0.08598252463283138,
      "grad_norm": 1.7315590381622314,
      "learning_rate": 4.591543705640643e-05,
      "loss": 0.7773,
      "step": 3700
    },
    {
      "epoch": 0.08656348763710726,
      "grad_norm": 1.9806644916534424,
      "learning_rate": 4.588625326858424e-05,
      "loss": 0.9598,
      "step": 3725
    },
    {
      "epoch": 0.08714445064138315,
      "grad_norm": 1.4050508737564087,
      "learning_rate": 4.585706948076205e-05,
      "loss": 1.0002,
      "step": 3750
    },
    {
      "epoch": 0.08772541364565904,
      "grad_norm": 1.2861745357513428,
      "learning_rate": 4.582788569293986e-05,
      "loss": 0.8521,
      "step": 3775
    },
    {
      "epoch": 0.08830637664993493,
      "grad_norm": 1.4353630542755127,
      "learning_rate": 4.579870190511767e-05,
      "loss": 0.9404,
      "step": 3800
    },
    {
      "epoch": 0.08830637664993493,
      "eval_loss": 1.0497634410858154,
      "eval_runtime": 21.2128,
      "eval_samples_per_second": 188.565,
      "eval_steps_per_second": 47.141,
      "step": 3800
    },
    {
      "epoch": 0.08888733965421082,
      "grad_norm": 2.130676031112671,
      "learning_rate": 4.576951811729548e-05,
      "loss": 0.8295,
      "step": 3825
    },
    {
      "epoch": 0.08946830265848671,
      "grad_norm": 1.8087847232818604,
      "learning_rate": 4.574033432947329e-05,
      "loss": 1.1032,
      "step": 3850
    },
    {
      "epoch": 0.0900492656627626,
      "grad_norm": 1.3976479768753052,
      "learning_rate": 4.57111505416511e-05,
      "loss": 0.8496,
      "step": 3875
    },
    {
      "epoch": 0.09063022866703849,
      "grad_norm": 1.6051571369171143,
      "learning_rate": 4.568196675382891e-05,
      "loss": 1.2506,
      "step": 3900
    },
    {
      "epoch": 0.09121119167131438,
      "grad_norm": 1.7445791959762573,
      "learning_rate": 4.565278296600672e-05,
      "loss": 1.1341,
      "step": 3925
    },
    {
      "epoch": 0.09179215467559027,
      "grad_norm": 1.5731900930404663,
      "learning_rate": 4.562359917818454e-05,
      "loss": 1.125,
      "step": 3950
    },
    {
      "epoch": 0.09237311767986614,
      "grad_norm": 2.5134470462799072,
      "learning_rate": 4.559441539036235e-05,
      "loss": 0.8822,
      "step": 3975
    },
    {
      "epoch": 0.09295408068414203,
      "grad_norm": 1.7974086999893188,
      "learning_rate": 4.556523160254016e-05,
      "loss": 0.8175,
      "step": 4000
    },
    {
      "epoch": 0.09295408068414203,
      "eval_loss": 1.0532792806625366,
      "eval_runtime": 21.5772,
      "eval_samples_per_second": 185.381,
      "eval_steps_per_second": 46.345,
      "step": 4000
    },
    {
      "epoch": 0.09353504368841792,
      "grad_norm": 2.390918254852295,
      "learning_rate": 4.553604781471797e-05,
      "loss": 1.1446,
      "step": 4025
    },
    {
      "epoch": 0.09411600669269381,
      "grad_norm": 1.608151912689209,
      "learning_rate": 4.550686402689578e-05,
      "loss": 1.0969,
      "step": 4050
    },
    {
      "epoch": 0.0946969696969697,
      "grad_norm": 1.8090628385543823,
      "learning_rate": 4.54776802390736e-05,
      "loss": 0.5965,
      "step": 4075
    },
    {
      "epoch": 0.09527793270124559,
      "grad_norm": 1.3115190267562866,
      "learning_rate": 4.54484964512514e-05,
      "loss": 0.8231,
      "step": 4100
    },
    {
      "epoch": 0.09585889570552147,
      "grad_norm": 1.2104532718658447,
      "learning_rate": 4.541931266342921e-05,
      "loss": 0.8181,
      "step": 4125
    },
    {
      "epoch": 0.09643985870979736,
      "grad_norm": 1.4972726106643677,
      "learning_rate": 4.539012887560702e-05,
      "loss": 1.2704,
      "step": 4150
    },
    {
      "epoch": 0.09702082171407325,
      "grad_norm": 15.754253387451172,
      "learning_rate": 4.536094508778483e-05,
      "loss": 0.8598,
      "step": 4175
    },
    {
      "epoch": 0.09760178471834914,
      "grad_norm": 1.926774501800537,
      "learning_rate": 4.533176129996265e-05,
      "loss": 1.1272,
      "step": 4200
    },
    {
      "epoch": 0.09760178471834914,
      "eval_loss": 1.0555346012115479,
      "eval_runtime": 22.6828,
      "eval_samples_per_second": 176.345,
      "eval_steps_per_second": 44.086,
      "step": 4200
    },
    {
      "epoch": 0.09818274772262503,
      "grad_norm": 2.0110223293304443,
      "learning_rate": 4.530257751214046e-05,
      "loss": 0.9367,
      "step": 4225
    },
    {
      "epoch": 0.0987637107269009,
      "grad_norm": 2.797603130340576,
      "learning_rate": 4.527339372431827e-05,
      "loss": 1.4286,
      "step": 4250
    },
    {
      "epoch": 0.0993446737311768,
      "grad_norm": 2.676725387573242,
      "learning_rate": 4.524420993649608e-05,
      "loss": 1.1333,
      "step": 4275
    },
    {
      "epoch": 0.09992563673545268,
      "grad_norm": 1.9777507781982422,
      "learning_rate": 4.521502614867389e-05,
      "loss": 1.3033,
      "step": 4300
    },
    {
      "epoch": 0.10050659973972857,
      "grad_norm": 1.9989126920700073,
      "learning_rate": 4.518584236085171e-05,
      "loss": 0.9777,
      "step": 4325
    },
    {
      "epoch": 0.10108756274400446,
      "grad_norm": 1.6328494548797607,
      "learning_rate": 4.515665857302952e-05,
      "loss": 0.7331,
      "step": 4350
    },
    {
      "epoch": 0.10166852574828035,
      "grad_norm": 2.638040781021118,
      "learning_rate": 4.512747478520732e-05,
      "loss": 0.8298,
      "step": 4375
    },
    {
      "epoch": 0.10224948875255624,
      "grad_norm": 2.0056049823760986,
      "learning_rate": 4.509829099738513e-05,
      "loss": 0.716,
      "step": 4400
    },
    {
      "epoch": 0.10224948875255624,
      "eval_loss": 1.0465036630630493,
      "eval_runtime": 21.484,
      "eval_samples_per_second": 186.185,
      "eval_steps_per_second": 46.546,
      "step": 4400
    },
    {
      "epoch": 0.10283045175683213,
      "grad_norm": 1.6739808320999146,
      "learning_rate": 4.506910720956294e-05,
      "loss": 0.8348,
      "step": 4425
    },
    {
      "epoch": 0.10341141476110802,
      "grad_norm": 1.6625341176986694,
      "learning_rate": 4.503992342174075e-05,
      "loss": 0.7262,
      "step": 4450
    },
    {
      "epoch": 0.1039923777653839,
      "grad_norm": 1.8732540607452393,
      "learning_rate": 4.501073963391857e-05,
      "loss": 1.2891,
      "step": 4475
    },
    {
      "epoch": 0.1045733407696598,
      "grad_norm": 3.0275022983551025,
      "learning_rate": 4.498155584609638e-05,
      "loss": 1.2172,
      "step": 4500
    },
    {
      "epoch": 0.10515430377393567,
      "grad_norm": 2.2266058921813965,
      "learning_rate": 4.495237205827419e-05,
      "loss": 1.4627,
      "step": 4525
    },
    {
      "epoch": 0.10573526677821156,
      "grad_norm": 1.8293291330337524,
      "learning_rate": 4.4923188270452e-05,
      "loss": 1.1692,
      "step": 4550
    },
    {
      "epoch": 0.10631622978248745,
      "grad_norm": 2.2570505142211914,
      "learning_rate": 4.489400448262981e-05,
      "loss": 1.2025,
      "step": 4575
    },
    {
      "epoch": 0.10689719278676334,
      "grad_norm": 1.512515902519226,
      "learning_rate": 4.486482069480763e-05,
      "loss": 1.2243,
      "step": 4600
    },
    {
      "epoch": 0.10689719278676334,
      "eval_loss": 1.0434907674789429,
      "eval_runtime": 21.237,
      "eval_samples_per_second": 188.351,
      "eval_steps_per_second": 47.088,
      "step": 4600
    },
    {
      "epoch": 0.10747815579103923,
      "grad_norm": 1.3682613372802734,
      "learning_rate": 4.483563690698543e-05,
      "loss": 0.9496,
      "step": 4625
    },
    {
      "epoch": 0.10805911879531511,
      "grad_norm": 3.7014548778533936,
      "learning_rate": 4.480645311916324e-05,
      "loss": 0.8416,
      "step": 4650
    },
    {
      "epoch": 0.108640081799591,
      "grad_norm": 1.7545424699783325,
      "learning_rate": 4.477726933134105e-05,
      "loss": 0.8711,
      "step": 4675
    },
    {
      "epoch": 0.10922104480386689,
      "grad_norm": 1.7006226778030396,
      "learning_rate": 4.474808554351886e-05,
      "loss": 1.4837,
      "step": 4700
    },
    {
      "epoch": 0.10980200780814278,
      "grad_norm": 1.2032972574234009,
      "learning_rate": 4.471890175569668e-05,
      "loss": 1.1679,
      "step": 4725
    },
    {
      "epoch": 0.11038297081241867,
      "grad_norm": 1.463026762008667,
      "learning_rate": 4.468971796787449e-05,
      "loss": 0.9496,
      "step": 4750
    },
    {
      "epoch": 0.11096393381669455,
      "grad_norm": 1.8106584548950195,
      "learning_rate": 4.46605341800523e-05,
      "loss": 1.0407,
      "step": 4775
    },
    {
      "epoch": 0.11154489682097044,
      "grad_norm": 1.6963837146759033,
      "learning_rate": 4.463135039223011e-05,
      "loss": 1.0798,
      "step": 4800
    },
    {
      "epoch": 0.11154489682097044,
      "eval_loss": 1.037475824356079,
      "eval_runtime": 21.2923,
      "eval_samples_per_second": 187.861,
      "eval_steps_per_second": 46.965,
      "step": 4800
    },
    {
      "epoch": 0.11212585982524632,
      "grad_norm": 1.9451289176940918,
      "learning_rate": 4.460216660440792e-05,
      "loss": 1.1471,
      "step": 4825
    },
    {
      "epoch": 0.11270682282952221,
      "grad_norm": 2.0683484077453613,
      "learning_rate": 4.457298281658574e-05,
      "loss": 1.7553,
      "step": 4850
    },
    {
      "epoch": 0.1132877858337981,
      "grad_norm": 2.034597158432007,
      "learning_rate": 4.454379902876355e-05,
      "loss": 1.0239,
      "step": 4875
    },
    {
      "epoch": 0.11386874883807399,
      "grad_norm": 1.314342975616455,
      "learning_rate": 4.451461524094135e-05,
      "loss": 0.8288,
      "step": 4900
    },
    {
      "epoch": 0.11444971184234988,
      "grad_norm": 1.3065637350082397,
      "learning_rate": 4.448543145311916e-05,
      "loss": 1.2382,
      "step": 4925
    },
    {
      "epoch": 0.11503067484662577,
      "grad_norm": 1.6125327348709106,
      "learning_rate": 4.445624766529697e-05,
      "loss": 0.7511,
      "step": 4950
    },
    {
      "epoch": 0.11561163785090166,
      "grad_norm": 1.3335833549499512,
      "learning_rate": 4.442706387747479e-05,
      "loss": 0.4716,
      "step": 4975
    },
    {
      "epoch": 0.11619260085517755,
      "grad_norm": 1.2764952182769775,
      "learning_rate": 4.43978800896526e-05,
      "loss": 0.557,
      "step": 5000
    },
    {
      "epoch": 0.11619260085517755,
      "eval_loss": 1.0620967149734497,
      "eval_runtime": 21.4091,
      "eval_samples_per_second": 186.837,
      "eval_steps_per_second": 46.709,
      "step": 5000
    },
    {
      "epoch": 0.11677356385945344,
      "grad_norm": 2.3326406478881836,
      "learning_rate": 4.436869630183041e-05,
      "loss": 0.8282,
      "step": 5025
    },
    {
      "epoch": 0.11735452686372931,
      "grad_norm": 1.1908923387527466,
      "learning_rate": 4.433951251400822e-05,
      "loss": 1.2922,
      "step": 5050
    },
    {
      "epoch": 0.1179354898680052,
      "grad_norm": 1.936587929725647,
      "learning_rate": 4.431032872618603e-05,
      "loss": 1.2564,
      "step": 5075
    },
    {
      "epoch": 0.11851645287228109,
      "grad_norm": 1.6356154680252075,
      "learning_rate": 4.428114493836385e-05,
      "loss": 1.3102,
      "step": 5100
    },
    {
      "epoch": 0.11909741587655698,
      "grad_norm": 1.4396235942840576,
      "learning_rate": 4.425196115054166e-05,
      "loss": 1.8087,
      "step": 5125
    },
    {
      "epoch": 0.11967837888083287,
      "grad_norm": 2.0230977535247803,
      "learning_rate": 4.422277736271947e-05,
      "loss": 1.2921,
      "step": 5150
    },
    {
      "epoch": 0.12025934188510876,
      "grad_norm": 1.5150854587554932,
      "learning_rate": 4.419359357489727e-05,
      "loss": 1.1531,
      "step": 5175
    },
    {
      "epoch": 0.12084030488938464,
      "grad_norm": 1.5598615407943726,
      "learning_rate": 4.416440978707508e-05,
      "loss": 1.7024,
      "step": 5200
    },
    {
      "epoch": 0.12084030488938464,
      "eval_loss": 1.0158631801605225,
      "eval_runtime": 22.4854,
      "eval_samples_per_second": 177.893,
      "eval_steps_per_second": 44.473,
      "step": 5200
    },
    {
      "epoch": 0.12142126789366053,
      "grad_norm": 1.5198901891708374,
      "learning_rate": 4.41352259992529e-05,
      "loss": 1.4376,
      "step": 5225
    },
    {
      "epoch": 0.12200223089793642,
      "grad_norm": 1.4880143404006958,
      "learning_rate": 4.410604221143071e-05,
      "loss": 1.0074,
      "step": 5250
    },
    {
      "epoch": 0.12258319390221231,
      "grad_norm": 1.8025586605072021,
      "learning_rate": 4.407685842360852e-05,
      "loss": 1.3239,
      "step": 5275
    },
    {
      "epoch": 0.1231641569064882,
      "grad_norm": 1.9287019968032837,
      "learning_rate": 4.404767463578633e-05,
      "loss": 1.3968,
      "step": 5300
    },
    {
      "epoch": 0.12374511991076408,
      "grad_norm": 1.313092589378357,
      "learning_rate": 4.401849084796414e-05,
      "loss": 1.1665,
      "step": 5325
    },
    {
      "epoch": 0.12432608291503996,
      "grad_norm": 1.4353188276290894,
      "learning_rate": 4.3989307060141957e-05,
      "loss": 0.9844,
      "step": 5350
    },
    {
      "epoch": 0.12490704591931585,
      "grad_norm": 1.7804670333862305,
      "learning_rate": 4.396012327231977e-05,
      "loss": 1.3807,
      "step": 5375
    },
    {
      "epoch": 0.12548800892359174,
      "grad_norm": 1.097791075706482,
      "learning_rate": 4.393093948449758e-05,
      "loss": 1.0839,
      "step": 5400
    },
    {
      "epoch": 0.12548800892359174,
      "eval_loss": 1.0201263427734375,
      "eval_runtime": 21.1863,
      "eval_samples_per_second": 188.801,
      "eval_steps_per_second": 47.2,
      "step": 5400
    },
    {
      "epoch": 0.12606897192786765,
      "grad_norm": 1.6112220287322998,
      "learning_rate": 4.390175569667539e-05,
      "loss": 1.4863,
      "step": 5425
    },
    {
      "epoch": 0.12664993493214352,
      "grad_norm": 1.500822901725769,
      "learning_rate": 4.387257190885319e-05,
      "loss": 1.1266,
      "step": 5450
    },
    {
      "epoch": 0.1272308979364194,
      "grad_norm": 1.409350872039795,
      "learning_rate": 4.384338812103101e-05,
      "loss": 1.0945,
      "step": 5475
    },
    {
      "epoch": 0.1278118609406953,
      "grad_norm": 2.3026282787323,
      "learning_rate": 4.381420433320882e-05,
      "loss": 1.1364,
      "step": 5500
    },
    {
      "epoch": 0.12839282394497117,
      "grad_norm": 2.2134430408477783,
      "learning_rate": 4.378502054538663e-05,
      "loss": 1.2331,
      "step": 5525
    },
    {
      "epoch": 0.12897378694924708,
      "grad_norm": 2.157008647918701,
      "learning_rate": 4.375583675756444e-05,
      "loss": 1.1336,
      "step": 5550
    },
    {
      "epoch": 0.12955474995352295,
      "grad_norm": 1.4050241708755493,
      "learning_rate": 4.372665296974225e-05,
      "loss": 1.8145,
      "step": 5575
    },
    {
      "epoch": 0.13013571295779885,
      "grad_norm": 1.759559154510498,
      "learning_rate": 4.3697469181920066e-05,
      "loss": 1.1643,
      "step": 5600
    },
    {
      "epoch": 0.13013571295779885,
      "eval_loss": 1.0220205783843994,
      "eval_runtime": 21.1428,
      "eval_samples_per_second": 189.19,
      "eval_steps_per_second": 47.297,
      "step": 5600
    },
    {
      "epoch": 0.13071667596207473,
      "grad_norm": 2.9099011421203613,
      "learning_rate": 4.3668285394097877e-05,
      "loss": 1.0149,
      "step": 5625
    },
    {
      "epoch": 0.13129763896635063,
      "grad_norm": 1.5729225873947144,
      "learning_rate": 4.363910160627569e-05,
      "loss": 0.9302,
      "step": 5650
    },
    {
      "epoch": 0.1318786019706265,
      "grad_norm": 1.3045305013656616,
      "learning_rate": 4.36099178184535e-05,
      "loss": 1.1593,
      "step": 5675
    },
    {
      "epoch": 0.1324595649749024,
      "grad_norm": 1.7862684726715088,
      "learning_rate": 4.35807340306313e-05,
      "loss": 1.0646,
      "step": 5700
    },
    {
      "epoch": 0.13304052797917829,
      "grad_norm": 1.196404218673706,
      "learning_rate": 4.355155024280912e-05,
      "loss": 0.8577,
      "step": 5725
    },
    {
      "epoch": 0.13362149098345416,
      "grad_norm": 2.194004774093628,
      "learning_rate": 4.352236645498693e-05,
      "loss": 1.0252,
      "step": 5750
    },
    {
      "epoch": 0.13420245398773006,
      "grad_norm": 1.472631812095642,
      "learning_rate": 4.349318266716474e-05,
      "loss": 1.533,
      "step": 5775
    },
    {
      "epoch": 0.13478341699200594,
      "grad_norm": 1.324255347251892,
      "learning_rate": 4.346399887934255e-05,
      "loss": 1.4933,
      "step": 5800
    },
    {
      "epoch": 0.13478341699200594,
      "eval_loss": 1.008392572402954,
      "eval_runtime": 21.4976,
      "eval_samples_per_second": 186.068,
      "eval_steps_per_second": 46.517,
      "step": 5800
    },
    {
      "epoch": 0.13536437999628184,
      "grad_norm": 1.4609720706939697,
      "learning_rate": 4.343481509152036e-05,
      "loss": 1.0947,
      "step": 5825
    },
    {
      "epoch": 0.13594534300055772,
      "grad_norm": 1.9420692920684814,
      "learning_rate": 4.3405631303698176e-05,
      "loss": 1.3485,
      "step": 5850
    },
    {
      "epoch": 0.13652630600483362,
      "grad_norm": 1.6587212085723877,
      "learning_rate": 4.3376447515875986e-05,
      "loss": 0.8408,
      "step": 5875
    },
    {
      "epoch": 0.1371072690091095,
      "grad_norm": 1.6968467235565186,
      "learning_rate": 4.3347263728053796e-05,
      "loss": 0.8958,
      "step": 5900
    },
    {
      "epoch": 0.1376882320133854,
      "grad_norm": 1.4955098628997803,
      "learning_rate": 4.331807994023161e-05,
      "loss": 0.7339,
      "step": 5925
    },
    {
      "epoch": 0.13826919501766127,
      "grad_norm": 1.1719640493392944,
      "learning_rate": 4.328889615240942e-05,
      "loss": 0.8508,
      "step": 5950
    },
    {
      "epoch": 0.13885015802193718,
      "grad_norm": 1.4919103384017944,
      "learning_rate": 4.325971236458723e-05,
      "loss": 0.7029,
      "step": 5975
    },
    {
      "epoch": 0.13943112102621305,
      "grad_norm": 1.8725239038467407,
      "learning_rate": 4.323052857676504e-05,
      "loss": 0.7441,
      "step": 6000
    },
    {
      "epoch": 0.13943112102621305,
      "eval_loss": 1.0103498697280884,
      "eval_runtime": 21.4744,
      "eval_samples_per_second": 186.268,
      "eval_steps_per_second": 46.567,
      "step": 6000
    },
    {
      "epoch": 0.14001208403048893,
      "grad_norm": 2.0080108642578125,
      "learning_rate": 4.320134478894285e-05,
      "loss": 0.6693,
      "step": 6025
    },
    {
      "epoch": 0.14059304703476483,
      "grad_norm": 1.6534199714660645,
      "learning_rate": 4.317216100112066e-05,
      "loss": 0.8212,
      "step": 6050
    },
    {
      "epoch": 0.1411740100390407,
      "grad_norm": 1.3134562969207764,
      "learning_rate": 4.314297721329847e-05,
      "loss": 0.8522,
      "step": 6075
    },
    {
      "epoch": 0.1417549730433166,
      "grad_norm": 1.8413313627243042,
      "learning_rate": 4.311379342547628e-05,
      "loss": 0.8813,
      "step": 6100
    },
    {
      "epoch": 0.14233593604759248,
      "grad_norm": 1.1290549039840698,
      "learning_rate": 4.3084609637654096e-05,
      "loss": 0.7732,
      "step": 6125
    },
    {
      "epoch": 0.14291689905186838,
      "grad_norm": 1.4366651773452759,
      "learning_rate": 4.3055425849831906e-05,
      "loss": 0.6617,
      "step": 6150
    },
    {
      "epoch": 0.14349786205614426,
      "grad_norm": 1.5613369941711426,
      "learning_rate": 4.3026242062009716e-05,
      "loss": 0.805,
      "step": 6175
    },
    {
      "epoch": 0.14407882506042016,
      "grad_norm": 1.3720197677612305,
      "learning_rate": 4.299705827418753e-05,
      "loss": 0.8091,
      "step": 6200
    },
    {
      "epoch": 0.14407882506042016,
      "eval_loss": 1.0088927745819092,
      "eval_runtime": 22.9951,
      "eval_samples_per_second": 173.95,
      "eval_steps_per_second": 43.488,
      "step": 6200
    },
    {
      "epoch": 0.14465978806469604,
      "grad_norm": 1.6816284656524658,
      "learning_rate": 4.296787448636534e-05,
      "loss": 0.8221,
      "step": 6225
    },
    {
      "epoch": 0.14524075106897194,
      "grad_norm": 1.7508375644683838,
      "learning_rate": 4.293869069854315e-05,
      "loss": 0.8226,
      "step": 6250
    },
    {
      "epoch": 0.14582171407324782,
      "grad_norm": 0.9763016700744629,
      "learning_rate": 4.290950691072096e-05,
      "loss": 0.836,
      "step": 6275
    },
    {
      "epoch": 0.1464026770775237,
      "grad_norm": 2.1705281734466553,
      "learning_rate": 4.288032312289877e-05,
      "loss": 0.7237,
      "step": 6300
    },
    {
      "epoch": 0.1469836400817996,
      "grad_norm": 1.2365418672561646,
      "learning_rate": 4.285113933507658e-05,
      "loss": 0.9356,
      "step": 6325
    },
    {
      "epoch": 0.14756460308607547,
      "grad_norm": 1.7920541763305664,
      "learning_rate": 4.282195554725439e-05,
      "loss": 0.7636,
      "step": 6350
    },
    {
      "epoch": 0.14814556609035137,
      "grad_norm": 1.8210808038711548,
      "learning_rate": 4.2792771759432206e-05,
      "loss": 0.8194,
      "step": 6375
    },
    {
      "epoch": 0.14872652909462725,
      "grad_norm": 1.4191279411315918,
      "learning_rate": 4.2763587971610016e-05,
      "loss": 0.6417,
      "step": 6400
    },
    {
      "epoch": 0.14872652909462725,
      "eval_loss": 1.018103837966919,
      "eval_runtime": 21.2519,
      "eval_samples_per_second": 188.219,
      "eval_steps_per_second": 47.055,
      "step": 6400
    },
    {
      "epoch": 0.14930749209890315,
      "grad_norm": 1.9583148956298828,
      "learning_rate": 4.2734404183787826e-05,
      "loss": 0.8056,
      "step": 6425
    },
    {
      "epoch": 0.14988845510317902,
      "grad_norm": 2.101470470428467,
      "learning_rate": 4.2705220395965636e-05,
      "loss": 1.3466,
      "step": 6450
    },
    {
      "epoch": 0.15046941810745493,
      "grad_norm": 2.288172721862793,
      "learning_rate": 4.267603660814345e-05,
      "loss": 1.2208,
      "step": 6475
    },
    {
      "epoch": 0.1510503811117308,
      "grad_norm": 1.7136353254318237,
      "learning_rate": 4.264685282032126e-05,
      "loss": 0.755,
      "step": 6500
    },
    {
      "epoch": 0.1516313441160067,
      "grad_norm": 1.9987531900405884,
      "learning_rate": 4.261766903249907e-05,
      "loss": 0.6877,
      "step": 6525
    },
    {
      "epoch": 0.15221230712028258,
      "grad_norm": 3.169346570968628,
      "learning_rate": 4.258848524467688e-05,
      "loss": 0.7627,
      "step": 6550
    },
    {
      "epoch": 0.15279327012455846,
      "grad_norm": 1.5495779514312744,
      "learning_rate": 4.255930145685469e-05,
      "loss": 0.7359,
      "step": 6575
    },
    {
      "epoch": 0.15337423312883436,
      "grad_norm": 1.6472816467285156,
      "learning_rate": 4.25301176690325e-05,
      "loss": 0.7903,
      "step": 6600
    },
    {
      "epoch": 0.15337423312883436,
      "eval_loss": 0.9999310374259949,
      "eval_runtime": 21.7101,
      "eval_samples_per_second": 184.246,
      "eval_steps_per_second": 46.061,
      "step": 6600
    },
    {
      "epoch": 0.15395519613311023,
      "grad_norm": 1.5906682014465332,
      "learning_rate": 4.2500933881210315e-05,
      "loss": 0.6941,
      "step": 6625
    },
    {
      "epoch": 0.15453615913738614,
      "grad_norm": 1.6289997100830078,
      "learning_rate": 4.2471750093388126e-05,
      "loss": 0.7365,
      "step": 6650
    },
    {
      "epoch": 0.155117122141662,
      "grad_norm": 1.8819563388824463,
      "learning_rate": 4.2442566305565936e-05,
      "loss": 0.7362,
      "step": 6675
    },
    {
      "epoch": 0.15569808514593791,
      "grad_norm": 1.1358782052993774,
      "learning_rate": 4.2413382517743746e-05,
      "loss": 0.8594,
      "step": 6700
    },
    {
      "epoch": 0.1562790481502138,
      "grad_norm": 1.0665000677108765,
      "learning_rate": 4.2384198729921556e-05,
      "loss": 0.7703,
      "step": 6725
    },
    {
      "epoch": 0.1568600111544897,
      "grad_norm": 1.6145460605621338,
      "learning_rate": 4.235501494209937e-05,
      "loss": 0.7675,
      "step": 6750
    },
    {
      "epoch": 0.15744097415876557,
      "grad_norm": 2.122833490371704,
      "learning_rate": 4.232583115427718e-05,
      "loss": 0.8324,
      "step": 6775
    },
    {
      "epoch": 0.15802193716304147,
      "grad_norm": 1.7284436225891113,
      "learning_rate": 4.229664736645499e-05,
      "loss": 0.8856,
      "step": 6800
    },
    {
      "epoch": 0.15802193716304147,
      "eval_loss": 1.0014406442642212,
      "eval_runtime": 21.9487,
      "eval_samples_per_second": 182.243,
      "eval_steps_per_second": 45.561,
      "step": 6800
    },
    {
      "epoch": 0.15860290016731735,
      "grad_norm": 1.469436764717102,
      "learning_rate": 4.22674635786328e-05,
      "loss": 0.8791,
      "step": 6825
    },
    {
      "epoch": 0.15918386317159322,
      "grad_norm": 1.2210383415222168,
      "learning_rate": 4.223827979081061e-05,
      "loss": 0.7194,
      "step": 6850
    },
    {
      "epoch": 0.15976482617586912,
      "grad_norm": 2.264648914337158,
      "learning_rate": 4.2209096002988425e-05,
      "loss": 1.5736,
      "step": 6875
    },
    {
      "epoch": 0.160345789180145,
      "grad_norm": 1.869686245918274,
      "learning_rate": 4.2179912215166235e-05,
      "loss": 1.4453,
      "step": 6900
    },
    {
      "epoch": 0.1609267521844209,
      "grad_norm": 2.1481449604034424,
      "learning_rate": 4.2150728427344046e-05,
      "loss": 1.3908,
      "step": 6925
    },
    {
      "epoch": 0.16150771518869678,
      "grad_norm": 2.034086227416992,
      "learning_rate": 4.2121544639521856e-05,
      "loss": 1.6799,
      "step": 6950
    },
    {
      "epoch": 0.16208867819297268,
      "grad_norm": 2.1132352352142334,
      "learning_rate": 4.2092360851699666e-05,
      "loss": 1.6342,
      "step": 6975
    },
    {
      "epoch": 0.16266964119724855,
      "grad_norm": 1.2408862113952637,
      "learning_rate": 4.2063177063877476e-05,
      "loss": 0.9142,
      "step": 7000
    },
    {
      "epoch": 0.16266964119724855,
      "eval_loss": 1.0058932304382324,
      "eval_runtime": 21.8338,
      "eval_samples_per_second": 183.202,
      "eval_steps_per_second": 45.801,
      "step": 7000
    },
    {
      "epoch": 0.16325060420152446,
      "grad_norm": 2.986443519592285,
      "learning_rate": 4.203399327605529e-05,
      "loss": 2.0116,
      "step": 7025
    },
    {
      "epoch": 0.16383156720580033,
      "grad_norm": 2.653724193572998,
      "learning_rate": 4.20048094882331e-05,
      "loss": 1.9388,
      "step": 7050
    },
    {
      "epoch": 0.16441253021007624,
      "grad_norm": 1.36354660987854,
      "learning_rate": 4.197562570041091e-05,
      "loss": 1.6011,
      "step": 7075
    },
    {
      "epoch": 0.1649934932143521,
      "grad_norm": 1.2242517471313477,
      "learning_rate": 4.194644191258872e-05,
      "loss": 1.1002,
      "step": 7100
    },
    {
      "epoch": 0.16557445621862799,
      "grad_norm": 1.294416069984436,
      "learning_rate": 4.1917258124766535e-05,
      "loss": 1.0242,
      "step": 7125
    },
    {
      "epoch": 0.1661554192229039,
      "grad_norm": 1.5428450107574463,
      "learning_rate": 4.1888074336944345e-05,
      "loss": 1.0395,
      "step": 7150
    },
    {
      "epoch": 0.16673638222717976,
      "grad_norm": 2.072233200073242,
      "learning_rate": 4.1858890549122155e-05,
      "loss": 1.2568,
      "step": 7175
    },
    {
      "epoch": 0.16731734523145567,
      "grad_norm": 1.3869467973709106,
      "learning_rate": 4.1829706761299965e-05,
      "loss": 1.001,
      "step": 7200
    },
    {
      "epoch": 0.16731734523145567,
      "eval_loss": 0.989217221736908,
      "eval_runtime": 21.0818,
      "eval_samples_per_second": 189.737,
      "eval_steps_per_second": 47.434,
      "step": 7200
    },
    {
      "epoch": 0.16789830823573154,
      "grad_norm": 1.1061855554580688,
      "learning_rate": 4.1800522973477776e-05,
      "loss": 1.1144,
      "step": 7225
    },
    {
      "epoch": 0.16847927124000744,
      "grad_norm": 1.3858107328414917,
      "learning_rate": 4.1771339185655586e-05,
      "loss": 1.2406,
      "step": 7250
    },
    {
      "epoch": 0.16906023424428332,
      "grad_norm": 1.5312747955322266,
      "learning_rate": 4.1742155397833396e-05,
      "loss": 1.1907,
      "step": 7275
    },
    {
      "epoch": 0.16964119724855922,
      "grad_norm": 1.1472821235656738,
      "learning_rate": 4.171297161001121e-05,
      "loss": 0.9914,
      "step": 7300
    },
    {
      "epoch": 0.1702221602528351,
      "grad_norm": 0.9752455949783325,
      "learning_rate": 4.168378782218902e-05,
      "loss": 1.1328,
      "step": 7325
    },
    {
      "epoch": 0.170803123257111,
      "grad_norm": 1.9701311588287354,
      "learning_rate": 4.165460403436683e-05,
      "loss": 1.3837,
      "step": 7350
    },
    {
      "epoch": 0.17138408626138688,
      "grad_norm": 1.8768497705459595,
      "learning_rate": 4.1625420246544644e-05,
      "loss": 1.3215,
      "step": 7375
    },
    {
      "epoch": 0.17196504926566275,
      "grad_norm": 3.4222869873046875,
      "learning_rate": 4.1596236458722455e-05,
      "loss": 1.2719,
      "step": 7400
    },
    {
      "epoch": 0.17196504926566275,
      "eval_loss": 0.9998745918273926,
      "eval_runtime": 20.5344,
      "eval_samples_per_second": 194.795,
      "eval_steps_per_second": 48.699,
      "step": 7400
    },
    {
      "epoch": 0.17254601226993865,
      "grad_norm": 1.7544339895248413,
      "learning_rate": 4.1567052670900265e-05,
      "loss": 1.3575,
      "step": 7425
    },
    {
      "epoch": 0.17312697527421453,
      "grad_norm": 1.469239354133606,
      "learning_rate": 4.1537868883078075e-05,
      "loss": 1.4165,
      "step": 7450
    },
    {
      "epoch": 0.17370793827849043,
      "grad_norm": 2.0350708961486816,
      "learning_rate": 4.1508685095255885e-05,
      "loss": 1.2492,
      "step": 7475
    },
    {
      "epoch": 0.1742889012827663,
      "grad_norm": 1.6357907056808472,
      "learning_rate": 4.1479501307433696e-05,
      "loss": 1.1045,
      "step": 7500
    },
    {
      "epoch": 0.1748698642870422,
      "grad_norm": 1.772500991821289,
      "learning_rate": 4.1450317519611506e-05,
      "loss": 1.0771,
      "step": 7525
    },
    {
      "epoch": 0.17545082729131808,
      "grad_norm": 1.3911616802215576,
      "learning_rate": 4.1421133731789316e-05,
      "loss": 0.9786,
      "step": 7550
    },
    {
      "epoch": 0.176031790295594,
      "grad_norm": 1.8722879886627197,
      "learning_rate": 4.139194994396713e-05,
      "loss": 1.0652,
      "step": 7575
    },
    {
      "epoch": 0.17661275329986986,
      "grad_norm": 2.3284454345703125,
      "learning_rate": 4.136276615614494e-05,
      "loss": 0.9945,
      "step": 7600
    },
    {
      "epoch": 0.17661275329986986,
      "eval_loss": 0.9996811747550964,
      "eval_runtime": 20.3508,
      "eval_samples_per_second": 196.553,
      "eval_steps_per_second": 49.138,
      "step": 7600
    },
    {
      "epoch": 0.17719371630414577,
      "grad_norm": 1.6667722463607788,
      "learning_rate": 4.1333582368322754e-05,
      "loss": 0.9737,
      "step": 7625
    },
    {
      "epoch": 0.17777467930842164,
      "grad_norm": 1.6911340951919556,
      "learning_rate": 4.1304398580500564e-05,
      "loss": 1.1658,
      "step": 7650
    },
    {
      "epoch": 0.17835564231269752,
      "grad_norm": 1.300207495689392,
      "learning_rate": 4.1275214792678375e-05,
      "loss": 1.1471,
      "step": 7675
    },
    {
      "epoch": 0.17893660531697342,
      "grad_norm": 1.8731690645217896,
      "learning_rate": 4.1246031004856185e-05,
      "loss": 0.917,
      "step": 7700
    },
    {
      "epoch": 0.1795175683212493,
      "grad_norm": 2.491260290145874,
      "learning_rate": 4.1216847217033995e-05,
      "loss": 1.6465,
      "step": 7725
    },
    {
      "epoch": 0.1800985313255252,
      "grad_norm": 1.7553820610046387,
      "learning_rate": 4.1187663429211805e-05,
      "loss": 1.3773,
      "step": 7750
    },
    {
      "epoch": 0.18067949432980107,
      "grad_norm": 2.45731782913208,
      "learning_rate": 4.1158479641389616e-05,
      "loss": 1.3416,
      "step": 7775
    },
    {
      "epoch": 0.18126045733407697,
      "grad_norm": 1.5659480094909668,
      "learning_rate": 4.1129295853567426e-05,
      "loss": 1.1885,
      "step": 7800
    },
    {
      "epoch": 0.18126045733407697,
      "eval_loss": 0.9894229769706726,
      "eval_runtime": 20.4676,
      "eval_samples_per_second": 195.431,
      "eval_steps_per_second": 48.858,
      "step": 7800
    },
    {
      "epoch": 0.18184142033835285,
      "grad_norm": 1.3238098621368408,
      "learning_rate": 4.1100112065745236e-05,
      "loss": 0.8315,
      "step": 7825
    },
    {
      "epoch": 0.18242238334262875,
      "grad_norm": 2.052372932434082,
      "learning_rate": 4.1070928277923047e-05,
      "loss": 0.9266,
      "step": 7850
    },
    {
      "epoch": 0.18300334634690463,
      "grad_norm": 1.0379853248596191,
      "learning_rate": 4.104174449010086e-05,
      "loss": 1.6217,
      "step": 7875
    },
    {
      "epoch": 0.18358430935118053,
      "grad_norm": 1.1837177276611328,
      "learning_rate": 4.1012560702278674e-05,
      "loss": 1.0981,
      "step": 7900
    },
    {
      "epoch": 0.1841652723554564,
      "grad_norm": 2.1549246311187744,
      "learning_rate": 4.0983376914456484e-05,
      "loss": 0.9504,
      "step": 7925
    },
    {
      "epoch": 0.18474623535973228,
      "grad_norm": 1.932322382926941,
      "learning_rate": 4.0954193126634295e-05,
      "loss": 1.288,
      "step": 7950
    },
    {
      "epoch": 0.18532719836400818,
      "grad_norm": 1.2629361152648926,
      "learning_rate": 4.0925009338812105e-05,
      "loss": 0.9018,
      "step": 7975
    },
    {
      "epoch": 0.18590816136828406,
      "grad_norm": 4.001811504364014,
      "learning_rate": 4.0895825550989915e-05,
      "loss": 1.2153,
      "step": 8000
    },
    {
      "epoch": 0.18590816136828406,
      "eval_loss": 0.9861886501312256,
      "eval_runtime": 20.4847,
      "eval_samples_per_second": 195.268,
      "eval_steps_per_second": 48.817,
      "step": 8000
    },
    {
      "epoch": 0.18648912437255996,
      "grad_norm": 1.456312656402588,
      "learning_rate": 4.086664176316773e-05,
      "loss": 1.1619,
      "step": 8025
    },
    {
      "epoch": 0.18707008737683584,
      "grad_norm": 1.0519858598709106,
      "learning_rate": 4.0837457975345536e-05,
      "loss": 0.9106,
      "step": 8050
    },
    {
      "epoch": 0.18765105038111174,
      "grad_norm": 1.4485132694244385,
      "learning_rate": 4.0808274187523346e-05,
      "loss": 0.9809,
      "step": 8075
    },
    {
      "epoch": 0.18823201338538761,
      "grad_norm": 1.0167968273162842,
      "learning_rate": 4.0779090399701156e-05,
      "loss": 1.0469,
      "step": 8100
    },
    {
      "epoch": 0.18881297638966352,
      "grad_norm": 3.1587867736816406,
      "learning_rate": 4.0749906611878967e-05,
      "loss": 1.0467,
      "step": 8125
    },
    {
      "epoch": 0.1893939393939394,
      "grad_norm": 1.7745709419250488,
      "learning_rate": 4.0720722824056784e-05,
      "loss": 1.242,
      "step": 8150
    },
    {
      "epoch": 0.1899749023982153,
      "grad_norm": 2.3861160278320312,
      "learning_rate": 4.0691539036234594e-05,
      "loss": 1.0864,
      "step": 8175
    },
    {
      "epoch": 0.19055586540249117,
      "grad_norm": 2.683992385864258,
      "learning_rate": 4.0662355248412404e-05,
      "loss": 1.4153,
      "step": 8200
    },
    {
      "epoch": 0.19055586540249117,
      "eval_loss": 0.9893509745597839,
      "eval_runtime": 21.039,
      "eval_samples_per_second": 190.123,
      "eval_steps_per_second": 47.531,
      "step": 8200
    },
    {
      "epoch": 0.19113682840676705,
      "grad_norm": 1.172592043876648,
      "learning_rate": 4.0633171460590215e-05,
      "loss": 1.4269,
      "step": 8225
    },
    {
      "epoch": 0.19171779141104295,
      "grad_norm": 1.4970988035202026,
      "learning_rate": 4.0603987672768025e-05,
      "loss": 1.3701,
      "step": 8250
    },
    {
      "epoch": 0.19229875441531882,
      "grad_norm": 1.7070794105529785,
      "learning_rate": 4.057480388494584e-05,
      "loss": 1.2721,
      "step": 8275
    },
    {
      "epoch": 0.19287971741959473,
      "grad_norm": 1.389230728149414,
      "learning_rate": 4.054562009712365e-05,
      "loss": 1.7362,
      "step": 8300
    },
    {
      "epoch": 0.1934606804238706,
      "grad_norm": 1.746610403060913,
      "learning_rate": 4.0516436309301456e-05,
      "loss": 1.1425,
      "step": 8325
    },
    {
      "epoch": 0.1940416434281465,
      "grad_norm": 1.820507526397705,
      "learning_rate": 4.0487252521479266e-05,
      "loss": 0.5887,
      "step": 8350
    },
    {
      "epoch": 0.19462260643242238,
      "grad_norm": 2.607485294342041,
      "learning_rate": 4.0458068733657076e-05,
      "loss": 1.1855,
      "step": 8375
    },
    {
      "epoch": 0.19520356943669828,
      "grad_norm": 1.667506217956543,
      "learning_rate": 4.042888494583489e-05,
      "loss": 1.1702,
      "step": 8400
    },
    {
      "epoch": 0.19520356943669828,
      "eval_loss": 0.9830164313316345,
      "eval_runtime": 20.4865,
      "eval_samples_per_second": 195.25,
      "eval_steps_per_second": 48.813,
      "step": 8400
    },
    {
      "epoch": 0.19578453244097416,
      "grad_norm": 1.7234084606170654,
      "learning_rate": 4.0399701158012704e-05,
      "loss": 1.0681,
      "step": 8425
    },
    {
      "epoch": 0.19636549544525006,
      "grad_norm": 1.696286678314209,
      "learning_rate": 4.0370517370190514e-05,
      "loss": 1.1086,
      "step": 8450
    },
    {
      "epoch": 0.19694645844952594,
      "grad_norm": 1.472886085510254,
      "learning_rate": 4.0341333582368324e-05,
      "loss": 1.189,
      "step": 8475
    },
    {
      "epoch": 0.1975274214538018,
      "grad_norm": 1.0955573320388794,
      "learning_rate": 4.0312149794546134e-05,
      "loss": 0.9143,
      "step": 8500
    },
    {
      "epoch": 0.1981083844580777,
      "grad_norm": 1.5216972827911377,
      "learning_rate": 4.028296600672395e-05,
      "loss": 1.127,
      "step": 8525
    },
    {
      "epoch": 0.1986893474623536,
      "grad_norm": 1.9448729753494263,
      "learning_rate": 4.025378221890176e-05,
      "loss": 1.1317,
      "step": 8550
    },
    {
      "epoch": 0.1992703104666295,
      "grad_norm": 1.608210802078247,
      "learning_rate": 4.0224598431079565e-05,
      "loss": 1.1871,
      "step": 8575
    },
    {
      "epoch": 0.19985127347090537,
      "grad_norm": 2.5209670066833496,
      "learning_rate": 4.0195414643257376e-05,
      "loss": 1.0978,
      "step": 8600
    },
    {
      "epoch": 0.19985127347090537,
      "eval_loss": 0.990878164768219,
      "eval_runtime": 20.4553,
      "eval_samples_per_second": 195.549,
      "eval_steps_per_second": 48.887,
      "step": 8600
    },
    {
      "epoch": 0.20043223647518127,
      "grad_norm": 1.6553828716278076,
      "learning_rate": 4.0166230855435186e-05,
      "loss": 1.1928,
      "step": 8625
    },
    {
      "epoch": 0.20101319947945714,
      "grad_norm": 6.180654525756836,
      "learning_rate": 4.0137047067613e-05,
      "loss": 1.1183,
      "step": 8650
    },
    {
      "epoch": 0.20159416248373305,
      "grad_norm": 1.985324501991272,
      "learning_rate": 4.010786327979081e-05,
      "loss": 1.4425,
      "step": 8675
    },
    {
      "epoch": 0.20217512548800892,
      "grad_norm": 1.654929757118225,
      "learning_rate": 4.0078679491968624e-05,
      "loss": 1.2564,
      "step": 8700
    },
    {
      "epoch": 0.20275608849228482,
      "grad_norm": 1.102209210395813,
      "learning_rate": 4.0049495704146434e-05,
      "loss": 0.6775,
      "step": 8725
    },
    {
      "epoch": 0.2033370514965607,
      "grad_norm": 1.7977895736694336,
      "learning_rate": 4.0020311916324244e-05,
      "loss": 0.7071,
      "step": 8750
    },
    {
      "epoch": 0.20391801450083658,
      "grad_norm": 1.8824353218078613,
      "learning_rate": 3.999112812850206e-05,
      "loss": 0.7369,
      "step": 8775
    },
    {
      "epoch": 0.20449897750511248,
      "grad_norm": 1.0906120538711548,
      "learning_rate": 3.996194434067987e-05,
      "loss": 0.6724,
      "step": 8800
    },
    {
      "epoch": 0.20449897750511248,
      "eval_loss": 0.9792759418487549,
      "eval_runtime": 20.4596,
      "eval_samples_per_second": 195.508,
      "eval_steps_per_second": 48.877,
      "step": 8800
    },
    {
      "epoch": 0.20507994050938835,
      "grad_norm": 2.6605916023254395,
      "learning_rate": 3.993276055285768e-05,
      "loss": 0.6605,
      "step": 8825
    },
    {
      "epoch": 0.20566090351366426,
      "grad_norm": 1.2806901931762695,
      "learning_rate": 3.9903576765035485e-05,
      "loss": 0.5678,
      "step": 8850
    },
    {
      "epoch": 0.20624186651794013,
      "grad_norm": 1.3559921979904175,
      "learning_rate": 3.9874392977213296e-05,
      "loss": 0.7213,
      "step": 8875
    },
    {
      "epoch": 0.20682282952221603,
      "grad_norm": 1.127358317375183,
      "learning_rate": 3.984520918939111e-05,
      "loss": 0.7083,
      "step": 8900
    },
    {
      "epoch": 0.2074037925264919,
      "grad_norm": 1.2202519178390503,
      "learning_rate": 3.981602540156892e-05,
      "loss": 0.667,
      "step": 8925
    },
    {
      "epoch": 0.2079847555307678,
      "grad_norm": 1.8666582107543945,
      "learning_rate": 3.978684161374673e-05,
      "loss": 0.8286,
      "step": 8950
    },
    {
      "epoch": 0.2085657185350437,
      "grad_norm": 1.1288191080093384,
      "learning_rate": 3.9757657825924544e-05,
      "loss": 0.973,
      "step": 8975
    },
    {
      "epoch": 0.2091466815393196,
      "grad_norm": 1.0473687648773193,
      "learning_rate": 3.9728474038102354e-05,
      "loss": 0.8306,
      "step": 9000
    },
    {
      "epoch": 0.2091466815393196,
      "eval_loss": 0.9801948070526123,
      "eval_runtime": 20.6667,
      "eval_samples_per_second": 193.548,
      "eval_steps_per_second": 48.387,
      "step": 9000
    },
    {
      "epoch": 0.20972764454359547,
      "grad_norm": 2.488595485687256,
      "learning_rate": 3.969929025028017e-05,
      "loss": 1.2821,
      "step": 9025
    },
    {
      "epoch": 0.21030860754787134,
      "grad_norm": 1.667752742767334,
      "learning_rate": 3.967010646245798e-05,
      "loss": 1.3439,
      "step": 9050
    },
    {
      "epoch": 0.21088957055214724,
      "grad_norm": 2.4004571437835693,
      "learning_rate": 3.964092267463579e-05,
      "loss": 1.8817,
      "step": 9075
    },
    {
      "epoch": 0.21147053355642312,
      "grad_norm": 1.6105958223342896,
      "learning_rate": 3.96117388868136e-05,
      "loss": 1.1558,
      "step": 9100
    },
    {
      "epoch": 0.21205149656069902,
      "grad_norm": 1.5682923793792725,
      "learning_rate": 3.9582555098991405e-05,
      "loss": 0.694,
      "step": 9125
    },
    {
      "epoch": 0.2126324595649749,
      "grad_norm": 1.6883467435836792,
      "learning_rate": 3.955337131116922e-05,
      "loss": 1.5505,
      "step": 9150
    },
    {
      "epoch": 0.2132134225692508,
      "grad_norm": 1.8866933584213257,
      "learning_rate": 3.952418752334703e-05,
      "loss": 0.957,
      "step": 9175
    },
    {
      "epoch": 0.21379438557352667,
      "grad_norm": 1.3426803350448608,
      "learning_rate": 3.949500373552484e-05,
      "loss": 0.775,
      "step": 9200
    },
    {
      "epoch": 0.21379438557352667,
      "eval_loss": 0.9789342284202576,
      "eval_runtime": 21.2279,
      "eval_samples_per_second": 188.431,
      "eval_steps_per_second": 47.108,
      "step": 9200
    },
    {
      "epoch": 0.21437534857780258,
      "grad_norm": 1.4463143348693848,
      "learning_rate": 3.946581994770265e-05,
      "loss": 0.8998,
      "step": 9225
    },
    {
      "epoch": 0.21495631158207845,
      "grad_norm": 1.5731465816497803,
      "learning_rate": 3.9436636159880464e-05,
      "loss": 1.2056,
      "step": 9250
    },
    {
      "epoch": 0.21553727458635433,
      "grad_norm": 1.7183382511138916,
      "learning_rate": 3.9407452372058274e-05,
      "loss": 1.2968,
      "step": 9275
    },
    {
      "epoch": 0.21611823759063023,
      "grad_norm": 2.0298612117767334,
      "learning_rate": 3.937826858423609e-05,
      "loss": 1.1759,
      "step": 9300
    },
    {
      "epoch": 0.2166992005949061,
      "grad_norm": 1.8382307291030884,
      "learning_rate": 3.93490847964139e-05,
      "loss": 0.9888,
      "step": 9325
    },
    {
      "epoch": 0.217280163599182,
      "grad_norm": 1.6359134912490845,
      "learning_rate": 3.931990100859171e-05,
      "loss": 1.0046,
      "step": 9350
    },
    {
      "epoch": 0.21786112660345788,
      "grad_norm": 2.3447229862213135,
      "learning_rate": 3.929071722076952e-05,
      "loss": 1.0472,
      "step": 9375
    },
    {
      "epoch": 0.21844208960773379,
      "grad_norm": 1.7155681848526,
      "learning_rate": 3.9261533432947325e-05,
      "loss": 0.4193,
      "step": 9400
    },
    {
      "epoch": 0.21844208960773379,
      "eval_loss": 0.9916693568229675,
      "eval_runtime": 20.4346,
      "eval_samples_per_second": 195.746,
      "eval_steps_per_second": 48.937,
      "step": 9400
    },
    {
      "epoch": 0.21902305261200966,
      "grad_norm": 0.3067547082901001,
      "learning_rate": 3.923234964512514e-05,
      "loss": 0.1024,
      "step": 9425
    },
    {
      "epoch": 0.21960401561628556,
      "grad_norm": 2.3470561504364014,
      "learning_rate": 3.920316585730295e-05,
      "loss": 0.1245,
      "step": 9450
    },
    {
      "epoch": 0.22018497862056144,
      "grad_norm": 2.266263484954834,
      "learning_rate": 3.917398206948076e-05,
      "loss": 1.0674,
      "step": 9475
    },
    {
      "epoch": 0.22076594162483734,
      "grad_norm": 1.5402076244354248,
      "learning_rate": 3.914479828165857e-05,
      "loss": 0.8752,
      "step": 9500
    },
    {
      "epoch": 0.22134690462911322,
      "grad_norm": 2.3571150302886963,
      "learning_rate": 3.9115614493836384e-05,
      "loss": 0.9698,
      "step": 9525
    },
    {
      "epoch": 0.2219278676333891,
      "grad_norm": 1.8788001537322998,
      "learning_rate": 3.90864307060142e-05,
      "loss": 1.1584,
      "step": 9550
    },
    {
      "epoch": 0.222508830637665,
      "grad_norm": 3.309065818786621,
      "learning_rate": 3.905724691819201e-05,
      "loss": 0.7548,
      "step": 9575
    },
    {
      "epoch": 0.22308979364194087,
      "grad_norm": 3.7403063774108887,
      "learning_rate": 3.902806313036982e-05,
      "loss": 1.4478,
      "step": 9600
    },
    {
      "epoch": 0.22308979364194087,
      "eval_loss": 0.9735568761825562,
      "eval_runtime": 21.6735,
      "eval_samples_per_second": 184.557,
      "eval_steps_per_second": 46.139,
      "step": 9600
    },
    {
      "epoch": 0.22367075664621677,
      "grad_norm": 1.362705111503601,
      "learning_rate": 3.899887934254763e-05,
      "loss": 0.8369,
      "step": 9625
    },
    {
      "epoch": 0.22425171965049265,
      "grad_norm": 1.191572904586792,
      "learning_rate": 3.8969695554725435e-05,
      "loss": 0.9158,
      "step": 9650
    },
    {
      "epoch": 0.22483268265476855,
      "grad_norm": 1.6472846269607544,
      "learning_rate": 3.894051176690325e-05,
      "loss": 0.692,
      "step": 9675
    },
    {
      "epoch": 0.22541364565904443,
      "grad_norm": 2.362433671951294,
      "learning_rate": 3.891132797908106e-05,
      "loss": 0.7788,
      "step": 9700
    },
    {
      "epoch": 0.22599460866332033,
      "grad_norm": 2.0000874996185303,
      "learning_rate": 3.888214419125887e-05,
      "loss": 0.7862,
      "step": 9725
    },
    {
      "epoch": 0.2265755716675962,
      "grad_norm": 2.601635456085205,
      "learning_rate": 3.885296040343668e-05,
      "loss": 0.8772,
      "step": 9750
    },
    {
      "epoch": 0.2271565346718721,
      "grad_norm": 1.899192214012146,
      "learning_rate": 3.882377661561449e-05,
      "loss": 0.8782,
      "step": 9775
    },
    {
      "epoch": 0.22773749767614798,
      "grad_norm": 1.5906827449798584,
      "learning_rate": 3.879459282779231e-05,
      "loss": 0.8715,
      "step": 9800
    },
    {
      "epoch": 0.22773749767614798,
      "eval_loss": 0.9828234910964966,
      "eval_runtime": 21.9091,
      "eval_samples_per_second": 182.572,
      "eval_steps_per_second": 45.643,
      "step": 9800
    },
    {
      "epoch": 0.22831846068042386,
      "grad_norm": 1.736051321029663,
      "learning_rate": 3.876540903997012e-05,
      "loss": 0.8828,
      "step": 9825
    },
    {
      "epoch": 0.22889942368469976,
      "grad_norm": 2.128035306930542,
      "learning_rate": 3.873622525214793e-05,
      "loss": 0.9904,
      "step": 9850
    },
    {
      "epoch": 0.22948038668897563,
      "grad_norm": 2.7730038166046143,
      "learning_rate": 3.870704146432574e-05,
      "loss": 1.0521,
      "step": 9875
    },
    {
      "epoch": 0.23006134969325154,
      "grad_norm": 1.5443384647369385,
      "learning_rate": 3.867785767650355e-05,
      "loss": 0.9433,
      "step": 9900
    },
    {
      "epoch": 0.2306423126975274,
      "grad_norm": 1.7560125589370728,
      "learning_rate": 3.864867388868136e-05,
      "loss": 1.1211,
      "step": 9925
    },
    {
      "epoch": 0.23122327570180332,
      "grad_norm": 2.4444479942321777,
      "learning_rate": 3.861949010085917e-05,
      "loss": 1.5831,
      "step": 9950
    },
    {
      "epoch": 0.2318042387060792,
      "grad_norm": 3.2659482955932617,
      "learning_rate": 3.859030631303698e-05,
      "loss": 1.1835,
      "step": 9975
    },
    {
      "epoch": 0.2323852017103551,
      "grad_norm": 2.118460178375244,
      "learning_rate": 3.856112252521479e-05,
      "loss": 1.1368,
      "step": 10000
    },
    {
      "epoch": 0.2323852017103551,
      "eval_loss": 0.9805670380592346,
      "eval_runtime": 21.1379,
      "eval_samples_per_second": 189.233,
      "eval_steps_per_second": 47.308,
      "step": 10000
    },
    {
      "epoch": 0.23296616471463097,
      "grad_norm": 1.427301049232483,
      "learning_rate": 3.85319387373926e-05,
      "loss": 0.7625,
      "step": 10025
    },
    {
      "epoch": 0.23354712771890687,
      "grad_norm": 1.5189213752746582,
      "learning_rate": 3.850275494957042e-05,
      "loss": 0.7444,
      "step": 10050
    },
    {
      "epoch": 0.23412809072318275,
      "grad_norm": 1.7604714632034302,
      "learning_rate": 3.847357116174823e-05,
      "loss": 0.7647,
      "step": 10075
    },
    {
      "epoch": 0.23470905372745862,
      "grad_norm": 1.293291687965393,
      "learning_rate": 3.844438737392604e-05,
      "loss": 0.6552,
      "step": 10100
    },
    {
      "epoch": 0.23529001673173452,
      "grad_norm": 1.610516905784607,
      "learning_rate": 3.841520358610385e-05,
      "loss": 1.1162,
      "step": 10125
    },
    {
      "epoch": 0.2358709797360104,
      "grad_norm": 1.5029059648513794,
      "learning_rate": 3.838601979828166e-05,
      "loss": 1.15,
      "step": 10150
    },
    {
      "epoch": 0.2364519427402863,
      "grad_norm": 1.8227893114089966,
      "learning_rate": 3.835683601045947e-05,
      "loss": 1.1421,
      "step": 10175
    },
    {
      "epoch": 0.23703290574456218,
      "grad_norm": 1.5490835905075073,
      "learning_rate": 3.832765222263728e-05,
      "loss": 1.1561,
      "step": 10200
    },
    {
      "epoch": 0.23703290574456218,
      "eval_loss": 0.9767588376998901,
      "eval_runtime": 21.0093,
      "eval_samples_per_second": 190.392,
      "eval_steps_per_second": 47.598,
      "step": 10200
    },
    {
      "epoch": 0.23761386874883808,
      "grad_norm": 1.8600869178771973,
      "learning_rate": 3.829846843481509e-05,
      "loss": 1.0386,
      "step": 10225
    },
    {
      "epoch": 0.23819483175311396,
      "grad_norm": 2.227872848510742,
      "learning_rate": 3.82692846469929e-05,
      "loss": 1.3651,
      "step": 10250
    },
    {
      "epoch": 0.23877579475738986,
      "grad_norm": 3.6616365909576416,
      "learning_rate": 3.824010085917071e-05,
      "loss": 1.3242,
      "step": 10275
    },
    {
      "epoch": 0.23935675776166573,
      "grad_norm": 1.9960206747055054,
      "learning_rate": 3.821091707134853e-05,
      "loss": 1.3382,
      "step": 10300
    },
    {
      "epoch": 0.23993772076594164,
      "grad_norm": 1.1265642642974854,
      "learning_rate": 3.818173328352634e-05,
      "loss": 1.3194,
      "step": 10325
    },
    {
      "epoch": 0.2405186837702175,
      "grad_norm": 1.6244803667068481,
      "learning_rate": 3.815254949570415e-05,
      "loss": 1.2063,
      "step": 10350
    },
    {
      "epoch": 0.2410996467744934,
      "grad_norm": 2.5766537189483643,
      "learning_rate": 3.812336570788196e-05,
      "loss": 0.859,
      "step": 10375
    },
    {
      "epoch": 0.2416806097787693,
      "grad_norm": 1.9429962635040283,
      "learning_rate": 3.809418192005977e-05,
      "loss": 0.97,
      "step": 10400
    },
    {
      "epoch": 0.2416806097787693,
      "eval_loss": 0.9878916144371033,
      "eval_runtime": 20.7801,
      "eval_samples_per_second": 192.492,
      "eval_steps_per_second": 48.123,
      "step": 10400
    },
    {
      "epoch": 0.24226157278304516,
      "grad_norm": 1.3820176124572754,
      "learning_rate": 3.806499813223758e-05,
      "loss": 1.1158,
      "step": 10425
    },
    {
      "epoch": 0.24284253578732107,
      "grad_norm": 1.531424880027771,
      "learning_rate": 3.803581434441539e-05,
      "loss": 0.8712,
      "step": 10450
    },
    {
      "epoch": 0.24342349879159694,
      "grad_norm": 3.106250762939453,
      "learning_rate": 3.80066305565932e-05,
      "loss": 0.7885,
      "step": 10475
    },
    {
      "epoch": 0.24400446179587285,
      "grad_norm": 1.78531014919281,
      "learning_rate": 3.797744676877101e-05,
      "loss": 0.7805,
      "step": 10500
    },
    {
      "epoch": 0.24458542480014872,
      "grad_norm": 1.8565987348556519,
      "learning_rate": 3.794826298094882e-05,
      "loss": 0.6297,
      "step": 10525
    },
    {
      "epoch": 0.24516638780442462,
      "grad_norm": 2.0351905822753906,
      "learning_rate": 3.791907919312664e-05,
      "loss": 0.6077,
      "step": 10550
    },
    {
      "epoch": 0.2457473508087005,
      "grad_norm": 1.250356674194336,
      "learning_rate": 3.788989540530445e-05,
      "loss": 0.696,
      "step": 10575
    },
    {
      "epoch": 0.2463283138129764,
      "grad_norm": 1.6867945194244385,
      "learning_rate": 3.786071161748226e-05,
      "loss": 0.7773,
      "step": 10600
    },
    {
      "epoch": 0.2463283138129764,
      "eval_loss": 0.9714549779891968,
      "eval_runtime": 21.3299,
      "eval_samples_per_second": 187.53,
      "eval_steps_per_second": 46.883,
      "step": 10600
    },
    {
      "epoch": 0.24690927681725228,
      "grad_norm": 1.7622936964035034,
      "learning_rate": 3.783152782966007e-05,
      "loss": 0.8255,
      "step": 10625
    },
    {
      "epoch": 0.24749023982152815,
      "grad_norm": 1.4336471557617188,
      "learning_rate": 3.780234404183788e-05,
      "loss": 0.9593,
      "step": 10650
    },
    {
      "epoch": 0.24807120282580405,
      "grad_norm": 1.6109073162078857,
      "learning_rate": 3.777316025401569e-05,
      "loss": 1.1784,
      "step": 10675
    },
    {
      "epoch": 0.24865216583007993,
      "grad_norm": 2.4759933948516846,
      "learning_rate": 3.77439764661935e-05,
      "loss": 1.1869,
      "step": 10700
    },
    {
      "epoch": 0.24923312883435583,
      "grad_norm": 1.6275845766067505,
      "learning_rate": 3.771479267837131e-05,
      "loss": 1.1243,
      "step": 10725
    },
    {
      "epoch": 0.2498140918386317,
      "grad_norm": 1.3535208702087402,
      "learning_rate": 3.768560889054912e-05,
      "loss": 1.0476,
      "step": 10750
    },
    {
      "epoch": 0.2503950548429076,
      "grad_norm": 1.8132729530334473,
      "learning_rate": 3.765642510272693e-05,
      "loss": 1.1324,
      "step": 10775
    },
    {
      "epoch": 0.2509760178471835,
      "grad_norm": 1.4752188920974731,
      "learning_rate": 3.762724131490475e-05,
      "loss": 0.9099,
      "step": 10800
    },
    {
      "epoch": 0.2509760178471835,
      "eval_loss": 0.970676839351654,
      "eval_runtime": 21.6921,
      "eval_samples_per_second": 184.399,
      "eval_steps_per_second": 46.1,
      "step": 10800
    },
    {
      "epoch": 0.2515569808514594,
      "grad_norm": 2.664036750793457,
      "learning_rate": 3.759805752708256e-05,
      "loss": 1.2211,
      "step": 10825
    },
    {
      "epoch": 0.2521379438557353,
      "grad_norm": 1.6264841556549072,
      "learning_rate": 3.756887373926037e-05,
      "loss": 1.0696,
      "step": 10850
    },
    {
      "epoch": 0.25271890686001114,
      "grad_norm": 1.2282724380493164,
      "learning_rate": 3.753968995143818e-05,
      "loss": 1.4007,
      "step": 10875
    },
    {
      "epoch": 0.25329986986428704,
      "grad_norm": 1.1279436349868774,
      "learning_rate": 3.751050616361599e-05,
      "loss": 1.1563,
      "step": 10900
    },
    {
      "epoch": 0.25388083286856294,
      "grad_norm": 2.148284912109375,
      "learning_rate": 3.74813223757938e-05,
      "loss": 0.9672,
      "step": 10925
    },
    {
      "epoch": 0.2544617958728388,
      "grad_norm": 1.705172061920166,
      "learning_rate": 3.745213858797161e-05,
      "loss": 1.1172,
      "step": 10950
    },
    {
      "epoch": 0.2550427588771147,
      "grad_norm": 1.2787836790084839,
      "learning_rate": 3.742295480014942e-05,
      "loss": 0.8948,
      "step": 10975
    },
    {
      "epoch": 0.2556237218813906,
      "grad_norm": 1.593428611755371,
      "learning_rate": 3.739377101232723e-05,
      "loss": 0.8569,
      "step": 11000
    },
    {
      "epoch": 0.2556237218813906,
      "eval_loss": 0.9751132130622864,
      "eval_runtime": 21.1012,
      "eval_samples_per_second": 189.563,
      "eval_steps_per_second": 47.391,
      "step": 11000
    },
    {
      "epoch": 0.2562046848856665,
      "grad_norm": 1.4159996509552002,
      "learning_rate": 3.736458722450504e-05,
      "loss": 0.9848,
      "step": 11025
    },
    {
      "epoch": 0.25678564788994235,
      "grad_norm": 1.0966854095458984,
      "learning_rate": 3.733540343668285e-05,
      "loss": 0.9207,
      "step": 11050
    },
    {
      "epoch": 0.25736661089421825,
      "grad_norm": 1.394687533378601,
      "learning_rate": 3.730621964886067e-05,
      "loss": 1.0281,
      "step": 11075
    },
    {
      "epoch": 0.25794757389849415,
      "grad_norm": 1.318100094795227,
      "learning_rate": 3.727703586103848e-05,
      "loss": 1.0655,
      "step": 11100
    },
    {
      "epoch": 0.25852853690277006,
      "grad_norm": 1.7380110025405884,
      "learning_rate": 3.724785207321629e-05,
      "loss": 0.9364,
      "step": 11125
    },
    {
      "epoch": 0.2591094999070459,
      "grad_norm": 0.977762758731842,
      "learning_rate": 3.72186682853941e-05,
      "loss": 0.8883,
      "step": 11150
    },
    {
      "epoch": 0.2596904629113218,
      "grad_norm": 1.4100348949432373,
      "learning_rate": 3.718948449757191e-05,
      "loss": 1.0125,
      "step": 11175
    },
    {
      "epoch": 0.2602714259155977,
      "grad_norm": 2.7397372722625732,
      "learning_rate": 3.716030070974972e-05,
      "loss": 1.1998,
      "step": 11200
    },
    {
      "epoch": 0.2602714259155977,
      "eval_loss": 0.9666863083839417,
      "eval_runtime": 20.6434,
      "eval_samples_per_second": 193.767,
      "eval_steps_per_second": 48.442,
      "step": 11200
    },
    {
      "epoch": 0.26085238891987356,
      "grad_norm": 1.4190077781677246,
      "learning_rate": 3.713111692192753e-05,
      "loss": 1.658,
      "step": 11225
    },
    {
      "epoch": 0.26143335192414946,
      "grad_norm": 2.516880750656128,
      "learning_rate": 3.710193313410534e-05,
      "loss": 0.8739,
      "step": 11250
    },
    {
      "epoch": 0.26201431492842536,
      "grad_norm": 1.6244255304336548,
      "learning_rate": 3.707274934628315e-05,
      "loss": 1.1739,
      "step": 11275
    },
    {
      "epoch": 0.26259527793270127,
      "grad_norm": 2.097848892211914,
      "learning_rate": 3.704356555846096e-05,
      "loss": 1.0936,
      "step": 11300
    },
    {
      "epoch": 0.2631762409369771,
      "grad_norm": 1.894623041152954,
      "learning_rate": 3.701438177063878e-05,
      "loss": 1.8149,
      "step": 11325
    },
    {
      "epoch": 0.263757203941253,
      "grad_norm": 1.8159425258636475,
      "learning_rate": 3.698519798281659e-05,
      "loss": 1.3813,
      "step": 11350
    },
    {
      "epoch": 0.2643381669455289,
      "grad_norm": 1.5738458633422852,
      "learning_rate": 3.69560141949944e-05,
      "loss": 0.723,
      "step": 11375
    },
    {
      "epoch": 0.2649191299498048,
      "grad_norm": 1.4188463687896729,
      "learning_rate": 3.692683040717221e-05,
      "loss": 0.6816,
      "step": 11400
    },
    {
      "epoch": 0.2649191299498048,
      "eval_loss": 0.970474123954773,
      "eval_runtime": 21.2792,
      "eval_samples_per_second": 187.977,
      "eval_steps_per_second": 46.994,
      "step": 11400
    },
    {
      "epoch": 0.26550009295408067,
      "grad_norm": 1.3998249769210815,
      "learning_rate": 3.689764661935002e-05,
      "loss": 0.9751,
      "step": 11425
    },
    {
      "epoch": 0.26608105595835657,
      "grad_norm": 1.656822681427002,
      "learning_rate": 3.686846283152784e-05,
      "loss": 0.9159,
      "step": 11450
    },
    {
      "epoch": 0.2666620189626325,
      "grad_norm": 1.7640851736068726,
      "learning_rate": 3.683927904370564e-05,
      "loss": 1.2874,
      "step": 11475
    },
    {
      "epoch": 0.2672429819669083,
      "grad_norm": 1.96847665309906,
      "learning_rate": 3.681009525588345e-05,
      "loss": 1.3566,
      "step": 11500
    },
    {
      "epoch": 0.2678239449711842,
      "grad_norm": 1.3247756958007812,
      "learning_rate": 3.678091146806126e-05,
      "loss": 0.9711,
      "step": 11525
    },
    {
      "epoch": 0.2684049079754601,
      "grad_norm": 2.078995704650879,
      "learning_rate": 3.675172768023907e-05,
      "loss": 0.8177,
      "step": 11550
    },
    {
      "epoch": 0.26898587097973603,
      "grad_norm": 1.889053225517273,
      "learning_rate": 3.672254389241689e-05,
      "loss": 0.9745,
      "step": 11575
    },
    {
      "epoch": 0.2695668339840119,
      "grad_norm": 1.3023552894592285,
      "learning_rate": 3.66933601045947e-05,
      "loss": 0.682,
      "step": 11600
    },
    {
      "epoch": 0.2695668339840119,
      "eval_loss": 0.9642294645309448,
      "eval_runtime": 20.6375,
      "eval_samples_per_second": 193.822,
      "eval_steps_per_second": 48.455,
      "step": 11600
    },
    {
      "epoch": 0.2701477969882878,
      "grad_norm": 1.381256341934204,
      "learning_rate": 3.666417631677251e-05,
      "loss": 0.6601,
      "step": 11625
    },
    {
      "epoch": 0.2707287599925637,
      "grad_norm": 2.0387802124023438,
      "learning_rate": 3.663499252895032e-05,
      "loss": 0.7123,
      "step": 11650
    },
    {
      "epoch": 0.2713097229968396,
      "grad_norm": 0.923788845539093,
      "learning_rate": 3.660580874112813e-05,
      "loss": 0.8527,
      "step": 11675
    },
    {
      "epoch": 0.27189068600111543,
      "grad_norm": 1.2396082878112793,
      "learning_rate": 3.6576624953305947e-05,
      "loss": 0.8291,
      "step": 11700
    },
    {
      "epoch": 0.27247164900539134,
      "grad_norm": 1.0986623764038086,
      "learning_rate": 3.654744116548375e-05,
      "loss": 0.7166,
      "step": 11725
    },
    {
      "epoch": 0.27305261200966724,
      "grad_norm": 2.0224881172180176,
      "learning_rate": 3.651825737766156e-05,
      "loss": 0.7066,
      "step": 11750
    },
    {
      "epoch": 0.2736335750139431,
      "grad_norm": 1.536331057548523,
      "learning_rate": 3.648907358983937e-05,
      "loss": 0.71,
      "step": 11775
    },
    {
      "epoch": 0.274214538018219,
      "grad_norm": 1.1445072889328003,
      "learning_rate": 3.645988980201718e-05,
      "loss": 0.7152,
      "step": 11800
    },
    {
      "epoch": 0.274214538018219,
      "eval_loss": 0.9691796898841858,
      "eval_runtime": 20.7156,
      "eval_samples_per_second": 193.091,
      "eval_steps_per_second": 48.273,
      "step": 11800
    },
    {
      "epoch": 0.2747955010224949,
      "grad_norm": 1.4762040376663208,
      "learning_rate": 3.6430706014195e-05,
      "loss": 0.8528,
      "step": 11825
    },
    {
      "epoch": 0.2753764640267708,
      "grad_norm": 1.736741304397583,
      "learning_rate": 3.640152222637281e-05,
      "loss": 0.7218,
      "step": 11850
    },
    {
      "epoch": 0.27595742703104664,
      "grad_norm": 1.4343726634979248,
      "learning_rate": 3.637233843855062e-05,
      "loss": 0.6919,
      "step": 11875
    },
    {
      "epoch": 0.27653839003532255,
      "grad_norm": 1.3506929874420166,
      "learning_rate": 3.634315465072843e-05,
      "loss": 0.7244,
      "step": 11900
    },
    {
      "epoch": 0.27711935303959845,
      "grad_norm": 2.4569339752197266,
      "learning_rate": 3.631397086290624e-05,
      "loss": 0.774,
      "step": 11925
    },
    {
      "epoch": 0.27770031604387435,
      "grad_norm": 1.3367921113967896,
      "learning_rate": 3.6284787075084056e-05,
      "loss": 1.3292,
      "step": 11950
    },
    {
      "epoch": 0.2782812790481502,
      "grad_norm": 1.6058908700942993,
      "learning_rate": 3.6255603287261867e-05,
      "loss": 1.0338,
      "step": 11975
    },
    {
      "epoch": 0.2788622420524261,
      "grad_norm": 1.2204211950302124,
      "learning_rate": 3.622641949943967e-05,
      "loss": 1.0885,
      "step": 12000
    },
    {
      "epoch": 0.2788622420524261,
      "eval_loss": 0.9668116569519043,
      "eval_runtime": 20.5086,
      "eval_samples_per_second": 195.041,
      "eval_steps_per_second": 48.76,
      "step": 12000
    },
    {
      "epoch": 0.279443205056702,
      "grad_norm": 2.039074182510376,
      "learning_rate": 3.619723571161748e-05,
      "loss": 0.8301,
      "step": 12025
    },
    {
      "epoch": 0.28002416806097785,
      "grad_norm": 2.6227142810821533,
      "learning_rate": 3.616805192379529e-05,
      "loss": 0.7264,
      "step": 12050
    },
    {
      "epoch": 0.28060513106525375,
      "grad_norm": 2.290076732635498,
      "learning_rate": 3.613886813597311e-05,
      "loss": 0.7882,
      "step": 12075
    },
    {
      "epoch": 0.28118609406952966,
      "grad_norm": 1.5314407348632812,
      "learning_rate": 3.610968434815092e-05,
      "loss": 0.9412,
      "step": 12100
    },
    {
      "epoch": 0.28176705707380556,
      "grad_norm": 1.7339086532592773,
      "learning_rate": 3.608050056032873e-05,
      "loss": 0.9046,
      "step": 12125
    },
    {
      "epoch": 0.2823480200780814,
      "grad_norm": 1.2797526121139526,
      "learning_rate": 3.605131677250654e-05,
      "loss": 1.2364,
      "step": 12150
    },
    {
      "epoch": 0.2829289830823573,
      "grad_norm": 1.0882999897003174,
      "learning_rate": 3.602213298468435e-05,
      "loss": 1.087,
      "step": 12175
    },
    {
      "epoch": 0.2835099460866332,
      "grad_norm": 2.072777271270752,
      "learning_rate": 3.5992949196862166e-05,
      "loss": 1.218,
      "step": 12200
    },
    {
      "epoch": 0.2835099460866332,
      "eval_loss": 0.9564757943153381,
      "eval_runtime": 21.2432,
      "eval_samples_per_second": 188.295,
      "eval_steps_per_second": 47.074,
      "step": 12200
    },
    {
      "epoch": 0.2840909090909091,
      "grad_norm": 1.0990294218063354,
      "learning_rate": 3.5963765409039976e-05,
      "loss": 1.1524,
      "step": 12225
    },
    {
      "epoch": 0.28467187209518496,
      "grad_norm": 2.9597368240356445,
      "learning_rate": 3.5934581621217787e-05,
      "loss": 1.5711,
      "step": 12250
    },
    {
      "epoch": 0.28525283509946087,
      "grad_norm": 1.1020400524139404,
      "learning_rate": 3.590539783339559e-05,
      "loss": 1.3244,
      "step": 12275
    },
    {
      "epoch": 0.28583379810373677,
      "grad_norm": 1.9399312734603882,
      "learning_rate": 3.58762140455734e-05,
      "loss": 1.0173,
      "step": 12300
    },
    {
      "epoch": 0.2864147611080126,
      "grad_norm": 1.019330382347107,
      "learning_rate": 3.584703025775122e-05,
      "loss": 1.1478,
      "step": 12325
    },
    {
      "epoch": 0.2869957241122885,
      "grad_norm": 1.522986888885498,
      "learning_rate": 3.581784646992903e-05,
      "loss": 0.6653,
      "step": 12350
    },
    {
      "epoch": 0.2875766871165644,
      "grad_norm": 1.5509378910064697,
      "learning_rate": 3.578866268210684e-05,
      "loss": 1.2202,
      "step": 12375
    },
    {
      "epoch": 0.2881576501208403,
      "grad_norm": 1.3919230699539185,
      "learning_rate": 3.575947889428465e-05,
      "loss": 1.0558,
      "step": 12400
    },
    {
      "epoch": 0.2881576501208403,
      "eval_loss": 0.9576756358146667,
      "eval_runtime": 20.7028,
      "eval_samples_per_second": 193.211,
      "eval_steps_per_second": 48.303,
      "step": 12400
    },
    {
      "epoch": 0.2887386131251162,
      "grad_norm": 1.4450753927230835,
      "learning_rate": 3.573029510646246e-05,
      "loss": 1.4133,
      "step": 12425
    },
    {
      "epoch": 0.2893195761293921,
      "grad_norm": 1.7902607917785645,
      "learning_rate": 3.570111131864027e-05,
      "loss": 1.0635,
      "step": 12450
    },
    {
      "epoch": 0.289900539133668,
      "grad_norm": 1.8118990659713745,
      "learning_rate": 3.5671927530818086e-05,
      "loss": 0.9219,
      "step": 12475
    },
    {
      "epoch": 0.2904815021379439,
      "grad_norm": 1.877601146697998,
      "learning_rate": 3.5642743742995896e-05,
      "loss": 0.9304,
      "step": 12500
    },
    {
      "epoch": 0.29106246514221973,
      "grad_norm": 1.7067207098007202,
      "learning_rate": 3.5613559955173706e-05,
      "loss": 1.3024,
      "step": 12525
    },
    {
      "epoch": 0.29164342814649563,
      "grad_norm": 2.068510055541992,
      "learning_rate": 3.558437616735151e-05,
      "loss": 0.7917,
      "step": 12550
    },
    {
      "epoch": 0.29222439115077153,
      "grad_norm": 1.7319307327270508,
      "learning_rate": 3.555519237952932e-05,
      "loss": 0.5423,
      "step": 12575
    },
    {
      "epoch": 0.2928053541550474,
      "grad_norm": 2.4452033042907715,
      "learning_rate": 3.552600859170714e-05,
      "loss": 0.9286,
      "step": 12600
    },
    {
      "epoch": 0.2928053541550474,
      "eval_loss": 0.9639642834663391,
      "eval_runtime": 20.6931,
      "eval_samples_per_second": 193.301,
      "eval_steps_per_second": 48.325,
      "step": 12600
    },
    {
      "epoch": 0.2933863171593233,
      "grad_norm": 1.5831725597381592,
      "learning_rate": 3.549682480388495e-05,
      "loss": 1.2763,
      "step": 12625
    },
    {
      "epoch": 0.2939672801635992,
      "grad_norm": 2.3095693588256836,
      "learning_rate": 3.546764101606276e-05,
      "loss": 1.0798,
      "step": 12650
    },
    {
      "epoch": 0.2945482431678751,
      "grad_norm": 2.483798027038574,
      "learning_rate": 3.543845722824057e-05,
      "loss": 1.6671,
      "step": 12675
    },
    {
      "epoch": 0.29512920617215094,
      "grad_norm": 3.170832633972168,
      "learning_rate": 3.540927344041838e-05,
      "loss": 1.9696,
      "step": 12700
    },
    {
      "epoch": 0.29571016917642684,
      "grad_norm": 1.900957465171814,
      "learning_rate": 3.5380089652596196e-05,
      "loss": 1.8837,
      "step": 12725
    },
    {
      "epoch": 0.29629113218070274,
      "grad_norm": 1.2061128616333008,
      "learning_rate": 3.5350905864774006e-05,
      "loss": 1.1736,
      "step": 12750
    },
    {
      "epoch": 0.29687209518497865,
      "grad_norm": 1.7525099515914917,
      "learning_rate": 3.5321722076951816e-05,
      "loss": 1.0941,
      "step": 12775
    },
    {
      "epoch": 0.2974530581892545,
      "grad_norm": 1.7684775590896606,
      "learning_rate": 3.529253828912962e-05,
      "loss": 1.3134,
      "step": 12800
    },
    {
      "epoch": 0.2974530581892545,
      "eval_loss": 0.9706447720527649,
      "eval_runtime": 20.3561,
      "eval_samples_per_second": 196.501,
      "eval_steps_per_second": 49.125,
      "step": 12800
    },
    {
      "epoch": 0.2980340211935304,
      "grad_norm": 2.015460729598999,
      "learning_rate": 3.526335450130743e-05,
      "loss": 1.0377,
      "step": 12825
    },
    {
      "epoch": 0.2986149841978063,
      "grad_norm": 1.8859961032867432,
      "learning_rate": 3.523417071348525e-05,
      "loss": 1.2433,
      "step": 12850
    },
    {
      "epoch": 0.29919594720208215,
      "grad_norm": 1.6130096912384033,
      "learning_rate": 3.520498692566306e-05,
      "loss": 0.9762,
      "step": 12875
    },
    {
      "epoch": 0.29977691020635805,
      "grad_norm": 1.3844972848892212,
      "learning_rate": 3.517580313784087e-05,
      "loss": 0.5974,
      "step": 12900
    },
    {
      "epoch": 0.30035787321063395,
      "grad_norm": 1.7297745943069458,
      "learning_rate": 3.514661935001868e-05,
      "loss": 0.3922,
      "step": 12925
    },
    {
      "epoch": 0.30093883621490986,
      "grad_norm": 2.561933755874634,
      "learning_rate": 3.511743556219649e-05,
      "loss": 0.3654,
      "step": 12950
    },
    {
      "epoch": 0.3015197992191857,
      "grad_norm": 1.6257531642913818,
      "learning_rate": 3.5088251774374305e-05,
      "loss": 0.8615,
      "step": 12975
    },
    {
      "epoch": 0.3021007622234616,
      "grad_norm": 1.1427514553070068,
      "learning_rate": 3.5059067986552116e-05,
      "loss": 0.7917,
      "step": 13000
    },
    {
      "epoch": 0.3021007622234616,
      "eval_loss": 0.9563756585121155,
      "eval_runtime": 20.4811,
      "eval_samples_per_second": 195.302,
      "eval_steps_per_second": 48.826,
      "step": 13000
    },
    {
      "epoch": 0.3026817252277375,
      "grad_norm": 1.208101511001587,
      "learning_rate": 3.5029884198729926e-05,
      "loss": 0.7565,
      "step": 13025
    },
    {
      "epoch": 0.3032626882320134,
      "grad_norm": 1.4128658771514893,
      "learning_rate": 3.5000700410907736e-05,
      "loss": 0.7401,
      "step": 13050
    },
    {
      "epoch": 0.30384365123628926,
      "grad_norm": 1.6207330226898193,
      "learning_rate": 3.497151662308554e-05,
      "loss": 0.7771,
      "step": 13075
    },
    {
      "epoch": 0.30442461424056516,
      "grad_norm": 1.092152714729309,
      "learning_rate": 3.494233283526336e-05,
      "loss": 0.7959,
      "step": 13100
    },
    {
      "epoch": 0.30500557724484106,
      "grad_norm": 1.7447575330734253,
      "learning_rate": 3.491314904744117e-05,
      "loss": 0.8335,
      "step": 13125
    },
    {
      "epoch": 0.3055865402491169,
      "grad_norm": 1.3964232206344604,
      "learning_rate": 3.488396525961898e-05,
      "loss": 0.826,
      "step": 13150
    },
    {
      "epoch": 0.3061675032533928,
      "grad_norm": 1.212088704109192,
      "learning_rate": 3.485478147179679e-05,
      "loss": 0.8682,
      "step": 13175
    },
    {
      "epoch": 0.3067484662576687,
      "grad_norm": 1.142883539199829,
      "learning_rate": 3.48255976839746e-05,
      "loss": 0.8592,
      "step": 13200
    },
    {
      "epoch": 0.3067484662576687,
      "eval_loss": 0.9560070633888245,
      "eval_runtime": 21.1901,
      "eval_samples_per_second": 188.767,
      "eval_steps_per_second": 47.192,
      "step": 13200
    },
    {
      "epoch": 0.3073294292619446,
      "grad_norm": NaN,
      "learning_rate": 3.4796413896152415e-05,
      "loss": 0.982,
      "step": 13225
    },
    {
      "epoch": 0.30791039226622047,
      "grad_norm": 1.1351865530014038,
      "learning_rate": 3.4767230108330225e-05,
      "loss": 0.9171,
      "step": 13250
    },
    {
      "epoch": 0.30849135527049637,
      "grad_norm": 1.552597999572754,
      "learning_rate": 3.4738046320508036e-05,
      "loss": 0.8724,
      "step": 13275
    },
    {
      "epoch": 0.3090723182747723,
      "grad_norm": 1.130171537399292,
      "learning_rate": 3.4708862532685846e-05,
      "loss": 1.1144,
      "step": 13300
    },
    {
      "epoch": 0.3096532812790482,
      "grad_norm": 1.6187163591384888,
      "learning_rate": 3.4679678744863656e-05,
      "loss": 1.1564,
      "step": 13325
    },
    {
      "epoch": 0.310234244283324,
      "grad_norm": 1.8426710367202759,
      "learning_rate": 3.4650494957041466e-05,
      "loss": 1.0648,
      "step": 13350
    },
    {
      "epoch": 0.3108152072875999,
      "grad_norm": 1.4191067218780518,
      "learning_rate": 3.462131116921928e-05,
      "loss": 1.1895,
      "step": 13375
    },
    {
      "epoch": 0.31139617029187583,
      "grad_norm": 1.6811753511428833,
      "learning_rate": 3.459212738139709e-05,
      "loss": 1.6776,
      "step": 13400
    },
    {
      "epoch": 0.31139617029187583,
      "eval_loss": 0.9578102231025696,
      "eval_runtime": 20.5694,
      "eval_samples_per_second": 194.463,
      "eval_steps_per_second": 48.616,
      "step": 13400
    },
    {
      "epoch": 0.3119771332961517,
      "grad_norm": 1.2613306045532227,
      "learning_rate": 3.45629435935749e-05,
      "loss": 1.8231,
      "step": 13425
    },
    {
      "epoch": 0.3125580963004276,
      "grad_norm": 2.21655535697937,
      "learning_rate": 3.453375980575271e-05,
      "loss": 1.0846,
      "step": 13450
    },
    {
      "epoch": 0.3131390593047035,
      "grad_norm": 1.49484384059906,
      "learning_rate": 3.4504576017930525e-05,
      "loss": 1.0393,
      "step": 13475
    },
    {
      "epoch": 0.3137200223089794,
      "grad_norm": 2.312910318374634,
      "learning_rate": 3.4475392230108335e-05,
      "loss": 0.9783,
      "step": 13500
    },
    {
      "epoch": 0.31430098531325523,
      "grad_norm": 1.8782932758331299,
      "learning_rate": 3.4446208442286145e-05,
      "loss": 1.0783,
      "step": 13525
    },
    {
      "epoch": 0.31488194831753114,
      "grad_norm": 2.0521628856658936,
      "learning_rate": 3.4417024654463956e-05,
      "loss": 1.0597,
      "step": 13550
    },
    {
      "epoch": 0.31546291132180704,
      "grad_norm": 2.077845573425293,
      "learning_rate": 3.4387840866641766e-05,
      "loss": 1.4406,
      "step": 13575
    },
    {
      "epoch": 0.31604387432608294,
      "grad_norm": 3.7750637531280518,
      "learning_rate": 3.4358657078819576e-05,
      "loss": 1.4156,
      "step": 13600
    },
    {
      "epoch": 0.31604387432608294,
      "eval_loss": 0.9537913799285889,
      "eval_runtime": 20.5152,
      "eval_samples_per_second": 194.978,
      "eval_steps_per_second": 48.744,
      "step": 13600
    },
    {
      "epoch": 0.3166248373303588,
      "grad_norm": 2.0485637187957764,
      "learning_rate": 3.4329473290997386e-05,
      "loss": 1.0127,
      "step": 13625
    },
    {
      "epoch": 0.3172058003346347,
      "grad_norm": 1.1417505741119385,
      "learning_rate": 3.43002895031752e-05,
      "loss": 1.2403,
      "step": 13650
    },
    {
      "epoch": 0.3177867633389106,
      "grad_norm": 2.4040496349334717,
      "learning_rate": 3.427110571535301e-05,
      "loss": 1.349,
      "step": 13675
    },
    {
      "epoch": 0.31836772634318644,
      "grad_norm": 1.7379895448684692,
      "learning_rate": 3.424192192753082e-05,
      "loss": 1.4618,
      "step": 13700
    },
    {
      "epoch": 0.31894868934746234,
      "grad_norm": 1.7618892192840576,
      "learning_rate": 3.4212738139708634e-05,
      "loss": 2.0715,
      "step": 13725
    },
    {
      "epoch": 0.31952965235173825,
      "grad_norm": 1.1788407564163208,
      "learning_rate": 3.4183554351886445e-05,
      "loss": 1.2123,
      "step": 13750
    },
    {
      "epoch": 0.32011061535601415,
      "grad_norm": 1.8463364839553833,
      "learning_rate": 3.4154370564064255e-05,
      "loss": 1.4812,
      "step": 13775
    },
    {
      "epoch": 0.32069157836029,
      "grad_norm": 1.5562090873718262,
      "learning_rate": 3.4125186776242065e-05,
      "loss": 1.0365,
      "step": 13800
    },
    {
      "epoch": 0.32069157836029,
      "eval_loss": 0.9501974582672119,
      "eval_runtime": 20.5208,
      "eval_samples_per_second": 194.924,
      "eval_steps_per_second": 48.731,
      "step": 13800
    },
    {
      "epoch": 0.3212725413645659,
      "grad_norm": 2.2476933002471924,
      "learning_rate": 3.4096002988419875e-05,
      "loss": 0.7014,
      "step": 13825
    },
    {
      "epoch": 0.3218535043688418,
      "grad_norm": 1.2057194709777832,
      "learning_rate": 3.4066819200597686e-05,
      "loss": 0.5499,
      "step": 13850
    },
    {
      "epoch": 0.3224344673731177,
      "grad_norm": 2.2124202251434326,
      "learning_rate": 3.4037635412775496e-05,
      "loss": 0.7668,
      "step": 13875
    },
    {
      "epoch": 0.32301543037739355,
      "grad_norm": 1.6540364027023315,
      "learning_rate": 3.4008451624953306e-05,
      "loss": 0.322,
      "step": 13900
    },
    {
      "epoch": 0.32359639338166946,
      "grad_norm": 1.221332311630249,
      "learning_rate": 3.397926783713112e-05,
      "loss": 0.33,
      "step": 13925
    },
    {
      "epoch": 0.32417735638594536,
      "grad_norm": 2.2868399620056152,
      "learning_rate": 3.395008404930893e-05,
      "loss": 1.0949,
      "step": 13950
    },
    {
      "epoch": 0.3247583193902212,
      "grad_norm": 1.9119696617126465,
      "learning_rate": 3.3920900261486744e-05,
      "loss": 1.1618,
      "step": 13975
    },
    {
      "epoch": 0.3253392823944971,
      "grad_norm": 1.9418267011642456,
      "learning_rate": 3.3891716473664554e-05,
      "loss": 1.0698,
      "step": 14000
    },
    {
      "epoch": 0.3253392823944971,
      "eval_loss": 0.9580422639846802,
      "eval_runtime": 20.6521,
      "eval_samples_per_second": 193.684,
      "eval_steps_per_second": 48.421,
      "step": 14000
    },
    {
      "epoch": 0.325920245398773,
      "grad_norm": 1.60044264793396,
      "learning_rate": 3.3862532685842365e-05,
      "loss": 1.0722,
      "step": 14025
    },
    {
      "epoch": 0.3265012084030489,
      "grad_norm": 1.7768056392669678,
      "learning_rate": 3.3833348898020175e-05,
      "loss": 0.8778,
      "step": 14050
    },
    {
      "epoch": 0.32708217140732476,
      "grad_norm": 1.4938571453094482,
      "learning_rate": 3.3804165110197985e-05,
      "loss": 0.9837,
      "step": 14075
    },
    {
      "epoch": 0.32766313441160066,
      "grad_norm": 1.490832805633545,
      "learning_rate": 3.3774981322375795e-05,
      "loss": 0.3682,
      "step": 14100
    },
    {
      "epoch": 0.32824409741587657,
      "grad_norm": 3.3807079792022705,
      "learning_rate": 3.3745797534553606e-05,
      "loss": 0.1098,
      "step": 14125
    },
    {
      "epoch": 0.32882506042015247,
      "grad_norm": 2.393537759780884,
      "learning_rate": 3.3716613746731416e-05,
      "loss": 0.896,
      "step": 14150
    },
    {
      "epoch": 0.3294060234244283,
      "grad_norm": 1.9867247343063354,
      "learning_rate": 3.3687429958909226e-05,
      "loss": 0.9588,
      "step": 14175
    },
    {
      "epoch": 0.3299869864287042,
      "grad_norm": 3.810366630554199,
      "learning_rate": 3.365824617108704e-05,
      "loss": 1.0961,
      "step": 14200
    },
    {
      "epoch": 0.3299869864287042,
      "eval_loss": 0.9585598707199097,
      "eval_runtime": 21.0099,
      "eval_samples_per_second": 190.387,
      "eval_steps_per_second": 47.597,
      "step": 14200
    },
    {
      "epoch": 0.3305679494329801,
      "grad_norm": 1.692258358001709,
      "learning_rate": 3.362906238326485e-05,
      "loss": 0.8908,
      "step": 14225
    },
    {
      "epoch": 0.33114891243725597,
      "grad_norm": 1.7769681215286255,
      "learning_rate": 3.3599878595442664e-05,
      "loss": 0.9659,
      "step": 14250
    },
    {
      "epoch": 0.3317298754415319,
      "grad_norm": 1.3804160356521606,
      "learning_rate": 3.3570694807620474e-05,
      "loss": 1.1343,
      "step": 14275
    },
    {
      "epoch": 0.3323108384458078,
      "grad_norm": 1.0605288743972778,
      "learning_rate": 3.3541511019798285e-05,
      "loss": 0.9542,
      "step": 14300
    },
    {
      "epoch": 0.3328918014500837,
      "grad_norm": 1.8134891986846924,
      "learning_rate": 3.3512327231976095e-05,
      "loss": 1.6029,
      "step": 14325
    },
    {
      "epoch": 1.0001394311210263,
      "grad_norm": 1.5090457201004028,
      "learning_rate": 3.3483143444153905e-05,
      "loss": 1.449,
      "step": 14350
    },
    {
      "epoch": 1.000720394125302,
      "grad_norm": 2.229785680770874,
      "learning_rate": 3.3453959656331715e-05,
      "loss": 0.9023,
      "step": 14375
    },
    {
      "epoch": 1.001301357129578,
      "grad_norm": 1.7835832834243774,
      "learning_rate": 3.3424775868509526e-05,
      "loss": 1.1165,
      "step": 14400
    },
    {
      "epoch": 1.001301357129578,
      "eval_loss": 0.9472520351409912,
      "eval_runtime": 20.5219,
      "eval_samples_per_second": 194.914,
      "eval_steps_per_second": 48.729,
      "step": 14400
    },
    {
      "epoch": 1.0018823201338538,
      "grad_norm": 1.3180065155029297,
      "learning_rate": 3.3395592080687336e-05,
      "loss": 1.0852,
      "step": 14425
    },
    {
      "epoch": 1.0024632831381297,
      "grad_norm": 2.3097193241119385,
      "learning_rate": 3.3366408292865146e-05,
      "loss": 0.9931,
      "step": 14450
    },
    {
      "epoch": 1.0030442461424056,
      "grad_norm": 2.975618839263916,
      "learning_rate": 3.3337224505042957e-05,
      "loss": 0.5138,
      "step": 14475
    },
    {
      "epoch": 1.0036252091466815,
      "grad_norm": 1.7137455940246582,
      "learning_rate": 3.3308040717220774e-05,
      "loss": 0.5466,
      "step": 14500
    },
    {
      "epoch": 1.0042061721509574,
      "grad_norm": 1.2715916633605957,
      "learning_rate": 3.3278856929398584e-05,
      "loss": 0.7755,
      "step": 14525
    },
    {
      "epoch": 1.0047871351552333,
      "grad_norm": 1.5734394788742065,
      "learning_rate": 3.3249673141576394e-05,
      "loss": 1.1581,
      "step": 14550
    },
    {
      "epoch": 1.0053680981595092,
      "grad_norm": 1.8602310419082642,
      "learning_rate": 3.3220489353754205e-05,
      "loss": 1.2205,
      "step": 14575
    },
    {
      "epoch": 1.0059490611637851,
      "grad_norm": 2.253910541534424,
      "learning_rate": 3.3191305565932015e-05,
      "loss": 1.1242,
      "step": 14600
    },
    {
      "epoch": 1.0059490611637851,
      "eval_loss": 0.9513230919837952,
      "eval_runtime": 20.5057,
      "eval_samples_per_second": 195.068,
      "eval_steps_per_second": 48.767,
      "step": 14600
    },
    {
      "epoch": 1.006530024168061,
      "grad_norm": 2.17911434173584,
      "learning_rate": 3.3162121778109825e-05,
      "loss": 1.1883,
      "step": 14625
    },
    {
      "epoch": 1.007110987172337,
      "grad_norm": 1.497233510017395,
      "learning_rate": 3.3132937990287635e-05,
      "loss": 1.0968,
      "step": 14650
    },
    {
      "epoch": 1.0076919501766128,
      "grad_norm": 1.293662428855896,
      "learning_rate": 3.3103754202465446e-05,
      "loss": 1.0966,
      "step": 14675
    },
    {
      "epoch": 1.0082729131808887,
      "grad_norm": 2.517414093017578,
      "learning_rate": 3.3074570414643256e-05,
      "loss": 1.257,
      "step": 14700
    },
    {
      "epoch": 1.0088538761851644,
      "grad_norm": 1.2048231363296509,
      "learning_rate": 3.3045386626821066e-05,
      "loss": 0.8109,
      "step": 14725
    },
    {
      "epoch": 1.0094348391894403,
      "grad_norm": 2.3162660598754883,
      "learning_rate": 3.301620283899888e-05,
      "loss": 0.6377,
      "step": 14750
    },
    {
      "epoch": 1.0100158021937162,
      "grad_norm": 2.303786277770996,
      "learning_rate": 3.2987019051176694e-05,
      "loss": 0.7671,
      "step": 14775
    },
    {
      "epoch": 1.0105967651979921,
      "grad_norm": 1.8424694538116455,
      "learning_rate": 3.2957835263354504e-05,
      "loss": 0.8375,
      "step": 14800
    },
    {
      "epoch": 1.0105967651979921,
      "eval_loss": 0.9561255574226379,
      "eval_runtime": 20.7031,
      "eval_samples_per_second": 193.208,
      "eval_steps_per_second": 48.302,
      "step": 14800
    },
    {
      "epoch": 1.011177728202268,
      "grad_norm": 1.852622151374817,
      "learning_rate": 3.2928651475532314e-05,
      "loss": 1.7591,
      "step": 14825
    },
    {
      "epoch": 1.011758691206544,
      "grad_norm": 2.040907621383667,
      "learning_rate": 3.2899467687710125e-05,
      "loss": 1.7291,
      "step": 14850
    },
    {
      "epoch": 1.0123396542108198,
      "grad_norm": 1.877610206604004,
      "learning_rate": 3.2870283899887935e-05,
      "loss": 1.6665,
      "step": 14875
    },
    {
      "epoch": 1.0129206172150957,
      "grad_norm": 3.6274962425231934,
      "learning_rate": 3.2841100112065745e-05,
      "loss": 1.6358,
      "step": 14900
    },
    {
      "epoch": 1.0135015802193716,
      "grad_norm": 1.844580888748169,
      "learning_rate": 3.2811916324243555e-05,
      "loss": 1.047,
      "step": 14925
    },
    {
      "epoch": 1.0140825432236475,
      "grad_norm": 2.2996766567230225,
      "learning_rate": 3.2782732536421366e-05,
      "loss": 1.1431,
      "step": 14950
    },
    {
      "epoch": 1.0146635062279235,
      "grad_norm": 1.105459451675415,
      "learning_rate": 3.2753548748599176e-05,
      "loss": 1.3332,
      "step": 14975
    },
    {
      "epoch": 1.0152444692321994,
      "grad_norm": 2.353863000869751,
      "learning_rate": 3.272436496077699e-05,
      "loss": 1.0888,
      "step": 15000
    },
    {
      "epoch": 1.0152444692321994,
      "eval_loss": 0.9410144090652466,
      "eval_runtime": 20.7099,
      "eval_samples_per_second": 193.144,
      "eval_steps_per_second": 48.286,
      "step": 15000
    },
    {
      "epoch": 1.0158254322364753,
      "grad_norm": 1.9829376935958862,
      "learning_rate": 3.26951811729548e-05,
      "loss": 1.3278,
      "step": 15025
    },
    {
      "epoch": 1.0164063952407512,
      "grad_norm": 1.152193307876587,
      "learning_rate": 3.2665997385132614e-05,
      "loss": 1.0794,
      "step": 15050
    },
    {
      "epoch": 1.016987358245027,
      "grad_norm": 2.4584386348724365,
      "learning_rate": 3.2636813597310424e-05,
      "loss": 0.6123,
      "step": 15075
    },
    {
      "epoch": 1.0175683212493027,
      "grad_norm": 2.3609018325805664,
      "learning_rate": 3.2607629809488234e-05,
      "loss": 0.5648,
      "step": 15100
    },
    {
      "epoch": 1.0181492842535786,
      "grad_norm": 1.795565128326416,
      "learning_rate": 3.257844602166605e-05,
      "loss": 0.7052,
      "step": 15125
    },
    {
      "epoch": 1.0187302472578545,
      "grad_norm": 1.0693604946136475,
      "learning_rate": 3.2549262233843855e-05,
      "loss": 0.7278,
      "step": 15150
    },
    {
      "epoch": 1.0193112102621305,
      "grad_norm": 0.9863396286964417,
      "learning_rate": 3.2520078446021665e-05,
      "loss": 0.7344,
      "step": 15175
    },
    {
      "epoch": 1.0198921732664064,
      "grad_norm": 1.732486605644226,
      "learning_rate": 3.2490894658199475e-05,
      "loss": 0.8889,
      "step": 15200
    },
    {
      "epoch": 1.0198921732664064,
      "eval_loss": 0.943551778793335,
      "eval_runtime": 20.5816,
      "eval_samples_per_second": 194.349,
      "eval_steps_per_second": 48.587,
      "step": 15200
    },
    {
      "epoch": 1.0204731362706823,
      "grad_norm": 1.5924643278121948,
      "learning_rate": 3.2461710870377286e-05,
      "loss": 0.875,
      "step": 15225
    },
    {
      "epoch": 1.0210540992749582,
      "grad_norm": 1.5269578695297241,
      "learning_rate": 3.24325270825551e-05,
      "loss": 0.9266,
      "step": 15250
    },
    {
      "epoch": 1.021635062279234,
      "grad_norm": 3.062375545501709,
      "learning_rate": 3.240334329473291e-05,
      "loss": 1.5892,
      "step": 15275
    },
    {
      "epoch": 1.02221602528351,
      "grad_norm": 2.234961748123169,
      "learning_rate": 3.237415950691072e-05,
      "loss": 1.2579,
      "step": 15300
    },
    {
      "epoch": 1.0227969882877859,
      "grad_norm": 2.144026756286621,
      "learning_rate": 3.2344975719088534e-05,
      "loss": 1.0737,
      "step": 15325
    },
    {
      "epoch": 1.0233779512920618,
      "grad_norm": 1.450250506401062,
      "learning_rate": 3.2315791931266344e-05,
      "loss": 0.838,
      "step": 15350
    },
    {
      "epoch": 1.0239589142963377,
      "grad_norm": 2.111290693283081,
      "learning_rate": 3.228660814344416e-05,
      "loss": 0.9338,
      "step": 15375
    },
    {
      "epoch": 1.0245398773006136,
      "grad_norm": 1.3107788562774658,
      "learning_rate": 3.225742435562197e-05,
      "loss": 0.9854,
      "step": 15400
    },
    {
      "epoch": 1.0245398773006136,
      "eval_loss": 0.9482030272483826,
      "eval_runtime": 20.7173,
      "eval_samples_per_second": 193.076,
      "eval_steps_per_second": 48.269,
      "step": 15400
    },
    {
      "epoch": 1.0251208403048895,
      "grad_norm": 1.642775535583496,
      "learning_rate": 3.2228240567799775e-05,
      "loss": 0.9568,
      "step": 15425
    },
    {
      "epoch": 1.0257018033091652,
      "grad_norm": 1.8140414953231812,
      "learning_rate": 3.2199056779977585e-05,
      "loss": 0.9022,
      "step": 15450
    },
    {
      "epoch": 1.026282766313441,
      "grad_norm": 1.326194167137146,
      "learning_rate": 3.2169872992155395e-05,
      "loss": 1.1323,
      "step": 15475
    },
    {
      "epoch": 1.026863729317717,
      "grad_norm": 2.6990506649017334,
      "learning_rate": 3.214068920433321e-05,
      "loss": 0.9458,
      "step": 15500
    },
    {
      "epoch": 1.0274446923219929,
      "grad_norm": 2.066728115081787,
      "learning_rate": 3.211150541651102e-05,
      "loss": 0.4548,
      "step": 15525
    },
    {
      "epoch": 1.0280256553262688,
      "grad_norm": 1.7390387058258057,
      "learning_rate": 3.208232162868883e-05,
      "loss": 0.4204,
      "step": 15550
    },
    {
      "epoch": 1.0286066183305447,
      "grad_norm": 1.7384496927261353,
      "learning_rate": 3.205313784086664e-05,
      "loss": 0.2847,
      "step": 15575
    },
    {
      "epoch": 1.0291875813348206,
      "grad_norm": 2.5667641162872314,
      "learning_rate": 3.2023954053044454e-05,
      "loss": 1.2572,
      "step": 15600
    },
    {
      "epoch": 1.0291875813348206,
      "eval_loss": 0.9583905935287476,
      "eval_runtime": 21.0717,
      "eval_samples_per_second": 189.828,
      "eval_steps_per_second": 47.457,
      "step": 15600
    },
    {
      "epoch": 1.0297685443390965,
      "grad_norm": 1.7838547229766846,
      "learning_rate": 3.1994770265222264e-05,
      "loss": 1.2583,
      "step": 15625
    },
    {
      "epoch": 1.0303495073433724,
      "grad_norm": 2.688478946685791,
      "learning_rate": 3.196558647740008e-05,
      "loss": 1.2659,
      "step": 15650
    },
    {
      "epoch": 1.0309304703476483,
      "grad_norm": 1.7636570930480957,
      "learning_rate": 3.1936402689577884e-05,
      "loss": 1.4134,
      "step": 15675
    },
    {
      "epoch": 1.0315114333519242,
      "grad_norm": 1.389121413230896,
      "learning_rate": 3.1907218901755695e-05,
      "loss": 0.9497,
      "step": 15700
    },
    {
      "epoch": 1.0320923963562,
      "grad_norm": 11.36617660522461,
      "learning_rate": 3.1878035113933505e-05,
      "loss": 0.7931,
      "step": 15725
    },
    {
      "epoch": 1.032673359360476,
      "grad_norm": 1.1343475580215454,
      "learning_rate": 3.1848851326111315e-05,
      "loss": 0.7679,
      "step": 15750
    },
    {
      "epoch": 1.033254322364752,
      "grad_norm": 1.854909896850586,
      "learning_rate": 3.181966753828913e-05,
      "loss": 1.129,
      "step": 15775
    },
    {
      "epoch": 1.0338352853690278,
      "grad_norm": 1.3052318096160889,
      "learning_rate": 3.179048375046694e-05,
      "loss": 1.0652,
      "step": 15800
    },
    {
      "epoch": 1.0338352853690278,
      "eval_loss": 0.9434937834739685,
      "eval_runtime": 20.6939,
      "eval_samples_per_second": 193.293,
      "eval_steps_per_second": 48.323,
      "step": 15800
    },
    {
      "epoch": 1.0344162483733035,
      "grad_norm": 0.948228120803833,
      "learning_rate": 3.176129996264475e-05,
      "loss": 0.9826,
      "step": 15825
    },
    {
      "epoch": 1.0349972113775794,
      "grad_norm": 2.0746726989746094,
      "learning_rate": 3.173211617482256e-05,
      "loss": 0.8671,
      "step": 15850
    },
    {
      "epoch": 1.0355781743818553,
      "grad_norm": 1.2751779556274414,
      "learning_rate": 3.1702932387000374e-05,
      "loss": 0.9253,
      "step": 15875
    },
    {
      "epoch": 1.0361591373861312,
      "grad_norm": 1.6702888011932373,
      "learning_rate": 3.167374859917819e-05,
      "loss": 1.0927,
      "step": 15900
    },
    {
      "epoch": 1.036740100390407,
      "grad_norm": 1.3104150295257568,
      "learning_rate": 3.1644564811356e-05,
      "loss": 0.9481,
      "step": 15925
    },
    {
      "epoch": 1.037321063394683,
      "grad_norm": 1.1182904243469238,
      "learning_rate": 3.1615381023533804e-05,
      "loss": 0.7393,
      "step": 15950
    },
    {
      "epoch": 1.037902026398959,
      "grad_norm": 1.276931881904602,
      "learning_rate": 3.1586197235711615e-05,
      "loss": 0.7129,
      "step": 15975
    },
    {
      "epoch": 1.0384829894032348,
      "grad_norm": 2.355463981628418,
      "learning_rate": 3.1557013447889425e-05,
      "loss": 0.9248,
      "step": 16000
    },
    {
      "epoch": 1.0384829894032348,
      "eval_loss": 0.9452726244926453,
      "eval_runtime": 20.6347,
      "eval_samples_per_second": 193.848,
      "eval_steps_per_second": 48.462,
      "step": 16000
    },
    {
      "epoch": 1.0390639524075107,
      "grad_norm": 1.2594150304794312,
      "learning_rate": 3.152782966006724e-05,
      "loss": 1.4983,
      "step": 16025
    },
    {
      "epoch": 1.0396449154117866,
      "grad_norm": 2.5380146503448486,
      "learning_rate": 3.149864587224505e-05,
      "loss": 0.9146,
      "step": 16050
    },
    {
      "epoch": 1.0402258784160625,
      "grad_norm": 1.3336199522018433,
      "learning_rate": 3.146946208442286e-05,
      "loss": 0.7568,
      "step": 16075
    },
    {
      "epoch": 1.0408068414203384,
      "grad_norm": 2.5338821411132812,
      "learning_rate": 3.144027829660067e-05,
      "loss": 0.9771,
      "step": 16100
    },
    {
      "epoch": 1.0413878044246143,
      "grad_norm": 1.3794193267822266,
      "learning_rate": 3.141109450877848e-05,
      "loss": 1.1797,
      "step": 16125
    },
    {
      "epoch": 1.0419687674288902,
      "grad_norm": 2.724309206008911,
      "learning_rate": 3.13819107209563e-05,
      "loss": 1.0502,
      "step": 16150
    },
    {
      "epoch": 1.0425497304331661,
      "grad_norm": 3.039137125015259,
      "learning_rate": 3.135272693313411e-05,
      "loss": 1.4346,
      "step": 16175
    },
    {
      "epoch": 1.0431306934374418,
      "grad_norm": 1.937546730041504,
      "learning_rate": 3.132354314531192e-05,
      "loss": 1.262,
      "step": 16200
    },
    {
      "epoch": 1.0431306934374418,
      "eval_loss": 0.9466952085494995,
      "eval_runtime": 20.7004,
      "eval_samples_per_second": 193.233,
      "eval_steps_per_second": 48.308,
      "step": 16200
    },
    {
      "epoch": 1.0437116564417177,
      "grad_norm": 2.6169228553771973,
      "learning_rate": 3.1294359357489724e-05,
      "loss": 1.0841,
      "step": 16225
    },
    {
      "epoch": 1.0442926194459936,
      "grad_norm": 1.665091872215271,
      "learning_rate": 3.1265175569667535e-05,
      "loss": 0.9787,
      "step": 16250
    },
    {
      "epoch": 1.0448735824502695,
      "grad_norm": 1.597328782081604,
      "learning_rate": 3.123599178184535e-05,
      "loss": 1.3224,
      "step": 16275
    },
    {
      "epoch": 1.0454545454545454,
      "grad_norm": 1.20295250415802,
      "learning_rate": 3.120680799402316e-05,
      "loss": 1.0605,
      "step": 16300
    },
    {
      "epoch": 1.0460355084588213,
      "grad_norm": 2.9447789192199707,
      "learning_rate": 3.117762420620097e-05,
      "loss": 1.1879,
      "step": 16325
    },
    {
      "epoch": 1.0466164714630972,
      "grad_norm": 1.3183963298797607,
      "learning_rate": 3.114844041837878e-05,
      "loss": 1.1583,
      "step": 16350
    },
    {
      "epoch": 1.0471974344673731,
      "grad_norm": 1.6611332893371582,
      "learning_rate": 3.111925663055659e-05,
      "loss": 1.0117,
      "step": 16375
    },
    {
      "epoch": 1.047778397471649,
      "grad_norm": 1.631567120552063,
      "learning_rate": 3.109007284273441e-05,
      "loss": 1.1472,
      "step": 16400
    },
    {
      "epoch": 1.047778397471649,
      "eval_loss": 0.9378876090049744,
      "eval_runtime": 20.6076,
      "eval_samples_per_second": 194.103,
      "eval_steps_per_second": 48.526,
      "step": 16400
    },
    {
      "epoch": 1.048359360475925,
      "grad_norm": 2.103227376937866,
      "learning_rate": 3.106088905491222e-05,
      "loss": 1.3944,
      "step": 16425
    },
    {
      "epoch": 1.0489403234802008,
      "grad_norm": 2.0744948387145996,
      "learning_rate": 3.103170526709003e-05,
      "loss": 1.4999,
      "step": 16450
    },
    {
      "epoch": 1.0495212864844767,
      "grad_norm": 2.0266013145446777,
      "learning_rate": 3.100252147926784e-05,
      "loss": 1.0933,
      "step": 16475
    },
    {
      "epoch": 1.0501022494887526,
      "grad_norm": 1.2762104272842407,
      "learning_rate": 3.0973337691445644e-05,
      "loss": 1.3132,
      "step": 16500
    },
    {
      "epoch": 1.0506832124930285,
      "grad_norm": 1.4432629346847534,
      "learning_rate": 3.094415390362346e-05,
      "loss": 1.2891,
      "step": 16525
    },
    {
      "epoch": 1.0512641754973044,
      "grad_norm": 1.8708394765853882,
      "learning_rate": 3.091497011580127e-05,
      "loss": 1.3923,
      "step": 16550
    },
    {
      "epoch": 1.0518451385015801,
      "grad_norm": 1.5087127685546875,
      "learning_rate": 3.088578632797908e-05,
      "loss": 1.1996,
      "step": 16575
    },
    {
      "epoch": 1.052426101505856,
      "grad_norm": 1.1431735754013062,
      "learning_rate": 3.085660254015689e-05,
      "loss": 1.3629,
      "step": 16600
    },
    {
      "epoch": 1.052426101505856,
      "eval_loss": 0.9284904599189758,
      "eval_runtime": 21.5154,
      "eval_samples_per_second": 185.913,
      "eval_steps_per_second": 46.478,
      "step": 16600
    },
    {
      "epoch": 1.053007064510132,
      "grad_norm": 1.5326189994812012,
      "learning_rate": 3.08274187523347e-05,
      "loss": 1.0003,
      "step": 16625
    },
    {
      "epoch": 1.0535880275144078,
      "grad_norm": 1.8946791887283325,
      "learning_rate": 3.079823496451252e-05,
      "loss": 1.4798,
      "step": 16650
    },
    {
      "epoch": 1.0541689905186837,
      "grad_norm": 1.7122211456298828,
      "learning_rate": 3.076905117669033e-05,
      "loss": 1.7481,
      "step": 16675
    },
    {
      "epoch": 1.0547499535229596,
      "grad_norm": 1.027683973312378,
      "learning_rate": 3.073986738886814e-05,
      "loss": 1.5305,
      "step": 16700
    },
    {
      "epoch": 1.0553309165272355,
      "grad_norm": 1.2594643831253052,
      "learning_rate": 3.071068360104595e-05,
      "loss": 1.2503,
      "step": 16725
    },
    {
      "epoch": 1.0559118795315114,
      "grad_norm": 1.606475591659546,
      "learning_rate": 3.0681499813223754e-05,
      "loss": 1.2512,
      "step": 16750
    },
    {
      "epoch": 1.0564928425357873,
      "grad_norm": 1.558822751045227,
      "learning_rate": 3.065231602540157e-05,
      "loss": 1.0206,
      "step": 16775
    },
    {
      "epoch": 1.0570738055400632,
      "grad_norm": 1.9626771211624146,
      "learning_rate": 3.062313223757938e-05,
      "loss": 0.9114,
      "step": 16800
    },
    {
      "epoch": 1.0570738055400632,
      "eval_loss": 0.9330945014953613,
      "eval_runtime": 20.7195,
      "eval_samples_per_second": 193.055,
      "eval_steps_per_second": 48.264,
      "step": 16800
    },
    {
      "epoch": 1.0576547685443392,
      "grad_norm": 1.1667366027832031,
      "learning_rate": 3.059394844975719e-05,
      "loss": 1.2946,
      "step": 16825
    },
    {
      "epoch": 1.058235731548615,
      "grad_norm": 2.089653968811035,
      "learning_rate": 3.0564764661935e-05,
      "loss": 1.2756,
      "step": 16850
    },
    {
      "epoch": 1.058816694552891,
      "grad_norm": 1.5635786056518555,
      "learning_rate": 3.053558087411281e-05,
      "loss": 1.2892,
      "step": 16875
    },
    {
      "epoch": 1.0593976575571669,
      "grad_norm": 2.1888680458068848,
      "learning_rate": 3.050639708629063e-05,
      "loss": 1.7273,
      "step": 16900
    },
    {
      "epoch": 1.0599786205614425,
      "grad_norm": 1.7223509550094604,
      "learning_rate": 3.0477213298468436e-05,
      "loss": 1.2855,
      "step": 16925
    },
    {
      "epoch": 1.0605595835657184,
      "grad_norm": 1.3254684209823608,
      "learning_rate": 3.0448029510646247e-05,
      "loss": 0.9487,
      "step": 16950
    },
    {
      "epoch": 1.0611405465699943,
      "grad_norm": 2.4892189502716064,
      "learning_rate": 3.0418845722824057e-05,
      "loss": 1.0681,
      "step": 16975
    },
    {
      "epoch": 1.0617215095742703,
      "grad_norm": 1.5718601942062378,
      "learning_rate": 3.0389661935001867e-05,
      "loss": 1.2142,
      "step": 17000
    },
    {
      "epoch": 1.0617215095742703,
      "eval_loss": 0.9285054206848145,
      "eval_runtime": 20.7512,
      "eval_samples_per_second": 192.76,
      "eval_steps_per_second": 48.19,
      "step": 17000
    },
    {
      "epoch": 1.0623024725785462,
      "grad_norm": 1.5359299182891846,
      "learning_rate": 3.0360478147179684e-05,
      "loss": 1.2114,
      "step": 17025
    },
    {
      "epoch": 1.062883435582822,
      "grad_norm": 1.4067591428756714,
      "learning_rate": 3.033129435935749e-05,
      "loss": 1.2571,
      "step": 17050
    },
    {
      "epoch": 1.063464398587098,
      "grad_norm": 1.7327078580856323,
      "learning_rate": 3.03021105715353e-05,
      "loss": 0.9771,
      "step": 17075
    },
    {
      "epoch": 1.0640453615913739,
      "grad_norm": 1.5488433837890625,
      "learning_rate": 3.027292678371311e-05,
      "loss": 0.8927,
      "step": 17100
    },
    {
      "epoch": 1.0646263245956498,
      "grad_norm": 1.2742600440979004,
      "learning_rate": 3.0243742995890922e-05,
      "loss": 1.3176,
      "step": 17125
    },
    {
      "epoch": 1.0652072875999257,
      "grad_norm": 1.8430745601654053,
      "learning_rate": 3.021455920806874e-05,
      "loss": 1.4489,
      "step": 17150
    },
    {
      "epoch": 1.0657882506042016,
      "grad_norm": 1.5533068180084229,
      "learning_rate": 3.018537542024655e-05,
      "loss": 1.1177,
      "step": 17175
    },
    {
      "epoch": 1.0663692136084775,
      "grad_norm": 1.4204403162002563,
      "learning_rate": 3.0156191632424356e-05,
      "loss": 1.2165,
      "step": 17200
    },
    {
      "epoch": 1.0663692136084775,
      "eval_loss": 0.930841863155365,
      "eval_runtime": 21.2302,
      "eval_samples_per_second": 188.411,
      "eval_steps_per_second": 47.103,
      "step": 17200
    },
    {
      "epoch": 1.0669501766127534,
      "grad_norm": 1.455437183380127,
      "learning_rate": 3.0127007844602167e-05,
      "loss": 1.2967,
      "step": 17225
    },
    {
      "epoch": 1.0675311396170293,
      "grad_norm": 1.9681596755981445,
      "learning_rate": 3.0097824056779977e-05,
      "loss": 1.3561,
      "step": 17250
    },
    {
      "epoch": 1.068112102621305,
      "grad_norm": 1.7125461101531982,
      "learning_rate": 3.0068640268957787e-05,
      "loss": 1.5078,
      "step": 17275
    },
    {
      "epoch": 1.0686930656255809,
      "grad_norm": 1.595269799232483,
      "learning_rate": 3.0039456481135604e-05,
      "loss": 1.409,
      "step": 17300
    },
    {
      "epoch": 1.0692740286298568,
      "grad_norm": 1.6444783210754395,
      "learning_rate": 3.001027269331341e-05,
      "loss": 1.3834,
      "step": 17325
    },
    {
      "epoch": 1.0698549916341327,
      "grad_norm": 1.2202790975570679,
      "learning_rate": 2.998108890549122e-05,
      "loss": 1.4825,
      "step": 17350
    },
    {
      "epoch": 1.0704359546384086,
      "grad_norm": 1.2590082883834839,
      "learning_rate": 2.995190511766903e-05,
      "loss": 1.0294,
      "step": 17375
    },
    {
      "epoch": 1.0710169176426845,
      "grad_norm": 3.0964674949645996,
      "learning_rate": 2.9922721329846842e-05,
      "loss": 1.42,
      "step": 17400
    },
    {
      "epoch": 1.0710169176426845,
      "eval_loss": 0.9325028657913208,
      "eval_runtime": 20.4733,
      "eval_samples_per_second": 195.376,
      "eval_steps_per_second": 48.844,
      "step": 17400
    },
    {
      "epoch": 1.0715978806469604,
      "grad_norm": 2.649888277053833,
      "learning_rate": 2.989353754202466e-05,
      "loss": 1.2452,
      "step": 17425
    },
    {
      "epoch": 1.0721788436512363,
      "grad_norm": 2.0369112491607666,
      "learning_rate": 2.986435375420247e-05,
      "loss": 1.0383,
      "step": 17450
    },
    {
      "epoch": 1.0727598066555122,
      "grad_norm": 1.8796606063842773,
      "learning_rate": 2.9835169966380276e-05,
      "loss": 1.0639,
      "step": 17475
    },
    {
      "epoch": 1.073340769659788,
      "grad_norm": 1.6857092380523682,
      "learning_rate": 2.9805986178558087e-05,
      "loss": 1.0384,
      "step": 17500
    },
    {
      "epoch": 1.073921732664064,
      "grad_norm": 1.5666351318359375,
      "learning_rate": 2.9776802390735897e-05,
      "loss": 1.8683,
      "step": 17525
    },
    {
      "epoch": 1.07450269566834,
      "grad_norm": 1.6886601448059082,
      "learning_rate": 2.9747618602913714e-05,
      "loss": 0.9019,
      "step": 17550
    },
    {
      "epoch": 1.0750836586726158,
      "grad_norm": 1.6217116117477417,
      "learning_rate": 2.9718434815091524e-05,
      "loss": 0.4369,
      "step": 17575
    },
    {
      "epoch": 1.0756646216768917,
      "grad_norm": 0.9502178430557251,
      "learning_rate": 2.968925102726933e-05,
      "loss": 0.7163,
      "step": 17600
    },
    {
      "epoch": 1.0756646216768917,
      "eval_loss": 0.9432933330535889,
      "eval_runtime": 20.5298,
      "eval_samples_per_second": 194.839,
      "eval_steps_per_second": 48.71,
      "step": 17600
    },
    {
      "epoch": 1.0762455846811676,
      "grad_norm": 3.0476696491241455,
      "learning_rate": 2.966006723944714e-05,
      "loss": 1.0836,
      "step": 17625
    },
    {
      "epoch": 1.0768265476854433,
      "grad_norm": 1.5375877618789673,
      "learning_rate": 2.963088345162495e-05,
      "loss": 0.7689,
      "step": 17650
    },
    {
      "epoch": 1.0774075106897192,
      "grad_norm": 2.169375419616699,
      "learning_rate": 2.960169966380277e-05,
      "loss": 0.7578,
      "step": 17675
    },
    {
      "epoch": 1.077988473693995,
      "grad_norm": 2.510820150375366,
      "learning_rate": 2.957251587598058e-05,
      "loss": 1.3236,
      "step": 17700
    },
    {
      "epoch": 1.078569436698271,
      "grad_norm": 1.6443920135498047,
      "learning_rate": 2.9543332088158386e-05,
      "loss": 1.151,
      "step": 17725
    },
    {
      "epoch": 1.079150399702547,
      "grad_norm": 1.859910488128662,
      "learning_rate": 2.9514148300336196e-05,
      "loss": 1.2407,
      "step": 17750
    },
    {
      "epoch": 1.0797313627068228,
      "grad_norm": 4.584015846252441,
      "learning_rate": 2.9484964512514006e-05,
      "loss": 1.9039,
      "step": 17775
    },
    {
      "epoch": 1.0803123257110987,
      "grad_norm": 2.6360721588134766,
      "learning_rate": 2.9455780724691824e-05,
      "loss": 1.0336,
      "step": 17800
    },
    {
      "epoch": 1.0803123257110987,
      "eval_loss": 0.937106192111969,
      "eval_runtime": 20.7849,
      "eval_samples_per_second": 192.447,
      "eval_steps_per_second": 48.112,
      "step": 17800
    },
    {
      "epoch": 1.0808932887153746,
      "grad_norm": 1.6634117364883423,
      "learning_rate": 2.9426596936869634e-05,
      "loss": 1.0594,
      "step": 17825
    },
    {
      "epoch": 1.0814742517196505,
      "grad_norm": 3.2125957012176514,
      "learning_rate": 2.9397413149047444e-05,
      "loss": 1.0697,
      "step": 17850
    },
    {
      "epoch": 1.0820552147239264,
      "grad_norm": 2.4646074771881104,
      "learning_rate": 2.936822936122525e-05,
      "loss": 0.8483,
      "step": 17875
    },
    {
      "epoch": 1.0826361777282023,
      "grad_norm": 2.3752381801605225,
      "learning_rate": 2.933904557340306e-05,
      "loss": 0.8535,
      "step": 17900
    },
    {
      "epoch": 1.0832171407324782,
      "grad_norm": 2.166872024536133,
      "learning_rate": 2.930986178558088e-05,
      "loss": 1.3282,
      "step": 17925
    },
    {
      "epoch": 1.0837981037367541,
      "grad_norm": 2.0921630859375,
      "learning_rate": 2.928067799775869e-05,
      "loss": 1.3717,
      "step": 17950
    },
    {
      "epoch": 1.08437906674103,
      "grad_norm": 2.2468786239624023,
      "learning_rate": 2.92514942099365e-05,
      "loss": 1.5441,
      "step": 17975
    },
    {
      "epoch": 1.084960029745306,
      "grad_norm": 1.3414349555969238,
      "learning_rate": 2.9222310422114306e-05,
      "loss": 0.4385,
      "step": 18000
    },
    {
      "epoch": 1.084960029745306,
      "eval_loss": 0.9255023002624512,
      "eval_runtime": 21.3362,
      "eval_samples_per_second": 187.475,
      "eval_steps_per_second": 46.869,
      "step": 18000
    },
    {
      "epoch": 1.0855409927495816,
      "grad_norm": 4.076449871063232,
      "learning_rate": 2.9193126634292116e-05,
      "loss": 0.4877,
      "step": 18025
    },
    {
      "epoch": 1.0861219557538575,
      "grad_norm": 1.2410870790481567,
      "learning_rate": 2.9163942846469933e-05,
      "loss": 0.7405,
      "step": 18050
    },
    {
      "epoch": 1.0867029187581334,
      "grad_norm": 1.1724358797073364,
      "learning_rate": 2.9134759058647744e-05,
      "loss": 0.9536,
      "step": 18075
    },
    {
      "epoch": 1.0872838817624093,
      "grad_norm": 1.9825540781021118,
      "learning_rate": 2.9105575270825554e-05,
      "loss": 0.7511,
      "step": 18100
    },
    {
      "epoch": 1.0878648447666852,
      "grad_norm": 1.2362682819366455,
      "learning_rate": 2.907639148300336e-05,
      "loss": 0.7972,
      "step": 18125
    },
    {
      "epoch": 1.0884458077709611,
      "grad_norm": 1.4928672313690186,
      "learning_rate": 2.904720769518117e-05,
      "loss": 0.7897,
      "step": 18150
    },
    {
      "epoch": 1.089026770775237,
      "grad_norm": 1.4410909414291382,
      "learning_rate": 2.9018023907358988e-05,
      "loss": 0.7918,
      "step": 18175
    },
    {
      "epoch": 1.089607733779513,
      "grad_norm": 1.6863635778427124,
      "learning_rate": 2.89888401195368e-05,
      "loss": 0.888,
      "step": 18200
    },
    {
      "epoch": 1.089607733779513,
      "eval_loss": 0.9310956597328186,
      "eval_runtime": 22.1073,
      "eval_samples_per_second": 180.936,
      "eval_steps_per_second": 45.234,
      "step": 18200
    },
    {
      "epoch": 1.0901886967837888,
      "grad_norm": 1.9104276895523071,
      "learning_rate": 2.895965633171461e-05,
      "loss": 0.7833,
      "step": 18225
    },
    {
      "epoch": 1.0907696597880647,
      "grad_norm": 1.6136271953582764,
      "learning_rate": 2.893047254389242e-05,
      "loss": 1.1277,
      "step": 18250
    },
    {
      "epoch": 1.0913506227923406,
      "grad_norm": 1.3927401304244995,
      "learning_rate": 2.8901288756070226e-05,
      "loss": 0.9926,
      "step": 18275
    },
    {
      "epoch": 1.0919315857966165,
      "grad_norm": 1.8204935789108276,
      "learning_rate": 2.8872104968248043e-05,
      "loss": 0.9723,
      "step": 18300
    },
    {
      "epoch": 1.0925125488008924,
      "grad_norm": 1.7284375429153442,
      "learning_rate": 2.8842921180425853e-05,
      "loss": 0.7641,
      "step": 18325
    },
    {
      "epoch": 1.0930935118051683,
      "grad_norm": 2.213334798812866,
      "learning_rate": 2.8813737392603663e-05,
      "loss": 0.739,
      "step": 18350
    },
    {
      "epoch": 1.0936744748094442,
      "grad_norm": 1.857674479484558,
      "learning_rate": 2.8784553604781474e-05,
      "loss": 1.0234,
      "step": 18375
    },
    {
      "epoch": 1.09425543781372,
      "grad_norm": 1.5011028051376343,
      "learning_rate": 2.875536981695928e-05,
      "loss": 0.8698,
      "step": 18400
    },
    {
      "epoch": 1.09425543781372,
      "eval_loss": 0.9471971988677979,
      "eval_runtime": 24.7968,
      "eval_samples_per_second": 161.311,
      "eval_steps_per_second": 40.328,
      "step": 18400
    },
    {
      "epoch": 1.0948364008179958,
      "grad_norm": 2.6527438163757324,
      "learning_rate": 2.8726186029137098e-05,
      "loss": 0.4985,
      "step": 18425
    },
    {
      "epoch": 1.0954173638222717,
      "grad_norm": 1.2519774436950684,
      "learning_rate": 2.8697002241314908e-05,
      "loss": 0.6832,
      "step": 18450
    },
    {
      "epoch": 1.0959983268265476,
      "grad_norm": 2.008021116256714,
      "learning_rate": 2.866781845349272e-05,
      "loss": 0.8219,
      "step": 18475
    },
    {
      "epoch": 1.0965792898308235,
      "grad_norm": 1.425121784210205,
      "learning_rate": 2.863863466567053e-05,
      "loss": 1.0674,
      "step": 18500
    },
    {
      "epoch": 1.0971602528350994,
      "grad_norm": 1.4062697887420654,
      "learning_rate": 2.8609450877848336e-05,
      "loss": 0.7164,
      "step": 18525
    },
    {
      "epoch": 1.0977412158393753,
      "grad_norm": 2.0436694622039795,
      "learning_rate": 2.8580267090026153e-05,
      "loss": 0.9738,
      "step": 18550
    },
    {
      "epoch": 1.0983221788436512,
      "grad_norm": 2.3195924758911133,
      "learning_rate": 2.8551083302203963e-05,
      "loss": 0.9568,
      "step": 18575
    },
    {
      "epoch": 1.0989031418479271,
      "grad_norm": 1.6586086750030518,
      "learning_rate": 2.8521899514381773e-05,
      "loss": 1.2055,
      "step": 18600
    },
    {
      "epoch": 1.0989031418479271,
      "eval_loss": 0.9302799105644226,
      "eval_runtime": 22.7819,
      "eval_samples_per_second": 175.578,
      "eval_steps_per_second": 43.894,
      "step": 18600
    },
    {
      "epoch": 1.099484104852203,
      "grad_norm": 2.2737066745758057,
      "learning_rate": 2.8492715726559583e-05,
      "loss": 1.0319,
      "step": 18625
    },
    {
      "epoch": 1.100065067856479,
      "grad_norm": 1.6432976722717285,
      "learning_rate": 2.8463531938737394e-05,
      "loss": 1.0786,
      "step": 18650
    },
    {
      "epoch": 1.1006460308607549,
      "grad_norm": 2.177978515625,
      "learning_rate": 2.8434348150915207e-05,
      "loss": 0.7802,
      "step": 18675
    },
    {
      "epoch": 1.1012269938650308,
      "grad_norm": 2.3746232986450195,
      "learning_rate": 2.8405164363093018e-05,
      "loss": 0.7382,
      "step": 18700
    },
    {
      "epoch": 1.1018079568693067,
      "grad_norm": 1.5685664415359497,
      "learning_rate": 2.8375980575270828e-05,
      "loss": 0.6204,
      "step": 18725
    },
    {
      "epoch": 1.1023889198735826,
      "grad_norm": 1.3425214290618896,
      "learning_rate": 2.834679678744864e-05,
      "loss": 0.6289,
      "step": 18750
    },
    {
      "epoch": 1.1029698828778582,
      "grad_norm": 1.8146456480026245,
      "learning_rate": 2.831761299962645e-05,
      "loss": 0.7236,
      "step": 18775
    },
    {
      "epoch": 1.1035508458821341,
      "grad_norm": 5.625616073608398,
      "learning_rate": 2.8288429211804256e-05,
      "loss": 0.6053,
      "step": 18800
    },
    {
      "epoch": 1.1035508458821341,
      "eval_loss": 0.9367946982383728,
      "eval_runtime": 22.8035,
      "eval_samples_per_second": 175.412,
      "eval_steps_per_second": 43.853,
      "step": 18800
    },
    {
      "epoch": 1.10413180888641,
      "grad_norm": 1.6131647825241089,
      "learning_rate": 2.8259245423982073e-05,
      "loss": 1.2624,
      "step": 18825
    },
    {
      "epoch": 1.104712771890686,
      "grad_norm": 1.8023442029953003,
      "learning_rate": 2.8230061636159883e-05,
      "loss": 1.1889,
      "step": 18850
    },
    {
      "epoch": 1.1052937348949619,
      "grad_norm": 1.5416738986968994,
      "learning_rate": 2.8200877848337693e-05,
      "loss": 1.1721,
      "step": 18875
    },
    {
      "epoch": 1.1058746978992378,
      "grad_norm": 1.7890355587005615,
      "learning_rate": 2.8171694060515503e-05,
      "loss": 1.0709,
      "step": 18900
    },
    {
      "epoch": 1.1064556609035137,
      "grad_norm": 2.085953712463379,
      "learning_rate": 2.8142510272693314e-05,
      "loss": 1.1075,
      "step": 18925
    },
    {
      "epoch": 1.1070366239077896,
      "grad_norm": 2.4063198566436768,
      "learning_rate": 2.8113326484871127e-05,
      "loss": 1.0319,
      "step": 18950
    },
    {
      "epoch": 1.1076175869120655,
      "grad_norm": 1.6291148662567139,
      "learning_rate": 2.8084142697048938e-05,
      "loss": 0.8577,
      "step": 18975
    },
    {
      "epoch": 1.1081985499163414,
      "grad_norm": 2.376328945159912,
      "learning_rate": 2.8054958909226748e-05,
      "loss": 0.6812,
      "step": 19000
    },
    {
      "epoch": 1.1081985499163414,
      "eval_loss": 0.9371647834777832,
      "eval_runtime": 22.059,
      "eval_samples_per_second": 181.332,
      "eval_steps_per_second": 45.333,
      "step": 19000
    },
    {
      "epoch": 1.1087795129206173,
      "grad_norm": 1.5735864639282227,
      "learning_rate": 2.8025775121404558e-05,
      "loss": 0.8239,
      "step": 19025
    },
    {
      "epoch": 1.1093604759248932,
      "grad_norm": 2.078523874282837,
      "learning_rate": 2.799659133358237e-05,
      "loss": 1.2829,
      "step": 19050
    },
    {
      "epoch": 1.109941438929169,
      "grad_norm": 1.4164341688156128,
      "learning_rate": 2.7967407545760182e-05,
      "loss": 1.1014,
      "step": 19075
    },
    {
      "epoch": 1.110522401933445,
      "grad_norm": 0.9152536392211914,
      "learning_rate": 2.7938223757937993e-05,
      "loss": 0.8531,
      "step": 19100
    },
    {
      "epoch": 1.1111033649377209,
      "grad_norm": 1.516015648841858,
      "learning_rate": 2.7909039970115803e-05,
      "loss": 0.9068,
      "step": 19125
    },
    {
      "epoch": 1.1116843279419966,
      "grad_norm": 1.6464143991470337,
      "learning_rate": 2.7879856182293613e-05,
      "loss": 0.9649,
      "step": 19150
    },
    {
      "epoch": 1.1122652909462725,
      "grad_norm": 2.311981201171875,
      "learning_rate": 2.7850672394471423e-05,
      "loss": 1.2617,
      "step": 19175
    },
    {
      "epoch": 1.1128462539505484,
      "grad_norm": 2.2943129539489746,
      "learning_rate": 2.7821488606649237e-05,
      "loss": 1.408,
      "step": 19200
    },
    {
      "epoch": 1.1128462539505484,
      "eval_loss": 0.9210888743400574,
      "eval_runtime": 22.5505,
      "eval_samples_per_second": 177.38,
      "eval_steps_per_second": 44.345,
      "step": 19200
    },
    {
      "epoch": 1.1134272169548243,
      "grad_norm": 1.7587594985961914,
      "learning_rate": 2.7792304818827047e-05,
      "loss": 0.7277,
      "step": 19225
    },
    {
      "epoch": 1.1140081799591002,
      "grad_norm": 2.035081386566162,
      "learning_rate": 2.7763121031004858e-05,
      "loss": 0.7097,
      "step": 19250
    },
    {
      "epoch": 1.114589142963376,
      "grad_norm": 0.9922944903373718,
      "learning_rate": 2.7733937243182668e-05,
      "loss": 1.1313,
      "step": 19275
    },
    {
      "epoch": 1.115170105967652,
      "grad_norm": 1.332220435142517,
      "learning_rate": 2.7704753455360478e-05,
      "loss": 0.4287,
      "step": 19300
    },
    {
      "epoch": 1.1157510689719279,
      "grad_norm": 1.2574173212051392,
      "learning_rate": 2.7675569667538292e-05,
      "loss": 0.2932,
      "step": 19325
    },
    {
      "epoch": 1.1163320319762038,
      "grad_norm": 0.7724765539169312,
      "learning_rate": 2.7646385879716102e-05,
      "loss": 0.3895,
      "step": 19350
    },
    {
      "epoch": 1.1169129949804797,
      "grad_norm": 1.6963112354278564,
      "learning_rate": 2.7617202091893913e-05,
      "loss": 0.9459,
      "step": 19375
    },
    {
      "epoch": 1.1174939579847556,
      "grad_norm": 1.0734318494796753,
      "learning_rate": 2.7588018304071723e-05,
      "loss": 1.0124,
      "step": 19400
    },
    {
      "epoch": 1.1174939579847556,
      "eval_loss": 0.9222787022590637,
      "eval_runtime": 21.9645,
      "eval_samples_per_second": 182.112,
      "eval_steps_per_second": 45.528,
      "step": 19400
    },
    {
      "epoch": 1.1180749209890315,
      "grad_norm": 2.1521120071411133,
      "learning_rate": 2.7558834516249533e-05,
      "loss": 1.2296,
      "step": 19425
    },
    {
      "epoch": 1.1186558839933074,
      "grad_norm": 1.9256713390350342,
      "learning_rate": 2.7529650728427347e-05,
      "loss": 1.3543,
      "step": 19450
    },
    {
      "epoch": 1.119236846997583,
      "grad_norm": 1.4281141757965088,
      "learning_rate": 2.7500466940605157e-05,
      "loss": 1.6664,
      "step": 19475
    },
    {
      "epoch": 1.119817810001859,
      "grad_norm": 1.2556017637252808,
      "learning_rate": 2.7471283152782967e-05,
      "loss": 0.9153,
      "step": 19500
    },
    {
      "epoch": 1.1203987730061349,
      "grad_norm": 1.2249823808670044,
      "learning_rate": 2.7442099364960778e-05,
      "loss": 1.2475,
      "step": 19525
    },
    {
      "epoch": 1.1209797360104108,
      "grad_norm": 1.9355143308639526,
      "learning_rate": 2.7412915577138588e-05,
      "loss": 1.4782,
      "step": 19550
    },
    {
      "epoch": 1.1215606990146867,
      "grad_norm": 1.6871728897094727,
      "learning_rate": 2.73837317893164e-05,
      "loss": 1.2301,
      "step": 19575
    },
    {
      "epoch": 1.1221416620189626,
      "grad_norm": 1.8254891633987427,
      "learning_rate": 2.7354548001494212e-05,
      "loss": 0.9771,
      "step": 19600
    },
    {
      "epoch": 1.1221416620189626,
      "eval_loss": 0.9171589016914368,
      "eval_runtime": 22.2779,
      "eval_samples_per_second": 179.55,
      "eval_steps_per_second": 44.888,
      "step": 19600
    },
    {
      "epoch": 1.1227226250232385,
      "grad_norm": 0.9357762336730957,
      "learning_rate": 2.7325364213672022e-05,
      "loss": 1.206,
      "step": 19625
    },
    {
      "epoch": 1.1233035880275144,
      "grad_norm": 2.211294412612915,
      "learning_rate": 2.7296180425849832e-05,
      "loss": 1.236,
      "step": 19650
    },
    {
      "epoch": 1.1238845510317903,
      "grad_norm": 1.3336572647094727,
      "learning_rate": 2.7266996638027643e-05,
      "loss": 1.0185,
      "step": 19675
    },
    {
      "epoch": 1.1244655140360662,
      "grad_norm": 1.8249629735946655,
      "learning_rate": 2.7237812850205456e-05,
      "loss": 1.0513,
      "step": 19700
    },
    {
      "epoch": 1.125046477040342,
      "grad_norm": 1.2028464078903198,
      "learning_rate": 2.7208629062383267e-05,
      "loss": 1.1481,
      "step": 19725
    },
    {
      "epoch": 1.125627440044618,
      "grad_norm": 3.3195197582244873,
      "learning_rate": 2.7179445274561077e-05,
      "loss": 1.1596,
      "step": 19750
    },
    {
      "epoch": 1.126208403048894,
      "grad_norm": 2.916090726852417,
      "learning_rate": 2.7150261486738887e-05,
      "loss": 1.2092,
      "step": 19775
    },
    {
      "epoch": 1.1267893660531698,
      "grad_norm": 2.0178842544555664,
      "learning_rate": 2.7121077698916698e-05,
      "loss": 0.9149,
      "step": 19800
    },
    {
      "epoch": 1.1267893660531698,
      "eval_loss": 0.9199384450912476,
      "eval_runtime": 21.7223,
      "eval_samples_per_second": 184.142,
      "eval_steps_per_second": 46.036,
      "step": 19800
    },
    {
      "epoch": 1.1273703290574457,
      "grad_norm": 3.2649383544921875,
      "learning_rate": 2.709189391109451e-05,
      "loss": 1.0153,
      "step": 19825
    },
    {
      "epoch": 1.1279512920617214,
      "grad_norm": 3.763899564743042,
      "learning_rate": 2.706271012327232e-05,
      "loss": 1.0429,
      "step": 19850
    },
    {
      "epoch": 1.1285322550659973,
      "grad_norm": 2.1212310791015625,
      "learning_rate": 2.7033526335450132e-05,
      "loss": 1.1617,
      "step": 19875
    },
    {
      "epoch": 1.1291132180702732,
      "grad_norm": 1.890395164489746,
      "learning_rate": 2.7004342547627942e-05,
      "loss": 1.2303,
      "step": 19900
    },
    {
      "epoch": 1.129694181074549,
      "grad_norm": 2.0416786670684814,
      "learning_rate": 2.6975158759805752e-05,
      "loss": 1.5304,
      "step": 19925
    },
    {
      "epoch": 1.130275144078825,
      "grad_norm": 1.6592622995376587,
      "learning_rate": 2.6945974971983566e-05,
      "loss": 0.9501,
      "step": 19950
    },
    {
      "epoch": 1.130856107083101,
      "grad_norm": 1.8473871946334839,
      "learning_rate": 2.6916791184161376e-05,
      "loss": 0.9327,
      "step": 19975
    },
    {
      "epoch": 1.1314370700873768,
      "grad_norm": 2.1052744388580322,
      "learning_rate": 2.6887607396339187e-05,
      "loss": 0.8582,
      "step": 20000
    },
    {
      "epoch": 1.1314370700873768,
      "eval_loss": 0.9169191122055054,
      "eval_runtime": 21.9281,
      "eval_samples_per_second": 182.414,
      "eval_steps_per_second": 45.604,
      "step": 20000
    },
    {
      "epoch": 1.1320180330916527,
      "grad_norm": 22.089170455932617,
      "learning_rate": 2.6858423608516997e-05,
      "loss": 0.9931,
      "step": 20025
    },
    {
      "epoch": 1.1325989960959286,
      "grad_norm": 1.3301259279251099,
      "learning_rate": 2.6829239820694807e-05,
      "loss": 0.9835,
      "step": 20050
    },
    {
      "epoch": 1.1331799591002045,
      "grad_norm": 1.8071990013122559,
      "learning_rate": 2.680005603287262e-05,
      "loss": 0.8035,
      "step": 20075
    },
    {
      "epoch": 1.1337609221044804,
      "grad_norm": 2.208402156829834,
      "learning_rate": 2.677087224505043e-05,
      "loss": 1.1308,
      "step": 20100
    },
    {
      "epoch": 1.1343418851087563,
      "grad_norm": 1.6099107265472412,
      "learning_rate": 2.674168845722824e-05,
      "loss": 1.3968,
      "step": 20125
    },
    {
      "epoch": 1.1349228481130322,
      "grad_norm": 1.8180289268493652,
      "learning_rate": 2.6712504669406052e-05,
      "loss": 1.281,
      "step": 20150
    },
    {
      "epoch": 1.1355038111173081,
      "grad_norm": 1.6211907863616943,
      "learning_rate": 2.6683320881583862e-05,
      "loss": 0.9837,
      "step": 20175
    },
    {
      "epoch": 1.136084774121584,
      "grad_norm": 1.2793197631835938,
      "learning_rate": 2.6654137093761676e-05,
      "loss": 1.1967,
      "step": 20200
    },
    {
      "epoch": 1.136084774121584,
      "eval_loss": 0.9175792336463928,
      "eval_runtime": 22.6325,
      "eval_samples_per_second": 176.737,
      "eval_steps_per_second": 44.184,
      "step": 20200
    },
    {
      "epoch": 1.1366657371258597,
      "grad_norm": 1.4086514711380005,
      "learning_rate": 2.6624953305939486e-05,
      "loss": 0.7832,
      "step": 20225
    },
    {
      "epoch": 1.1372467001301356,
      "grad_norm": 1.1703380346298218,
      "learning_rate": 2.6595769518117296e-05,
      "loss": 0.7684,
      "step": 20250
    },
    {
      "epoch": 1.1378276631344115,
      "grad_norm": 1.717352271080017,
      "learning_rate": 2.6566585730295107e-05,
      "loss": 0.6481,
      "step": 20275
    },
    {
      "epoch": 1.1384086261386874,
      "grad_norm": 2.303781270980835,
      "learning_rate": 2.6537401942472917e-05,
      "loss": 0.715,
      "step": 20300
    },
    {
      "epoch": 1.1389895891429633,
      "grad_norm": 1.0762420892715454,
      "learning_rate": 2.6508218154650734e-05,
      "loss": 0.5906,
      "step": 20325
    },
    {
      "epoch": 1.1395705521472392,
      "grad_norm": 0.9905433654785156,
      "learning_rate": 2.647903436682854e-05,
      "loss": 0.6512,
      "step": 20350
    },
    {
      "epoch": 1.1401515151515151,
      "grad_norm": 1.467453122138977,
      "learning_rate": 2.644985057900635e-05,
      "loss": 0.5834,
      "step": 20375
    },
    {
      "epoch": 1.140732478155791,
      "grad_norm": 1.4593137502670288,
      "learning_rate": 2.642066679118416e-05,
      "loss": 0.7161,
      "step": 20400
    },
    {
      "epoch": 1.140732478155791,
      "eval_loss": 0.9168069958686829,
      "eval_runtime": 22.4422,
      "eval_samples_per_second": 178.235,
      "eval_steps_per_second": 44.559,
      "step": 20400
    },
    {
      "epoch": 1.141313441160067,
      "grad_norm": 2.2259788513183594,
      "learning_rate": 2.6391483003361972e-05,
      "loss": 0.8045,
      "step": 20425
    },
    {
      "epoch": 1.1418944041643428,
      "grad_norm": 1.3237178325653076,
      "learning_rate": 2.6362299215539782e-05,
      "loss": 0.77,
      "step": 20450
    },
    {
      "epoch": 1.1424753671686187,
      "grad_norm": 1.154920220375061,
      "learning_rate": 2.6333115427717596e-05,
      "loss": 0.6542,
      "step": 20475
    },
    {
      "epoch": 1.1430563301728947,
      "grad_norm": 1.676370620727539,
      "learning_rate": 2.6303931639895406e-05,
      "loss": 0.6458,
      "step": 20500
    },
    {
      "epoch": 1.1436372931771706,
      "grad_norm": 1.2081495523452759,
      "learning_rate": 2.6274747852073216e-05,
      "loss": 0.6591,
      "step": 20525
    },
    {
      "epoch": 1.1442182561814465,
      "grad_norm": 1.0429670810699463,
      "learning_rate": 2.6245564064251027e-05,
      "loss": 0.717,
      "step": 20550
    },
    {
      "epoch": 1.1447992191857224,
      "grad_norm": 1.2870053052902222,
      "learning_rate": 2.6216380276428837e-05,
      "loss": 0.773,
      "step": 20575
    },
    {
      "epoch": 1.145380182189998,
      "grad_norm": 1.7487391233444214,
      "learning_rate": 2.618719648860665e-05,
      "loss": 0.7458,
      "step": 20600
    },
    {
      "epoch": 1.145380182189998,
      "eval_loss": 0.9208121299743652,
      "eval_runtime": 22.0913,
      "eval_samples_per_second": 181.067,
      "eval_steps_per_second": 45.267,
      "step": 20600
    },
    {
      "epoch": 1.145961145194274,
      "grad_norm": 2.03486967086792,
      "learning_rate": 2.615801270078446e-05,
      "loss": 0.7134,
      "step": 20625
    },
    {
      "epoch": 1.1465421081985498,
      "grad_norm": 1.7590057849884033,
      "learning_rate": 2.612882891296227e-05,
      "loss": 0.7,
      "step": 20650
    },
    {
      "epoch": 1.1471230712028258,
      "grad_norm": 1.7901936769485474,
      "learning_rate": 2.609964512514008e-05,
      "loss": 0.7743,
      "step": 20675
    },
    {
      "epoch": 1.1477040342071017,
      "grad_norm": 1.8978121280670166,
      "learning_rate": 2.6070461337317892e-05,
      "loss": 0.7142,
      "step": 20700
    },
    {
      "epoch": 1.1482849972113776,
      "grad_norm": 1.6886987686157227,
      "learning_rate": 2.604127754949571e-05,
      "loss": 0.6434,
      "step": 20725
    },
    {
      "epoch": 1.1488659602156535,
      "grad_norm": 1.242047905921936,
      "learning_rate": 2.6012093761673516e-05,
      "loss": 0.5936,
      "step": 20750
    },
    {
      "epoch": 1.1494469232199294,
      "grad_norm": 1.8529061079025269,
      "learning_rate": 2.5982909973851326e-05,
      "loss": 0.8341,
      "step": 20775
    },
    {
      "epoch": 1.1500278862242053,
      "grad_norm": 1.5446101427078247,
      "learning_rate": 2.5953726186029136e-05,
      "loss": 1.2518,
      "step": 20800
    },
    {
      "epoch": 1.1500278862242053,
      "eval_loss": 0.9208548069000244,
      "eval_runtime": 22.2873,
      "eval_samples_per_second": 179.475,
      "eval_steps_per_second": 44.869,
      "step": 20800
    },
    {
      "epoch": 1.1506088492284812,
      "grad_norm": 1.6013351678848267,
      "learning_rate": 2.5924542398206947e-05,
      "loss": 1.0305,
      "step": 20825
    },
    {
      "epoch": 1.151189812232757,
      "grad_norm": 1.5915894508361816,
      "learning_rate": 2.5895358610384764e-05,
      "loss": 0.606,
      "step": 20850
    },
    {
      "epoch": 1.151770775237033,
      "grad_norm": 1.4799216985702515,
      "learning_rate": 2.586617482256257e-05,
      "loss": 0.5696,
      "step": 20875
    },
    {
      "epoch": 1.1523517382413089,
      "grad_norm": 1.6703567504882812,
      "learning_rate": 2.583699103474038e-05,
      "loss": 0.6934,
      "step": 20900
    },
    {
      "epoch": 1.1529327012455846,
      "grad_norm": 1.2336496114730835,
      "learning_rate": 2.580780724691819e-05,
      "loss": 0.6767,
      "step": 20925
    },
    {
      "epoch": 1.1535136642498607,
      "grad_norm": 1.3628480434417725,
      "learning_rate": 2.5778623459096e-05,
      "loss": 0.6561,
      "step": 20950
    },
    {
      "epoch": 1.1540946272541364,
      "grad_norm": 2.1284549236297607,
      "learning_rate": 2.574943967127382e-05,
      "loss": 0.6247,
      "step": 20975
    },
    {
      "epoch": 1.1546755902584123,
      "grad_norm": 1.158771276473999,
      "learning_rate": 2.572025588345163e-05,
      "loss": 0.7005,
      "step": 21000
    },
    {
      "epoch": 1.1546755902584123,
      "eval_loss": 0.9163911938667297,
      "eval_runtime": 22.426,
      "eval_samples_per_second": 178.364,
      "eval_steps_per_second": 44.591,
      "step": 21000
    },
    {
      "epoch": 1.1552565532626882,
      "grad_norm": 1.499165654182434,
      "learning_rate": 2.5691072095629436e-05,
      "loss": 0.6014,
      "step": 21025
    },
    {
      "epoch": 1.155837516266964,
      "grad_norm": 1.0172138214111328,
      "learning_rate": 2.5661888307807246e-05,
      "loss": 0.8314,
      "step": 21050
    },
    {
      "epoch": 1.15641847927124,
      "grad_norm": 1.370492696762085,
      "learning_rate": 2.5632704519985056e-05,
      "loss": 0.6915,
      "step": 21075
    },
    {
      "epoch": 1.1569994422755159,
      "grad_norm": 1.2674834728240967,
      "learning_rate": 2.5603520732162873e-05,
      "loss": 0.7323,
      "step": 21100
    },
    {
      "epoch": 1.1575804052797918,
      "grad_norm": 3.9564311504364014,
      "learning_rate": 2.5574336944340684e-05,
      "loss": 0.8121,
      "step": 21125
    },
    {
      "epoch": 1.1581613682840677,
      "grad_norm": 1.3034892082214355,
      "learning_rate": 2.554515315651849e-05,
      "loss": 0.718,
      "step": 21150
    },
    {
      "epoch": 1.1587423312883436,
      "grad_norm": 1.3566404581069946,
      "learning_rate": 2.55159693686963e-05,
      "loss": 0.7842,
      "step": 21175
    },
    {
      "epoch": 1.1593232942926195,
      "grad_norm": 7.237298965454102,
      "learning_rate": 2.548678558087411e-05,
      "loss": 0.8804,
      "step": 21200
    },
    {
      "epoch": 1.1593232942926195,
      "eval_loss": 0.9117593765258789,
      "eval_runtime": 23.0325,
      "eval_samples_per_second": 173.668,
      "eval_steps_per_second": 43.417,
      "step": 21200
    },
    {
      "epoch": 1.1599042572968954,
      "grad_norm": 2.3100216388702393,
      "learning_rate": 2.5457601793051928e-05,
      "loss": 1.3418,
      "step": 21225
    },
    {
      "epoch": 1.1604852203011713,
      "grad_norm": 2.8428502082824707,
      "learning_rate": 2.542841800522974e-05,
      "loss": 1.4073,
      "step": 21250
    },
    {
      "epoch": 1.1610661833054472,
      "grad_norm": 1.5925734043121338,
      "learning_rate": 2.5399234217407545e-05,
      "loss": 1.2827,
      "step": 21275
    },
    {
      "epoch": 1.1616471463097229,
      "grad_norm": 2.8107621669769287,
      "learning_rate": 2.5370050429585356e-05,
      "loss": 1.666,
      "step": 21300
    },
    {
      "epoch": 1.162228109313999,
      "grad_norm": 1.323443055152893,
      "learning_rate": 2.5340866641763166e-05,
      "loss": 1.3076,
      "step": 21325
    },
    {
      "epoch": 1.1628090723182747,
      "grad_norm": 3.035418748855591,
      "learning_rate": 2.5311682853940983e-05,
      "loss": 1.0841,
      "step": 21350
    },
    {
      "epoch": 1.1633900353225506,
      "grad_norm": 3.017233371734619,
      "learning_rate": 2.5282499066118793e-05,
      "loss": 1.8643,
      "step": 21375
    },
    {
      "epoch": 1.1639709983268265,
      "grad_norm": 3.3354790210723877,
      "learning_rate": 2.5253315278296604e-05,
      "loss": 1.942,
      "step": 21400
    },
    {
      "epoch": 1.1639709983268265,
      "eval_loss": 0.9169186949729919,
      "eval_runtime": 22.3394,
      "eval_samples_per_second": 179.056,
      "eval_steps_per_second": 44.764,
      "step": 21400
    },
    {
      "epoch": 1.1645519613311024,
      "grad_norm": 1.4383238554000854,
      "learning_rate": 2.522413149047441e-05,
      "loss": 1.3009,
      "step": 21425
    },
    {
      "epoch": 1.1651329243353783,
      "grad_norm": 1.2691845893859863,
      "learning_rate": 2.519494770265222e-05,
      "loss": 0.8904,
      "step": 21450
    },
    {
      "epoch": 1.1657138873396542,
      "grad_norm": 0.9637247323989868,
      "learning_rate": 2.5165763914830038e-05,
      "loss": 0.9543,
      "step": 21475
    },
    {
      "epoch": 1.16629485034393,
      "grad_norm": 1.4334566593170166,
      "learning_rate": 2.5136580127007848e-05,
      "loss": 1.0147,
      "step": 21500
    },
    {
      "epoch": 1.166875813348206,
      "grad_norm": 1.6784422397613525,
      "learning_rate": 2.510739633918566e-05,
      "loss": 1.1582,
      "step": 21525
    },
    {
      "epoch": 1.167456776352482,
      "grad_norm": 1.8280448913574219,
      "learning_rate": 2.5078212551363465e-05,
      "loss": 1.0649,
      "step": 21550
    },
    {
      "epoch": 1.1680377393567578,
      "grad_norm": 1.6057932376861572,
      "learning_rate": 2.5049028763541276e-05,
      "loss": 1.0351,
      "step": 21575
    },
    {
      "epoch": 1.1686187023610337,
      "grad_norm": 0.985565721988678,
      "learning_rate": 2.5019844975719093e-05,
      "loss": 1.0377,
      "step": 21600
    },
    {
      "epoch": 1.1686187023610337,
      "eval_loss": 0.9131677150726318,
      "eval_runtime": 22.3349,
      "eval_samples_per_second": 179.092,
      "eval_steps_per_second": 44.773,
      "step": 21600
    },
    {
      "epoch": 1.1691996653653096,
      "grad_norm": 1.5834964513778687,
      "learning_rate": 2.49906611878969e-05,
      "loss": 1.165,
      "step": 21625
    },
    {
      "epoch": 1.1697806283695855,
      "grad_norm": 1.9975850582122803,
      "learning_rate": 2.4961477400074713e-05,
      "loss": 1.003,
      "step": 21650
    },
    {
      "epoch": 1.1703615913738612,
      "grad_norm": 2.7588162422180176,
      "learning_rate": 2.493229361225252e-05,
      "loss": 0.965,
      "step": 21675
    },
    {
      "epoch": 1.1709425543781373,
      "grad_norm": 1.4872769117355347,
      "learning_rate": 2.4903109824430334e-05,
      "loss": 1.4701,
      "step": 21700
    },
    {
      "epoch": 1.171523517382413,
      "grad_norm": 2.352315664291382,
      "learning_rate": 2.4873926036608144e-05,
      "loss": 1.0858,
      "step": 21725
    },
    {
      "epoch": 1.172104480386689,
      "grad_norm": 2.0755198001861572,
      "learning_rate": 2.4844742248785955e-05,
      "loss": 1.2615,
      "step": 21750
    },
    {
      "epoch": 1.1726854433909648,
      "grad_norm": 2.4457530975341797,
      "learning_rate": 2.4815558460963768e-05,
      "loss": 1.2475,
      "step": 21775
    },
    {
      "epoch": 1.1732664063952407,
      "grad_norm": 1.6888645887374878,
      "learning_rate": 2.478637467314158e-05,
      "loss": 1.3217,
      "step": 21800
    },
    {
      "epoch": 1.1732664063952407,
      "eval_loss": 0.9134469032287598,
      "eval_runtime": 22.2384,
      "eval_samples_per_second": 179.869,
      "eval_steps_per_second": 44.967,
      "step": 21800
    },
    {
      "epoch": 1.1738473693995166,
      "grad_norm": 1.7728679180145264,
      "learning_rate": 2.475719088531939e-05,
      "loss": 1.082,
      "step": 21825
    },
    {
      "epoch": 1.1744283324037925,
      "grad_norm": 1.9341535568237305,
      "learning_rate": 2.47280070974972e-05,
      "loss": 1.1352,
      "step": 21850
    },
    {
      "epoch": 1.1750092954080684,
      "grad_norm": 2.31974720954895,
      "learning_rate": 2.469882330967501e-05,
      "loss": 0.9286,
      "step": 21875
    },
    {
      "epoch": 1.1755902584123443,
      "grad_norm": 1.7067608833312988,
      "learning_rate": 2.4669639521852823e-05,
      "loss": 0.845,
      "step": 21900
    },
    {
      "epoch": 1.1761712214166202,
      "grad_norm": 1.5597434043884277,
      "learning_rate": 2.4640455734030633e-05,
      "loss": 0.9699,
      "step": 21925
    },
    {
      "epoch": 1.1767521844208961,
      "grad_norm": 1.4553471803665161,
      "learning_rate": 2.4611271946208444e-05,
      "loss": 0.9333,
      "step": 21950
    },
    {
      "epoch": 1.177333147425172,
      "grad_norm": 1.9967224597930908,
      "learning_rate": 2.4582088158386254e-05,
      "loss": 0.8738,
      "step": 21975
    },
    {
      "epoch": 1.177914110429448,
      "grad_norm": 1.248641848564148,
      "learning_rate": 2.4552904370564064e-05,
      "loss": 1.21,
      "step": 22000
    },
    {
      "epoch": 1.177914110429448,
      "eval_loss": 0.9148917198181152,
      "eval_runtime": 21.9912,
      "eval_samples_per_second": 181.891,
      "eval_steps_per_second": 45.473,
      "step": 22000
    },
    {
      "epoch": 1.1784950734337238,
      "grad_norm": 1.8850784301757812,
      "learning_rate": 2.4523720582741878e-05,
      "loss": 0.9421,
      "step": 22025
    },
    {
      "epoch": 1.1790760364379995,
      "grad_norm": 1.756211280822754,
      "learning_rate": 2.4494536794919688e-05,
      "loss": 0.8708,
      "step": 22050
    },
    {
      "epoch": 1.1796569994422754,
      "grad_norm": 2.0719683170318604,
      "learning_rate": 2.44653530070975e-05,
      "loss": 1.4982,
      "step": 22075
    },
    {
      "epoch": 1.1802379624465513,
      "grad_norm": 2.301023483276367,
      "learning_rate": 2.443616921927531e-05,
      "loss": 1.3766,
      "step": 22100
    },
    {
      "epoch": 1.1808189254508272,
      "grad_norm": 2.5210635662078857,
      "learning_rate": 2.440698543145312e-05,
      "loss": 1.3454,
      "step": 22125
    },
    {
      "epoch": 1.1813998884551031,
      "grad_norm": 2.8532121181488037,
      "learning_rate": 2.4377801643630933e-05,
      "loss": 1.0084,
      "step": 22150
    },
    {
      "epoch": 1.181980851459379,
      "grad_norm": 1.9982798099517822,
      "learning_rate": 2.4348617855808743e-05,
      "loss": 0.766,
      "step": 22175
    },
    {
      "epoch": 1.182561814463655,
      "grad_norm": 1.2015421390533447,
      "learning_rate": 2.4319434067986553e-05,
      "loss": 0.8571,
      "step": 22200
    },
    {
      "epoch": 1.182561814463655,
      "eval_loss": 0.9119575023651123,
      "eval_runtime": 22.6902,
      "eval_samples_per_second": 176.287,
      "eval_steps_per_second": 44.072,
      "step": 22200
    },
    {
      "epoch": 1.1831427774679308,
      "grad_norm": 1.822368860244751,
      "learning_rate": 2.4290250280164364e-05,
      "loss": 1.5211,
      "step": 22225
    },
    {
      "epoch": 1.1837237404722067,
      "grad_norm": 2.3478524684906006,
      "learning_rate": 2.4261066492342174e-05,
      "loss": 1.0821,
      "step": 22250
    },
    {
      "epoch": 1.1843047034764826,
      "grad_norm": 2.463548183441162,
      "learning_rate": 2.4231882704519988e-05,
      "loss": 0.8421,
      "step": 22275
    },
    {
      "epoch": 1.1848856664807585,
      "grad_norm": 2.437021255493164,
      "learning_rate": 2.4202698916697798e-05,
      "loss": 1.1029,
      "step": 22300
    },
    {
      "epoch": 1.1854666294850345,
      "grad_norm": 1.6808406114578247,
      "learning_rate": 2.4173515128875608e-05,
      "loss": 0.9176,
      "step": 22325
    },
    {
      "epoch": 1.1860475924893104,
      "grad_norm": 2.201181173324585,
      "learning_rate": 2.414433134105342e-05,
      "loss": 1.0981,
      "step": 22350
    },
    {
      "epoch": 1.1866285554935863,
      "grad_norm": 1.3407255411148071,
      "learning_rate": 2.411514755323123e-05,
      "loss": 1.0973,
      "step": 22375
    },
    {
      "epoch": 1.1872095184978622,
      "grad_norm": 1.1051408052444458,
      "learning_rate": 2.4085963765409042e-05,
      "loss": 0.7791,
      "step": 22400
    },
    {
      "epoch": 1.1872095184978622,
      "eval_loss": 0.9154968857765198,
      "eval_runtime": 22.0146,
      "eval_samples_per_second": 181.697,
      "eval_steps_per_second": 45.424,
      "step": 22400
    },
    {
      "epoch": 1.1877904815021378,
      "grad_norm": 1.813710331916809,
      "learning_rate": 2.4056779977586853e-05,
      "loss": 1.0043,
      "step": 22425
    },
    {
      "epoch": 1.1883714445064137,
      "grad_norm": 1.4715404510498047,
      "learning_rate": 2.4027596189764663e-05,
      "loss": 0.9123,
      "step": 22450
    },
    {
      "epoch": 1.1889524075106896,
      "grad_norm": 2.0028879642486572,
      "learning_rate": 2.3998412401942473e-05,
      "loss": 1.1435,
      "step": 22475
    },
    {
      "epoch": 1.1895333705149655,
      "grad_norm": 2.235764741897583,
      "learning_rate": 2.3969228614120284e-05,
      "loss": 1.0097,
      "step": 22500
    },
    {
      "epoch": 1.1901143335192415,
      "grad_norm": 2.0162951946258545,
      "learning_rate": 2.3940044826298097e-05,
      "loss": 1.0927,
      "step": 22525
    },
    {
      "epoch": 1.1906952965235174,
      "grad_norm": 1.1804968118667603,
      "learning_rate": 2.3910861038475908e-05,
      "loss": 1.2208,
      "step": 22550
    },
    {
      "epoch": 1.1912762595277933,
      "grad_norm": 1.7609317302703857,
      "learning_rate": 2.3881677250653718e-05,
      "loss": 1.5331,
      "step": 22575
    },
    {
      "epoch": 1.1918572225320692,
      "grad_norm": 0.9574252963066101,
      "learning_rate": 2.3852493462831528e-05,
      "loss": 1.2395,
      "step": 22600
    },
    {
      "epoch": 1.1918572225320692,
      "eval_loss": 0.9157557487487793,
      "eval_runtime": 22.2343,
      "eval_samples_per_second": 179.903,
      "eval_steps_per_second": 44.976,
      "step": 22600
    },
    {
      "epoch": 1.192438185536345,
      "grad_norm": 1.3184705972671509,
      "learning_rate": 2.382330967500934e-05,
      "loss": 1.2429,
      "step": 22625
    },
    {
      "epoch": 1.193019148540621,
      "grad_norm": 1.7265125513076782,
      "learning_rate": 2.3794125887187152e-05,
      "loss": 1.763,
      "step": 22650
    },
    {
      "epoch": 1.1936001115448969,
      "grad_norm": 1.610924243927002,
      "learning_rate": 2.3764942099364962e-05,
      "loss": 0.6638,
      "step": 22675
    },
    {
      "epoch": 1.1941810745491728,
      "grad_norm": 1.5715599060058594,
      "learning_rate": 2.3735758311542773e-05,
      "loss": 0.6837,
      "step": 22700
    },
    {
      "epoch": 1.1947620375534487,
      "grad_norm": 1.1273795366287231,
      "learning_rate": 2.3706574523720583e-05,
      "loss": 1.0609,
      "step": 22725
    },
    {
      "epoch": 1.1953430005577246,
      "grad_norm": 1.4118010997772217,
      "learning_rate": 2.3677390735898393e-05,
      "loss": 1.0822,
      "step": 22750
    },
    {
      "epoch": 1.1959239635620005,
      "grad_norm": 3.21157169342041,
      "learning_rate": 2.3648206948076207e-05,
      "loss": 1.0622,
      "step": 22775
    },
    {
      "epoch": 1.1965049265662762,
      "grad_norm": 1.5164735317230225,
      "learning_rate": 2.3619023160254017e-05,
      "loss": 0.9528,
      "step": 22800
    },
    {
      "epoch": 1.1965049265662762,
      "eval_loss": 0.9087725281715393,
      "eval_runtime": 22.1695,
      "eval_samples_per_second": 180.428,
      "eval_steps_per_second": 45.107,
      "step": 22800
    },
    {
      "epoch": 1.197085889570552,
      "grad_norm": 1.3394986391067505,
      "learning_rate": 2.3589839372431828e-05,
      "loss": 1.07,
      "step": 22825
    },
    {
      "epoch": 1.197666852574828,
      "grad_norm": 2.344966173171997,
      "learning_rate": 2.3560655584609638e-05,
      "loss": 0.8959,
      "step": 22850
    },
    {
      "epoch": 1.1982478155791039,
      "grad_norm": 0.9131252765655518,
      "learning_rate": 2.3531471796787448e-05,
      "loss": 1.041,
      "step": 22875
    },
    {
      "epoch": 1.1988287785833798,
      "grad_norm": 2.328652858734131,
      "learning_rate": 2.3502288008965262e-05,
      "loss": 1.0817,
      "step": 22900
    },
    {
      "epoch": 1.1994097415876557,
      "grad_norm": 1.9273226261138916,
      "learning_rate": 2.3473104221143072e-05,
      "loss": 1.1421,
      "step": 22925
    },
    {
      "epoch": 1.1999907045919316,
      "grad_norm": 1.7039390802383423,
      "learning_rate": 2.3443920433320882e-05,
      "loss": 0.9954,
      "step": 22950
    },
    {
      "epoch": 1.2005716675962075,
      "grad_norm": 1.6412177085876465,
      "learning_rate": 2.3414736645498696e-05,
      "loss": 1.0785,
      "step": 22975
    },
    {
      "epoch": 1.2011526306004834,
      "grad_norm": 3.08791446685791,
      "learning_rate": 2.3385552857676503e-05,
      "loss": 1.1048,
      "step": 23000
    },
    {
      "epoch": 1.2011526306004834,
      "eval_loss": 0.9135785102844238,
      "eval_runtime": 22.2184,
      "eval_samples_per_second": 180.031,
      "eval_steps_per_second": 45.008,
      "step": 23000
    },
    {
      "epoch": 1.2017335936047593,
      "grad_norm": 1.3699983358383179,
      "learning_rate": 2.3356369069854317e-05,
      "loss": 1.4066,
      "step": 23025
    },
    {
      "epoch": 1.2023145566090352,
      "grad_norm": 1.6110676527023315,
      "learning_rate": 2.3327185282032127e-05,
      "loss": 0.9942,
      "step": 23050
    },
    {
      "epoch": 1.202895519613311,
      "grad_norm": 2.844163656234741,
      "learning_rate": 2.3298001494209937e-05,
      "loss": 0.6675,
      "step": 23075
    },
    {
      "epoch": 1.203476482617587,
      "grad_norm": 1.7155529260635376,
      "learning_rate": 2.326881770638775e-05,
      "loss": 0.6135,
      "step": 23100
    },
    {
      "epoch": 1.2040574456218627,
      "grad_norm": 1.5253092050552368,
      "learning_rate": 2.3239633918565558e-05,
      "loss": 0.6551,
      "step": 23125
    },
    {
      "epoch": 1.2046384086261388,
      "grad_norm": 1.0807430744171143,
      "learning_rate": 2.321045013074337e-05,
      "loss": 0.5822,
      "step": 23150
    },
    {
      "epoch": 1.2052193716304145,
      "grad_norm": 0.9868083596229553,
      "learning_rate": 2.3181266342921182e-05,
      "loss": 0.6092,
      "step": 23175
    },
    {
      "epoch": 1.2058003346346904,
      "grad_norm": 1.5044379234313965,
      "learning_rate": 2.3152082555098992e-05,
      "loss": 0.5195,
      "step": 23200
    },
    {
      "epoch": 1.2058003346346904,
      "eval_loss": 0.9069274663925171,
      "eval_runtime": 22.7408,
      "eval_samples_per_second": 175.895,
      "eval_steps_per_second": 43.974,
      "step": 23200
    },
    {
      "epoch": 1.2063812976389663,
      "grad_norm": 1.7024401426315308,
      "learning_rate": 2.3122898767276806e-05,
      "loss": 0.6667,
      "step": 23225
    },
    {
      "epoch": 1.2069622606432422,
      "grad_norm": 1.479944109916687,
      "learning_rate": 2.3093714979454613e-05,
      "loss": 0.6955,
      "step": 23250
    },
    {
      "epoch": 1.207543223647518,
      "grad_norm": 1.309046745300293,
      "learning_rate": 2.3064531191632423e-05,
      "loss": 0.5913,
      "step": 23275
    },
    {
      "epoch": 1.208124186651794,
      "grad_norm": 1.3824596405029297,
      "learning_rate": 2.3035347403810237e-05,
      "loss": 0.7977,
      "step": 23300
    },
    {
      "epoch": 1.20870514965607,
      "grad_norm": 1.0203338861465454,
      "learning_rate": 2.3006163615988047e-05,
      "loss": 0.8556,
      "step": 23325
    },
    {
      "epoch": 1.2092861126603458,
      "grad_norm": 1.7556439638137817,
      "learning_rate": 2.297697982816586e-05,
      "loss": 0.8182,
      "step": 23350
    },
    {
      "epoch": 1.2098670756646217,
      "grad_norm": 2.975050210952759,
      "learning_rate": 2.294779604034367e-05,
      "loss": 1.2538,
      "step": 23375
    },
    {
      "epoch": 1.2104480386688976,
      "grad_norm": 1.555702567100525,
      "learning_rate": 2.2918612252521478e-05,
      "loss": 1.3895,
      "step": 23400
    },
    {
      "epoch": 1.2104480386688976,
      "eval_loss": 0.9146645665168762,
      "eval_runtime": 22.2933,
      "eval_samples_per_second": 179.426,
      "eval_steps_per_second": 44.857,
      "step": 23400
    },
    {
      "epoch": 1.2110290016731735,
      "grad_norm": 1.7944642305374146,
      "learning_rate": 2.288942846469929e-05,
      "loss": 1.9492,
      "step": 23425
    },
    {
      "epoch": 1.2116099646774494,
      "grad_norm": 1.2486494779586792,
      "learning_rate": 2.2860244676877102e-05,
      "loss": 0.6375,
      "step": 23450
    },
    {
      "epoch": 1.2121909276817253,
      "grad_norm": 4.624693393707275,
      "learning_rate": 2.2831060889054915e-05,
      "loss": 1.1253,
      "step": 23475
    },
    {
      "epoch": 1.212771890686001,
      "grad_norm": 1.9343764781951904,
      "learning_rate": 2.2801877101232726e-05,
      "loss": 1.104,
      "step": 23500
    },
    {
      "epoch": 1.2133528536902771,
      "grad_norm": 1.5622315406799316,
      "learning_rate": 2.2772693313410533e-05,
      "loss": 0.8018,
      "step": 23525
    },
    {
      "epoch": 1.2139338166945528,
      "grad_norm": 2.3685901165008545,
      "learning_rate": 2.2743509525588346e-05,
      "loss": 0.7372,
      "step": 23550
    },
    {
      "epoch": 1.2145147796988287,
      "grad_norm": 1.8284523487091064,
      "learning_rate": 2.2714325737766157e-05,
      "loss": 1.0171,
      "step": 23575
    },
    {
      "epoch": 1.2150957427031046,
      "grad_norm": 2.9987215995788574,
      "learning_rate": 2.268514194994397e-05,
      "loss": 1.1164,
      "step": 23600
    },
    {
      "epoch": 1.2150957427031046,
      "eval_loss": 0.9131510257720947,
      "eval_runtime": 22.4072,
      "eval_samples_per_second": 178.514,
      "eval_steps_per_second": 44.629,
      "step": 23600
    },
    {
      "epoch": 1.2156767057073805,
      "grad_norm": 1.5461605787277222,
      "learning_rate": 2.265595816212178e-05,
      "loss": 1.1318,
      "step": 23625
    },
    {
      "epoch": 1.2162576687116564,
      "grad_norm": 1.3454041481018066,
      "learning_rate": 2.2626774374299587e-05,
      "loss": 1.0722,
      "step": 23650
    },
    {
      "epoch": 1.2168386317159323,
      "grad_norm": 1.469699740409851,
      "learning_rate": 2.25975905864774e-05,
      "loss": 0.9467,
      "step": 23675
    },
    {
      "epoch": 1.2174195947202082,
      "grad_norm": 1.2760661840438843,
      "learning_rate": 2.256840679865521e-05,
      "loss": 0.9304,
      "step": 23700
    },
    {
      "epoch": 1.2180005577244841,
      "grad_norm": 1.7619984149932861,
      "learning_rate": 2.2539223010833025e-05,
      "loss": 0.8972,
      "step": 23725
    },
    {
      "epoch": 1.21858152072876,
      "grad_norm": 0.548585057258606,
      "learning_rate": 2.2510039223010835e-05,
      "loss": 0.1579,
      "step": 23750
    },
    {
      "epoch": 1.219162483733036,
      "grad_norm": 0.2609090507030487,
      "learning_rate": 2.2480855435188646e-05,
      "loss": 0.0499,
      "step": 23775
    },
    {
      "epoch": 1.2197434467373118,
      "grad_norm": 2.1232011318206787,
      "learning_rate": 2.2451671647366456e-05,
      "loss": 0.3388,
      "step": 23800
    },
    {
      "epoch": 1.2197434467373118,
      "eval_loss": 0.9352173805236816,
      "eval_runtime": 21.81,
      "eval_samples_per_second": 183.402,
      "eval_steps_per_second": 45.85,
      "step": 23800
    },
    {
      "epoch": 1.2203244097415877,
      "grad_norm": 1.8924311399459839,
      "learning_rate": 2.2422487859544266e-05,
      "loss": 0.9656,
      "step": 23825
    },
    {
      "epoch": 1.2209053727458636,
      "grad_norm": 1.9472243785858154,
      "learning_rate": 2.239330407172208e-05,
      "loss": 0.8379,
      "step": 23850
    },
    {
      "epoch": 1.2214863357501393,
      "grad_norm": 1.353195071220398,
      "learning_rate": 2.236412028389989e-05,
      "loss": 0.9417,
      "step": 23875
    },
    {
      "epoch": 1.2220672987544154,
      "grad_norm": 2.1305038928985596,
      "learning_rate": 2.23349364960777e-05,
      "loss": 0.9852,
      "step": 23900
    },
    {
      "epoch": 1.2226482617586911,
      "grad_norm": 2.064291000366211,
      "learning_rate": 2.230575270825551e-05,
      "loss": 0.7734,
      "step": 23925
    },
    {
      "epoch": 1.223229224762967,
      "grad_norm": 1.9884328842163086,
      "learning_rate": 2.227656892043332e-05,
      "loss": 1.4738,
      "step": 23950
    },
    {
      "epoch": 1.223810187767243,
      "grad_norm": 1.4440797567367554,
      "learning_rate": 2.224738513261113e-05,
      "loss": 0.6049,
      "step": 23975
    },
    {
      "epoch": 1.2243911507715188,
      "grad_norm": 1.5477432012557983,
      "learning_rate": 2.2218201344788945e-05,
      "loss": 0.8846,
      "step": 24000
    },
    {
      "epoch": 1.2243911507715188,
      "eval_loss": 0.9173556566238403,
      "eval_runtime": 22.0983,
      "eval_samples_per_second": 181.009,
      "eval_steps_per_second": 45.252,
      "step": 24000
    },
    {
      "epoch": 1.2249721137757947,
      "grad_norm": 1.570956826210022,
      "learning_rate": 2.2189017556966755e-05,
      "loss": 0.5945,
      "step": 24025
    },
    {
      "epoch": 1.2255530767800706,
      "grad_norm": 2.393056631088257,
      "learning_rate": 2.2159833769144566e-05,
      "loss": 0.735,
      "step": 24050
    },
    {
      "epoch": 1.2261340397843465,
      "grad_norm": 2.042449474334717,
      "learning_rate": 2.2130649981322376e-05,
      "loss": 0.7869,
      "step": 24075
    },
    {
      "epoch": 1.2267150027886224,
      "grad_norm": 3.7703442573547363,
      "learning_rate": 2.2101466193500186e-05,
      "loss": 0.7578,
      "step": 24100
    },
    {
      "epoch": 1.2272959657928983,
      "grad_norm": 2.305859088897705,
      "learning_rate": 2.2072282405678e-05,
      "loss": 0.7955,
      "step": 24125
    },
    {
      "epoch": 1.2278769287971742,
      "grad_norm": 1.8566935062408447,
      "learning_rate": 2.204309861785581e-05,
      "loss": 0.7702,
      "step": 24150
    },
    {
      "epoch": 1.2284578918014502,
      "grad_norm": 2.6537766456604004,
      "learning_rate": 2.201391483003362e-05,
      "loss": 0.9196,
      "step": 24175
    },
    {
      "epoch": 1.229038854805726,
      "grad_norm": 1.814733624458313,
      "learning_rate": 2.198473104221143e-05,
      "loss": 0.9185,
      "step": 24200
    },
    {
      "epoch": 1.229038854805726,
      "eval_loss": 0.9147523641586304,
      "eval_runtime": 22.6211,
      "eval_samples_per_second": 176.826,
      "eval_steps_per_second": 44.207,
      "step": 24200
    },
    {
      "epoch": 1.229619817810002,
      "grad_norm": 1.859862208366394,
      "learning_rate": 2.195554725438924e-05,
      "loss": 0.9516,
      "step": 24225
    },
    {
      "epoch": 1.2302007808142776,
      "grad_norm": 3.6708970069885254,
      "learning_rate": 2.1926363466567055e-05,
      "loss": 0.9915,
      "step": 24250
    },
    {
      "epoch": 1.2307817438185535,
      "grad_norm": 2.3763322830200195,
      "learning_rate": 2.1897179678744865e-05,
      "loss": 1.0884,
      "step": 24275
    },
    {
      "epoch": 1.2313627068228294,
      "grad_norm": 2.8291726112365723,
      "learning_rate": 2.1867995890922675e-05,
      "loss": 1.4483,
      "step": 24300
    },
    {
      "epoch": 1.2319436698271053,
      "grad_norm": 2.5831408500671387,
      "learning_rate": 2.1838812103100486e-05,
      "loss": 1.1053,
      "step": 24325
    },
    {
      "epoch": 1.2325246328313813,
      "grad_norm": 1.2498414516448975,
      "learning_rate": 2.1809628315278296e-05,
      "loss": 0.9623,
      "step": 24350
    },
    {
      "epoch": 1.2331055958356572,
      "grad_norm": 2.3101954460144043,
      "learning_rate": 2.178044452745611e-05,
      "loss": 0.7206,
      "step": 24375
    },
    {
      "epoch": 1.233686558839933,
      "grad_norm": 1.622046947479248,
      "learning_rate": 2.175126073963392e-05,
      "loss": 0.7155,
      "step": 24400
    },
    {
      "epoch": 1.233686558839933,
      "eval_loss": 0.9130644202232361,
      "eval_runtime": 22.1799,
      "eval_samples_per_second": 180.343,
      "eval_steps_per_second": 45.086,
      "step": 24400
    },
    {
      "epoch": 1.234267521844209,
      "grad_norm": 1.6570650339126587,
      "learning_rate": 2.172207695181173e-05,
      "loss": 0.7106,
      "step": 24425
    },
    {
      "epoch": 1.2348484848484849,
      "grad_norm": 1.6821755170822144,
      "learning_rate": 2.169289316398954e-05,
      "loss": 0.6123,
      "step": 24450
    },
    {
      "epoch": 1.2354294478527608,
      "grad_norm": 2.4894800186157227,
      "learning_rate": 2.166370937616735e-05,
      "loss": 1.1702,
      "step": 24475
    },
    {
      "epoch": 1.2360104108570367,
      "grad_norm": 2.0308122634887695,
      "learning_rate": 2.1634525588345164e-05,
      "loss": 1.0173,
      "step": 24500
    },
    {
      "epoch": 1.2365913738613126,
      "grad_norm": 1.5737335681915283,
      "learning_rate": 2.1605341800522975e-05,
      "loss": 1.1484,
      "step": 24525
    },
    {
      "epoch": 1.2371723368655885,
      "grad_norm": 1.8311846256256104,
      "learning_rate": 2.157615801270079e-05,
      "loss": 1.0838,
      "step": 24550
    },
    {
      "epoch": 1.2377532998698644,
      "grad_norm": 1.186000943183899,
      "learning_rate": 2.1546974224878595e-05,
      "loss": 0.918,
      "step": 24575
    },
    {
      "epoch": 1.2383342628741403,
      "grad_norm": 1.9960274696350098,
      "learning_rate": 2.1517790437056406e-05,
      "loss": 1.3906,
      "step": 24600
    },
    {
      "epoch": 1.2383342628741403,
      "eval_loss": 0.914594292640686,
      "eval_runtime": 22.2257,
      "eval_samples_per_second": 179.972,
      "eval_steps_per_second": 44.993,
      "step": 24600
    },
    {
      "epoch": 1.238915225878416,
      "grad_norm": 1.7126928567886353,
      "learning_rate": 2.148860664923422e-05,
      "loss": 1.2475,
      "step": 24625
    },
    {
      "epoch": 1.2394961888826919,
      "grad_norm": 1.8448807001113892,
      "learning_rate": 2.145942286141203e-05,
      "loss": 1.4849,
      "step": 24650
    },
    {
      "epoch": 1.2400771518869678,
      "grad_norm": 2.3838672637939453,
      "learning_rate": 2.1430239073589843e-05,
      "loss": 1.0292,
      "step": 24675
    },
    {
      "epoch": 1.2406581148912437,
      "grad_norm": 2.361365795135498,
      "learning_rate": 2.140105528576765e-05,
      "loss": 1.0885,
      "step": 24700
    },
    {
      "epoch": 1.2412390778955196,
      "grad_norm": 1.4110509157180786,
      "learning_rate": 2.137187149794546e-05,
      "loss": 0.7229,
      "step": 24725
    },
    {
      "epoch": 1.2418200408997955,
      "grad_norm": 1.5960179567337036,
      "learning_rate": 2.1342687710123274e-05,
      "loss": 1.0698,
      "step": 24750
    },
    {
      "epoch": 1.2424010039040714,
      "grad_norm": 1.293492317199707,
      "learning_rate": 2.1313503922301084e-05,
      "loss": 0.9119,
      "step": 24775
    },
    {
      "epoch": 1.2429819669083473,
      "grad_norm": 1.7673262357711792,
      "learning_rate": 2.1284320134478895e-05,
      "loss": 0.8374,
      "step": 24800
    },
    {
      "epoch": 1.2429819669083473,
      "eval_loss": 0.9120287895202637,
      "eval_runtime": 22.1491,
      "eval_samples_per_second": 180.594,
      "eval_steps_per_second": 45.148,
      "step": 24800
    },
    {
      "epoch": 1.2435629299126232,
      "grad_norm": 1.9465782642364502,
      "learning_rate": 2.1255136346656705e-05,
      "loss": 0.642,
      "step": 24825
    },
    {
      "epoch": 1.244143892916899,
      "grad_norm": 2.5080504417419434,
      "learning_rate": 2.1225952558834515e-05,
      "loss": 0.6877,
      "step": 24850
    },
    {
      "epoch": 1.244724855921175,
      "grad_norm": 1.8782294988632202,
      "learning_rate": 2.119676877101233e-05,
      "loss": 0.5569,
      "step": 24875
    },
    {
      "epoch": 1.245305818925451,
      "grad_norm": 1.5895049571990967,
      "learning_rate": 2.116758498319014e-05,
      "loss": 0.5608,
      "step": 24900
    },
    {
      "epoch": 1.2458867819297268,
      "grad_norm": 2.32350754737854,
      "learning_rate": 2.113840119536795e-05,
      "loss": 0.6803,
      "step": 24925
    },
    {
      "epoch": 1.2464677449340027,
      "grad_norm": 1.12770414352417,
      "learning_rate": 2.1109217407545763e-05,
      "loss": 0.7654,
      "step": 24950
    },
    {
      "epoch": 1.2470487079382786,
      "grad_norm": 1.7168196439743042,
      "learning_rate": 2.108003361972357e-05,
      "loss": 0.7437,
      "step": 24975
    },
    {
      "epoch": 1.2476296709425543,
      "grad_norm": 1.404555082321167,
      "learning_rate": 2.1050849831901384e-05,
      "loss": 0.9646,
      "step": 25000
    },
    {
      "epoch": 1.2476296709425543,
      "eval_loss": 0.9085872769355774,
      "eval_runtime": 22.3457,
      "eval_samples_per_second": 179.006,
      "eval_steps_per_second": 44.751,
      "step": 25000
    },
    {
      "epoch": 1.2482106339468302,
      "grad_norm": 1.7940547466278076,
      "learning_rate": 2.1021666044079194e-05,
      "loss": 1.1502,
      "step": 25025
    },
    {
      "epoch": 1.248791596951106,
      "grad_norm": 1.5059645175933838,
      "learning_rate": 2.0992482256257004e-05,
      "loss": 1.1295,
      "step": 25050
    },
    {
      "epoch": 1.249372559955382,
      "grad_norm": 1.562130331993103,
      "learning_rate": 2.0963298468434818e-05,
      "loss": 1.117,
      "step": 25075
    },
    {
      "epoch": 1.249953522959658,
      "grad_norm": 0.9690702557563782,
      "learning_rate": 2.0934114680612625e-05,
      "loss": 0.9777,
      "step": 25100
    },
    {
      "epoch": 1.2505344859639338,
      "grad_norm": 1.299393653869629,
      "learning_rate": 2.090493089279044e-05,
      "loss": 0.9881,
      "step": 25125
    },
    {
      "epoch": 1.2511154489682097,
      "grad_norm": 1.2462458610534668,
      "learning_rate": 2.087574710496825e-05,
      "loss": 0.8857,
      "step": 25150
    },
    {
      "epoch": 1.2516964119724856,
      "grad_norm": 1.324357509613037,
      "learning_rate": 2.084656331714606e-05,
      "loss": 1.1472,
      "step": 25175
    },
    {
      "epoch": 1.2522773749767615,
      "grad_norm": 1.4057754278182983,
      "learning_rate": 2.0817379529323873e-05,
      "loss": 1.1801,
      "step": 25200
    },
    {
      "epoch": 1.2522773749767615,
      "eval_loss": 0.9111104607582092,
      "eval_runtime": 22.56,
      "eval_samples_per_second": 177.305,
      "eval_steps_per_second": 44.326,
      "step": 25200
    },
    {
      "epoch": 1.2528583379810374,
      "grad_norm": 1.6659865379333496,
      "learning_rate": 2.078819574150168e-05,
      "loss": 1.272,
      "step": 25225
    },
    {
      "epoch": 1.2534393009853133,
      "grad_norm": 1.1736143827438354,
      "learning_rate": 2.0759011953679493e-05,
      "loss": 1.0358,
      "step": 25250
    },
    {
      "epoch": 1.2540202639895892,
      "grad_norm": 2.0515613555908203,
      "learning_rate": 2.0729828165857304e-05,
      "loss": 0.9209,
      "step": 25275
    },
    {
      "epoch": 1.2546012269938651,
      "grad_norm": 1.466718077659607,
      "learning_rate": 2.0700644378035114e-05,
      "loss": 1.0052,
      "step": 25300
    },
    {
      "epoch": 1.2551821899981408,
      "grad_norm": 1.8549283742904663,
      "learning_rate": 2.0671460590212928e-05,
      "loss": 0.8658,
      "step": 25325
    },
    {
      "epoch": 1.255763153002417,
      "grad_norm": 0.9542954564094543,
      "learning_rate": 2.0642276802390738e-05,
      "loss": 0.8981,
      "step": 25350
    },
    {
      "epoch": 1.2563441160066926,
      "grad_norm": 1.7502336502075195,
      "learning_rate": 2.061309301456855e-05,
      "loss": 0.8487,
      "step": 25375
    },
    {
      "epoch": 1.2569250790109685,
      "grad_norm": 1.508339762687683,
      "learning_rate": 2.058390922674636e-05,
      "loss": 0.909,
      "step": 25400
    },
    {
      "epoch": 1.2569250790109685,
      "eval_loss": 0.9090855717658997,
      "eval_runtime": 22.2763,
      "eval_samples_per_second": 179.563,
      "eval_steps_per_second": 44.891,
      "step": 25400
    },
    {
      "epoch": 1.2575060420152444,
      "grad_norm": 1.557066798210144,
      "learning_rate": 2.055472543892417e-05,
      "loss": 0.8618,
      "step": 25425
    },
    {
      "epoch": 1.2580870050195203,
      "grad_norm": 2.220771312713623,
      "learning_rate": 2.0525541651101983e-05,
      "loss": 1.049,
      "step": 25450
    },
    {
      "epoch": 1.2586679680237962,
      "grad_norm": 1.5206544399261475,
      "learning_rate": 2.0496357863279793e-05,
      "loss": 0.8878,
      "step": 25475
    },
    {
      "epoch": 1.2592489310280721,
      "grad_norm": 0.978449821472168,
      "learning_rate": 2.0467174075457603e-05,
      "loss": 0.7937,
      "step": 25500
    },
    {
      "epoch": 1.259829894032348,
      "grad_norm": 1.7333682775497437,
      "learning_rate": 2.0437990287635413e-05,
      "loss": 0.9996,
      "step": 25525
    },
    {
      "epoch": 1.260410857036624,
      "grad_norm": 2.6525561809539795,
      "learning_rate": 2.0408806499813224e-05,
      "loss": 1.4461,
      "step": 25550
    },
    {
      "epoch": 1.2609918200408998,
      "grad_norm": 1.3970441818237305,
      "learning_rate": 2.0379622711991037e-05,
      "loss": 1.2913,
      "step": 25575
    },
    {
      "epoch": 1.2615727830451757,
      "grad_norm": 3.7134830951690674,
      "learning_rate": 2.0350438924168848e-05,
      "loss": 0.8966,
      "step": 25600
    },
    {
      "epoch": 1.2615727830451757,
      "eval_loss": 0.9125546813011169,
      "eval_runtime": 21.9301,
      "eval_samples_per_second": 182.398,
      "eval_steps_per_second": 45.599,
      "step": 25600
    },
    {
      "epoch": 1.2621537460494516,
      "grad_norm": 2.3472390174865723,
      "learning_rate": 2.0321255136346658e-05,
      "loss": 1.1749,
      "step": 25625
    },
    {
      "epoch": 1.2627347090537275,
      "grad_norm": 1.7623661756515503,
      "learning_rate": 2.0292071348524468e-05,
      "loss": 0.9267,
      "step": 25650
    },
    {
      "epoch": 1.2633156720580034,
      "grad_norm": 1.459049940109253,
      "learning_rate": 2.026288756070228e-05,
      "loss": 2.011,
      "step": 25675
    },
    {
      "epoch": 1.2638966350622791,
      "grad_norm": 1.2677557468414307,
      "learning_rate": 2.0233703772880092e-05,
      "loss": 1.0336,
      "step": 25700
    },
    {
      "epoch": 1.2644775980665552,
      "grad_norm": 1.6271454095840454,
      "learning_rate": 2.0204519985057903e-05,
      "loss": 0.6581,
      "step": 25725
    },
    {
      "epoch": 1.265058561070831,
      "grad_norm": 2.007291555404663,
      "learning_rate": 2.0175336197235713e-05,
      "loss": 0.6167,
      "step": 25750
    },
    {
      "epoch": 1.2656395240751068,
      "grad_norm": 1.0810478925704956,
      "learning_rate": 2.0146152409413523e-05,
      "loss": 0.8961,
      "step": 25775
    },
    {
      "epoch": 1.2662204870793827,
      "grad_norm": 1.0572915077209473,
      "learning_rate": 2.0116968621591333e-05,
      "loss": 0.9591,
      "step": 25800
    },
    {
      "epoch": 1.2662204870793827,
      "eval_loss": 0.911070704460144,
      "eval_runtime": 21.8996,
      "eval_samples_per_second": 182.652,
      "eval_steps_per_second": 45.663,
      "step": 25800
    },
    {
      "epoch": 1.2668014500836586,
      "grad_norm": 2.005631446838379,
      "learning_rate": 2.0087784833769147e-05,
      "loss": 1.3707,
      "step": 25825
    },
    {
      "epoch": 1.2673824130879345,
      "grad_norm": 1.1434473991394043,
      "learning_rate": 2.0058601045946957e-05,
      "loss": 1.1213,
      "step": 25850
    },
    {
      "epoch": 1.2679633760922104,
      "grad_norm": 1.2617180347442627,
      "learning_rate": 2.0029417258124768e-05,
      "loss": 0.8857,
      "step": 25875
    },
    {
      "epoch": 1.2685443390964863,
      "grad_norm": 1.8637288808822632,
      "learning_rate": 2.0000233470302578e-05,
      "loss": 0.83,
      "step": 25900
    },
    {
      "epoch": 1.2691253021007622,
      "grad_norm": 1.2748541831970215,
      "learning_rate": 1.9971049682480388e-05,
      "loss": 0.8764,
      "step": 25925
    },
    {
      "epoch": 1.2697062651050381,
      "grad_norm": 1.592728853225708,
      "learning_rate": 1.9941865894658202e-05,
      "loss": 0.6103,
      "step": 25950
    },
    {
      "epoch": 1.270287228109314,
      "grad_norm": 1.5838239192962646,
      "learning_rate": 1.9912682106836012e-05,
      "loss": 0.5915,
      "step": 25975
    },
    {
      "epoch": 1.27086819111359,
      "grad_norm": 1.9114562273025513,
      "learning_rate": 1.9883498319013823e-05,
      "loss": 0.8138,
      "step": 26000
    },
    {
      "epoch": 1.27086819111359,
      "eval_loss": 0.909254789352417,
      "eval_runtime": 22.3619,
      "eval_samples_per_second": 178.876,
      "eval_steps_per_second": 44.719,
      "step": 26000
    },
    {
      "epoch": 1.2714491541178659,
      "grad_norm": 2.1312623023986816,
      "learning_rate": 1.9854314531191633e-05,
      "loss": 0.7477,
      "step": 26025
    },
    {
      "epoch": 1.2720301171221418,
      "grad_norm": 1.1712262630462646,
      "learning_rate": 1.9825130743369443e-05,
      "loss": 0.7846,
      "step": 26050
    },
    {
      "epoch": 1.2726110801264174,
      "grad_norm": 1.305667757987976,
      "learning_rate": 1.9795946955547257e-05,
      "loss": 0.6465,
      "step": 26075
    },
    {
      "epoch": 1.2731920431306936,
      "grad_norm": 1.412774682044983,
      "learning_rate": 1.9766763167725067e-05,
      "loss": 0.643,
      "step": 26100
    },
    {
      "epoch": 1.2737730061349692,
      "grad_norm": 1.4857901334762573,
      "learning_rate": 1.9737579379902877e-05,
      "loss": 0.71,
      "step": 26125
    },
    {
      "epoch": 1.2743539691392451,
      "grad_norm": 1.8435273170471191,
      "learning_rate": 1.9708395592080688e-05,
      "loss": 0.6755,
      "step": 26150
    },
    {
      "epoch": 1.274934932143521,
      "grad_norm": 24.065383911132812,
      "learning_rate": 1.9679211804258498e-05,
      "loss": 0.7889,
      "step": 26175
    },
    {
      "epoch": 1.275515895147797,
      "grad_norm": 2.292489767074585,
      "learning_rate": 1.965002801643631e-05,
      "loss": 0.6848,
      "step": 26200
    },
    {
      "epoch": 1.275515895147797,
      "eval_loss": 0.9127381443977356,
      "eval_runtime": 22.7704,
      "eval_samples_per_second": 175.667,
      "eval_steps_per_second": 43.917,
      "step": 26200
    },
    {
      "epoch": 1.2760968581520729,
      "grad_norm": 1.8707636594772339,
      "learning_rate": 1.9620844228614122e-05,
      "loss": 0.6647,
      "step": 26225
    },
    {
      "epoch": 1.2766778211563488,
      "grad_norm": 2.462324619293213,
      "learning_rate": 1.9591660440791932e-05,
      "loss": 0.7393,
      "step": 26250
    },
    {
      "epoch": 1.2772587841606247,
      "grad_norm": 1.648099660873413,
      "learning_rate": 1.9562476652969743e-05,
      "loss": 0.805,
      "step": 26275
    },
    {
      "epoch": 1.2778397471649006,
      "grad_norm": 1.5760751962661743,
      "learning_rate": 1.9533292865147553e-05,
      "loss": 1.249,
      "step": 26300
    },
    {
      "epoch": 1.2784207101691765,
      "grad_norm": 1.8528140783309937,
      "learning_rate": 1.9504109077325366e-05,
      "loss": 0.9388,
      "step": 26325
    },
    {
      "epoch": 1.2790016731734524,
      "grad_norm": 1.5092551708221436,
      "learning_rate": 1.9474925289503177e-05,
      "loss": 1.0171,
      "step": 26350
    },
    {
      "epoch": 1.2795826361777283,
      "grad_norm": 1.7756109237670898,
      "learning_rate": 1.9445741501680987e-05,
      "loss": 0.7241,
      "step": 26375
    },
    {
      "epoch": 1.280163599182004,
      "grad_norm": 1.3580124378204346,
      "learning_rate": 1.9416557713858797e-05,
      "loss": 0.6367,
      "step": 26400
    },
    {
      "epoch": 1.280163599182004,
      "eval_loss": 0.9070433378219604,
      "eval_runtime": 22.4589,
      "eval_samples_per_second": 178.103,
      "eval_steps_per_second": 44.526,
      "step": 26400
    },
    {
      "epoch": 1.28074456218628,
      "grad_norm": 1.925614595413208,
      "learning_rate": 1.9387373926036608e-05,
      "loss": 0.8063,
      "step": 26425
    },
    {
      "epoch": 1.2813255251905558,
      "grad_norm": 1.0238755941390991,
      "learning_rate": 1.9358190138214418e-05,
      "loss": 0.9411,
      "step": 26450
    },
    {
      "epoch": 1.2819064881948319,
      "grad_norm": 1.4184263944625854,
      "learning_rate": 1.932900635039223e-05,
      "loss": 0.8635,
      "step": 26475
    },
    {
      "epoch": 1.2824874511991076,
      "grad_norm": 1.414475679397583,
      "learning_rate": 1.9299822562570042e-05,
      "loss": 1.2796,
      "step": 26500
    },
    {
      "epoch": 1.2830684142033835,
      "grad_norm": 1.1932615041732788,
      "learning_rate": 1.9270638774747856e-05,
      "loss": 1.0331,
      "step": 26525
    },
    {
      "epoch": 1.2836493772076594,
      "grad_norm": 1.257018804550171,
      "learning_rate": 1.9241454986925662e-05,
      "loss": 1.0903,
      "step": 26550
    },
    {
      "epoch": 1.2842303402119353,
      "grad_norm": 2.277412176132202,
      "learning_rate": 1.9212271199103473e-05,
      "loss": 1.2015,
      "step": 26575
    },
    {
      "epoch": 1.2848113032162112,
      "grad_norm": 2.1897435188293457,
      "learning_rate": 1.9183087411281286e-05,
      "loss": 1.4976,
      "step": 26600
    },
    {
      "epoch": 1.2848113032162112,
      "eval_loss": 0.9062196612358093,
      "eval_runtime": 22.3321,
      "eval_samples_per_second": 179.114,
      "eval_steps_per_second": 44.779,
      "step": 26600
    },
    {
      "epoch": 1.285392266220487,
      "grad_norm": 1.381913423538208,
      "learning_rate": 1.9153903623459097e-05,
      "loss": 1.1579,
      "step": 26625
    },
    {
      "epoch": 1.285973229224763,
      "grad_norm": 1.3697162866592407,
      "learning_rate": 1.912471983563691e-05,
      "loss": 0.9433,
      "step": 26650
    },
    {
      "epoch": 1.2865541922290389,
      "grad_norm": 1.5021052360534668,
      "learning_rate": 1.9095536047814717e-05,
      "loss": 1.0206,
      "step": 26675
    },
    {
      "epoch": 1.2871351552333148,
      "grad_norm": 1.7156133651733398,
      "learning_rate": 1.9066352259992528e-05,
      "loss": 0.7668,
      "step": 26700
    },
    {
      "epoch": 1.2877161182375907,
      "grad_norm": 1.0426063537597656,
      "learning_rate": 1.903716847217034e-05,
      "loss": 1.1587,
      "step": 26725
    },
    {
      "epoch": 1.2882970812418666,
      "grad_norm": 1.4869788885116577,
      "learning_rate": 1.900798468434815e-05,
      "loss": 1.0371,
      "step": 26750
    },
    {
      "epoch": 1.2888780442461423,
      "grad_norm": 1.2909965515136719,
      "learning_rate": 1.8978800896525965e-05,
      "loss": 1.3465,
      "step": 26775
    },
    {
      "epoch": 1.2894590072504184,
      "grad_norm": 1.7304054498672485,
      "learning_rate": 1.8949617108703772e-05,
      "loss": 1.0661,
      "step": 26800
    },
    {
      "epoch": 1.2894590072504184,
      "eval_loss": 0.9069137573242188,
      "eval_runtime": 22.1578,
      "eval_samples_per_second": 180.523,
      "eval_steps_per_second": 45.131,
      "step": 26800
    },
    {
      "epoch": 1.290039970254694,
      "grad_norm": 1.3616646528244019,
      "learning_rate": 1.8920433320881582e-05,
      "loss": 0.7973,
      "step": 26825
    },
    {
      "epoch": 1.2906209332589702,
      "grad_norm": 2.7297616004943848,
      "learning_rate": 1.8891249533059396e-05,
      "loss": 0.8681,
      "step": 26850
    },
    {
      "epoch": 1.2912018962632459,
      "grad_norm": 1.5137320756912231,
      "learning_rate": 1.8862065745237206e-05,
      "loss": 1.2465,
      "step": 26875
    },
    {
      "epoch": 1.2917828592675218,
      "grad_norm": 1.2829970121383667,
      "learning_rate": 1.883288195741502e-05,
      "loss": 0.6772,
      "step": 26900
    },
    {
      "epoch": 1.2923638222717977,
      "grad_norm": 1.3493937253952026,
      "learning_rate": 1.880369816959283e-05,
      "loss": 0.4946,
      "step": 26925
    },
    {
      "epoch": 1.2929447852760736,
      "grad_norm": 2.6213700771331787,
      "learning_rate": 1.8774514381770637e-05,
      "loss": 1.0608,
      "step": 26950
    },
    {
      "epoch": 1.2935257482803495,
      "grad_norm": 1.5638928413391113,
      "learning_rate": 1.874533059394845e-05,
      "loss": 1.2318,
      "step": 26975
    },
    {
      "epoch": 1.2941067112846254,
      "grad_norm": 1.9692564010620117,
      "learning_rate": 1.871614680612626e-05,
      "loss": 1.0887,
      "step": 27000
    },
    {
      "epoch": 1.2941067112846254,
      "eval_loss": 0.9069462418556213,
      "eval_runtime": 22.6353,
      "eval_samples_per_second": 176.715,
      "eval_steps_per_second": 44.179,
      "step": 27000
    },
    {
      "epoch": 1.2946876742889013,
      "grad_norm": 3.0320770740509033,
      "learning_rate": 1.8686963018304075e-05,
      "loss": 1.7022,
      "step": 27025
    },
    {
      "epoch": 1.2952686372931772,
      "grad_norm": 0.945061206817627,
      "learning_rate": 1.8657779230481885e-05,
      "loss": 1.768,
      "step": 27050
    },
    {
      "epoch": 1.295849600297453,
      "grad_norm": 1.1881517171859741,
      "learning_rate": 1.8628595442659692e-05,
      "loss": 1.7393,
      "step": 27075
    },
    {
      "epoch": 1.296430563301729,
      "grad_norm": 1.8249011039733887,
      "learning_rate": 1.8599411654837506e-05,
      "loss": 1.1821,
      "step": 27100
    },
    {
      "epoch": 1.297011526306005,
      "grad_norm": 1.3766217231750488,
      "learning_rate": 1.8570227867015316e-05,
      "loss": 1.0601,
      "step": 27125
    },
    {
      "epoch": 1.2975924893102806,
      "grad_norm": 1.659844994544983,
      "learning_rate": 1.8541044079193126e-05,
      "loss": 1.1523,
      "step": 27150
    },
    {
      "epoch": 1.2981734523145567,
      "grad_norm": 3.82174015045166,
      "learning_rate": 1.851186029137094e-05,
      "loss": 1.2758,
      "step": 27175
    },
    {
      "epoch": 1.2987544153188324,
      "grad_norm": 3.6573970317840576,
      "learning_rate": 1.848267650354875e-05,
      "loss": 0.9874,
      "step": 27200
    },
    {
      "epoch": 1.2987544153188324,
      "eval_loss": 0.910369873046875,
      "eval_runtime": 22.8671,
      "eval_samples_per_second": 174.924,
      "eval_steps_per_second": 43.731,
      "step": 27200
    },
    {
      "epoch": 1.2993353783231083,
      "grad_norm": 1.238417387008667,
      "learning_rate": 1.845349271572656e-05,
      "loss": 0.9701,
      "step": 27225
    },
    {
      "epoch": 1.2999163413273842,
      "grad_norm": 2.540879249572754,
      "learning_rate": 1.842430892790437e-05,
      "loss": 0.374,
      "step": 27250
    },
    {
      "epoch": 1.30049730433166,
      "grad_norm": 1.409387469291687,
      "learning_rate": 1.839512514008218e-05,
      "loss": 0.3335,
      "step": 27275
    },
    {
      "epoch": 1.301078267335936,
      "grad_norm": 1.6223516464233398,
      "learning_rate": 1.8365941352259995e-05,
      "loss": 0.3807,
      "step": 27300
    },
    {
      "epoch": 1.301659230340212,
      "grad_norm": 4.112948894500732,
      "learning_rate": 1.8336757564437805e-05,
      "loss": 0.8798,
      "step": 27325
    },
    {
      "epoch": 1.3022401933444878,
      "grad_norm": 1.6353379487991333,
      "learning_rate": 1.8307573776615616e-05,
      "loss": 0.7206,
      "step": 27350
    },
    {
      "epoch": 1.3028211563487637,
      "grad_norm": 1.7714698314666748,
      "learning_rate": 1.8278389988793426e-05,
      "loss": 0.7163,
      "step": 27375
    },
    {
      "epoch": 1.3034021193530396,
      "grad_norm": 1.0861852169036865,
      "learning_rate": 1.8249206200971236e-05,
      "loss": 0.7051,
      "step": 27400
    },
    {
      "epoch": 1.3034021193530396,
      "eval_loss": 0.906771183013916,
      "eval_runtime": 22.4929,
      "eval_samples_per_second": 177.834,
      "eval_steps_per_second": 44.458,
      "step": 27400
    },
    {
      "epoch": 1.3039830823573155,
      "grad_norm": 1.3395122289657593,
      "learning_rate": 1.822002241314905e-05,
      "loss": 0.7291,
      "step": 27425
    },
    {
      "epoch": 1.3045640453615914,
      "grad_norm": 1.8813750743865967,
      "learning_rate": 1.819083862532686e-05,
      "loss": 0.7447,
      "step": 27450
    },
    {
      "epoch": 1.3051450083658673,
      "grad_norm": 1.2641983032226562,
      "learning_rate": 1.816165483750467e-05,
      "loss": 0.7785,
      "step": 27475
    },
    {
      "epoch": 1.3057259713701432,
      "grad_norm": 1.342246651649475,
      "learning_rate": 1.813247104968248e-05,
      "loss": 0.8105,
      "step": 27500
    },
    {
      "epoch": 1.306306934374419,
      "grad_norm": 0.959242045879364,
      "learning_rate": 1.810328726186029e-05,
      "loss": 0.856,
      "step": 27525
    },
    {
      "epoch": 1.306887897378695,
      "grad_norm": 1.5268306732177734,
      "learning_rate": 1.8074103474038105e-05,
      "loss": 0.7661,
      "step": 27550
    },
    {
      "epoch": 1.3074688603829707,
      "grad_norm": 1.6408079862594604,
      "learning_rate": 1.8044919686215915e-05,
      "loss": 1.0494,
      "step": 27575
    },
    {
      "epoch": 1.3080498233872466,
      "grad_norm": 1.2512418031692505,
      "learning_rate": 1.8015735898393725e-05,
      "loss": 0.774,
      "step": 27600
    },
    {
      "epoch": 1.3080498233872466,
      "eval_loss": 0.9049863815307617,
      "eval_runtime": 22.9873,
      "eval_samples_per_second": 174.009,
      "eval_steps_per_second": 43.502,
      "step": 27600
    },
    {
      "epoch": 1.3086307863915225,
      "grad_norm": 2.060389518737793,
      "learning_rate": 1.7986552110571535e-05,
      "loss": 0.9684,
      "step": 27625
    },
    {
      "epoch": 1.3092117493957984,
      "grad_norm": 2.3313539028167725,
      "learning_rate": 1.7957368322749346e-05,
      "loss": 1.1215,
      "step": 27650
    },
    {
      "epoch": 1.3097927124000743,
      "grad_norm": 1.1080409288406372,
      "learning_rate": 1.792818453492716e-05,
      "loss": 0.9789,
      "step": 27675
    },
    {
      "epoch": 1.3103736754043502,
      "grad_norm": 1.6030235290527344,
      "learning_rate": 1.789900074710497e-05,
      "loss": 1.2015,
      "step": 27700
    },
    {
      "epoch": 1.3109546384086261,
      "grad_norm": 1.5329011678695679,
      "learning_rate": 1.786981695928278e-05,
      "loss": 1.068,
      "step": 27725
    },
    {
      "epoch": 1.311535601412902,
      "grad_norm": 2.697298765182495,
      "learning_rate": 1.784063317146059e-05,
      "loss": 2.0468,
      "step": 27750
    },
    {
      "epoch": 1.312116564417178,
      "grad_norm": 2.079073429107666,
      "learning_rate": 1.78114493836384e-05,
      "loss": 1.5379,
      "step": 27775
    },
    {
      "epoch": 1.3126975274214538,
      "grad_norm": 1.6700102090835571,
      "learning_rate": 1.7782265595816214e-05,
      "loss": 0.8765,
      "step": 27800
    },
    {
      "epoch": 1.3126975274214538,
      "eval_loss": 0.912017822265625,
      "eval_runtime": 22.4254,
      "eval_samples_per_second": 178.369,
      "eval_steps_per_second": 44.592,
      "step": 27800
    },
    {
      "epoch": 1.3132784904257297,
      "grad_norm": 2.3821041584014893,
      "learning_rate": 1.7753081807994025e-05,
      "loss": 0.9871,
      "step": 27825
    },
    {
      "epoch": 1.3138594534300057,
      "grad_norm": 2.203371047973633,
      "learning_rate": 1.7723898020171835e-05,
      "loss": 0.8301,
      "step": 27850
    },
    {
      "epoch": 1.3144404164342816,
      "grad_norm": 2.9803006649017334,
      "learning_rate": 1.7694714232349645e-05,
      "loss": 1.1717,
      "step": 27875
    },
    {
      "epoch": 1.3150213794385572,
      "grad_norm": 1.8445466756820679,
      "learning_rate": 1.7665530444527455e-05,
      "loss": 0.9397,
      "step": 27900
    },
    {
      "epoch": 1.3156023424428334,
      "grad_norm": 1.615143895149231,
      "learning_rate": 1.763634665670527e-05,
      "loss": 1.4793,
      "step": 27925
    },
    {
      "epoch": 1.316183305447109,
      "grad_norm": 1.0385644435882568,
      "learning_rate": 1.760716286888308e-05,
      "loss": 1.1959,
      "step": 27950
    },
    {
      "epoch": 1.316764268451385,
      "grad_norm": 2.1585988998413086,
      "learning_rate": 1.757797908106089e-05,
      "loss": 1.0807,
      "step": 27975
    },
    {
      "epoch": 1.3173452314556608,
      "grad_norm": 1.2854139804840088,
      "learning_rate": 1.75487952932387e-05,
      "loss": 1.096,
      "step": 28000
    },
    {
      "epoch": 1.3173452314556608,
      "eval_loss": 0.910554051399231,
      "eval_runtime": 22.3035,
      "eval_samples_per_second": 179.344,
      "eval_steps_per_second": 44.836,
      "step": 28000
    },
    {
      "epoch": 1.3179261944599368,
      "grad_norm": 2.2785332202911377,
      "learning_rate": 1.751961150541651e-05,
      "loss": 1.4449,
      "step": 28025
    },
    {
      "epoch": 1.3185071574642127,
      "grad_norm": 2.6558640003204346,
      "learning_rate": 1.7490427717594324e-05,
      "loss": 1.7117,
      "step": 28050
    },
    {
      "epoch": 1.3190881204684886,
      "grad_norm": 1.8139166831970215,
      "learning_rate": 1.7461243929772134e-05,
      "loss": 1.6434,
      "step": 28075
    },
    {
      "epoch": 1.3196690834727645,
      "grad_norm": 1.665520191192627,
      "learning_rate": 1.7432060141949945e-05,
      "loss": 1.1384,
      "step": 28100
    },
    {
      "epoch": 1.3202500464770404,
      "grad_norm": 1.2549645900726318,
      "learning_rate": 1.7402876354127755e-05,
      "loss": 1.3509,
      "step": 28125
    },
    {
      "epoch": 1.3208310094813163,
      "grad_norm": 1.1036341190338135,
      "learning_rate": 1.7373692566305565e-05,
      "loss": 0.991,
      "step": 28150
    },
    {
      "epoch": 1.3214119724855922,
      "grad_norm": 1.065321445465088,
      "learning_rate": 1.734450877848338e-05,
      "loss": 0.609,
      "step": 28175
    },
    {
      "epoch": 1.321992935489868,
      "grad_norm": 3.4263622760772705,
      "learning_rate": 1.731532499066119e-05,
      "loss": 0.6221,
      "step": 28200
    },
    {
      "epoch": 1.321992935489868,
      "eval_loss": 0.9052242636680603,
      "eval_runtime": 22.412,
      "eval_samples_per_second": 178.476,
      "eval_steps_per_second": 44.619,
      "step": 28200
    },
    {
      "epoch": 1.322573898494144,
      "grad_norm": 1.6691832542419434,
      "learning_rate": 1.7286141202839e-05,
      "loss": 0.5412,
      "step": 28225
    },
    {
      "epoch": 1.3231548614984199,
      "grad_norm": 1.4370982646942139,
      "learning_rate": 1.725695741501681e-05,
      "loss": 0.2905,
      "step": 28250
    },
    {
      "epoch": 1.3237358245026956,
      "grad_norm": 2.0469272136688232,
      "learning_rate": 1.722777362719462e-05,
      "loss": 0.3972,
      "step": 28275
    },
    {
      "epoch": 1.3243167875069717,
      "grad_norm": 1.421133279800415,
      "learning_rate": 1.7198589839372434e-05,
      "loss": 1.1724,
      "step": 28300
    },
    {
      "epoch": 1.3248977505112474,
      "grad_norm": 2.3713929653167725,
      "learning_rate": 1.7169406051550244e-05,
      "loss": 1.0478,
      "step": 28325
    },
    {
      "epoch": 1.3254787135155233,
      "grad_norm": 2.1960177421569824,
      "learning_rate": 1.7140222263728054e-05,
      "loss": 1.114,
      "step": 28350
    },
    {
      "epoch": 1.3260596765197992,
      "grad_norm": 1.4443570375442505,
      "learning_rate": 1.7111038475905865e-05,
      "loss": 0.891,
      "step": 28375
    },
    {
      "epoch": 1.326640639524075,
      "grad_norm": 2.153076171875,
      "learning_rate": 1.7081854688083675e-05,
      "loss": 0.8094,
      "step": 28400
    },
    {
      "epoch": 1.326640639524075,
      "eval_loss": 0.9070335626602173,
      "eval_runtime": 22.5129,
      "eval_samples_per_second": 177.676,
      "eval_steps_per_second": 44.419,
      "step": 28400
    },
    {
      "epoch": 1.327221602528351,
      "grad_norm": 2.2638678550720215,
      "learning_rate": 1.705267090026149e-05,
      "loss": 0.9013,
      "step": 28425
    },
    {
      "epoch": 1.3278025655326269,
      "grad_norm": 1.3024682998657227,
      "learning_rate": 1.70234871124393e-05,
      "loss": 0.095,
      "step": 28450
    },
    {
      "epoch": 1.3283835285369028,
      "grad_norm": 1.779198408126831,
      "learning_rate": 1.699430332461711e-05,
      "loss": 0.1328,
      "step": 28475
    },
    {
      "epoch": 1.3289644915411787,
      "grad_norm": 2.7291769981384277,
      "learning_rate": 1.6965119536794923e-05,
      "loss": 0.9521,
      "step": 28500
    },
    {
      "epoch": 1.3295454545454546,
      "grad_norm": 1.7310404777526855,
      "learning_rate": 1.693593574897273e-05,
      "loss": 0.989,
      "step": 28525
    },
    {
      "epoch": 1.3301264175497305,
      "grad_norm": 3.2344791889190674,
      "learning_rate": 1.6906751961150543e-05,
      "loss": 1.0224,
      "step": 28550
    },
    {
      "epoch": 1.3307073805540064,
      "grad_norm": 2.1507973670959473,
      "learning_rate": 1.6877568173328354e-05,
      "loss": 0.7989,
      "step": 28575
    },
    {
      "epoch": 1.331288343558282,
      "grad_norm": 1.4633018970489502,
      "learning_rate": 1.6848384385506164e-05,
      "loss": 1.0,
      "step": 28600
    },
    {
      "epoch": 1.331288343558282,
      "eval_loss": 0.9057018756866455,
      "eval_runtime": 20.8674,
      "eval_samples_per_second": 191.687,
      "eval_steps_per_second": 47.922,
      "step": 28600
    },
    {
      "epoch": 1.3318693065625582,
      "grad_norm": 1.4474296569824219,
      "learning_rate": 1.6819200597683978e-05,
      "loss": 0.9951,
      "step": 28625
    },
    {
      "epoch": 1.3324502695668339,
      "grad_norm": 1.6728342771530151,
      "learning_rate": 1.6790016809861785e-05,
      "loss": 1.0172,
      "step": 28650
    },
    {
      "epoch": 1.33303123257111,
      "grad_norm": 2.056865930557251,
      "learning_rate": 1.6760833022039598e-05,
      "loss": 1.6271,
      "step": 28675
    },
    {
      "epoch": 2.0002788622420526,
      "grad_norm": 1.8800718784332275,
      "learning_rate": 1.673164923421741e-05,
      "loss": 1.2318,
      "step": 28700
    },
    {
      "epoch": 2.0008598252463283,
      "grad_norm": 1.8393750190734863,
      "learning_rate": 1.670246544639522e-05,
      "loss": 0.8654,
      "step": 28725
    },
    {
      "epoch": 2.001440788250604,
      "grad_norm": 2.8929803371429443,
      "learning_rate": 1.6673281658573032e-05,
      "loss": 1.0916,
      "step": 28750
    },
    {
      "epoch": 2.00202175125488,
      "grad_norm": 1.3585728406906128,
      "learning_rate": 1.664409787075084e-05,
      "loss": 1.0074,
      "step": 28775
    },
    {
      "epoch": 2.002602714259156,
      "grad_norm": 2.412916898727417,
      "learning_rate": 1.661491408292865e-05,
      "loss": 0.8752,
      "step": 28800
    },
    {
      "epoch": 2.002602714259156,
      "eval_loss": 0.9050959944725037,
      "eval_runtime": 20.9759,
      "eval_samples_per_second": 190.695,
      "eval_steps_per_second": 47.674,
      "step": 28800
    },
    {
      "epoch": 2.003183677263432,
      "grad_norm": 3.7513535022735596,
      "learning_rate": 1.6585730295106463e-05,
      "loss": 0.4296,
      "step": 28825
    },
    {
      "epoch": 2.0037646402677076,
      "grad_norm": 2.102849006652832,
      "learning_rate": 1.6556546507284274e-05,
      "loss": 0.5209,
      "step": 28850
    },
    {
      "epoch": 2.0043456032719837,
      "grad_norm": 1.1455566883087158,
      "learning_rate": 1.6527362719462087e-05,
      "loss": 0.829,
      "step": 28875
    },
    {
      "epoch": 2.0049265662762594,
      "grad_norm": 1.6273523569107056,
      "learning_rate": 1.6498178931639898e-05,
      "loss": 1.1148,
      "step": 28900
    },
    {
      "epoch": 2.0055075292805356,
      "grad_norm": 1.289753794670105,
      "learning_rate": 1.6468995143817704e-05,
      "loss": 1.23,
      "step": 28925
    },
    {
      "epoch": 2.0060884922848112,
      "grad_norm": 1.6816127300262451,
      "learning_rate": 1.6439811355995518e-05,
      "loss": 1.0561,
      "step": 28950
    },
    {
      "epoch": 2.0066694552890874,
      "grad_norm": 1.2521530389785767,
      "learning_rate": 1.641062756817333e-05,
      "loss": 1.0206,
      "step": 28975
    },
    {
      "epoch": 2.007250418293363,
      "grad_norm": 1.6570515632629395,
      "learning_rate": 1.6381443780351142e-05,
      "loss": 1.0409,
      "step": 29000
    },
    {
      "epoch": 2.007250418293363,
      "eval_loss": 0.9040507674217224,
      "eval_runtime": 22.5524,
      "eval_samples_per_second": 177.365,
      "eval_steps_per_second": 44.341,
      "step": 29000
    },
    {
      "epoch": 2.007831381297639,
      "grad_norm": 2.723193883895874,
      "learning_rate": 1.6352259992528952e-05,
      "loss": 1.305,
      "step": 29025
    },
    {
      "epoch": 2.008412344301915,
      "grad_norm": 1.3649780750274658,
      "learning_rate": 1.632307620470676e-05,
      "loss": 1.0384,
      "step": 29050
    },
    {
      "epoch": 2.0089933073061905,
      "grad_norm": 1.8720388412475586,
      "learning_rate": 1.6293892416884573e-05,
      "loss": 0.697,
      "step": 29075
    },
    {
      "epoch": 2.0095742703104666,
      "grad_norm": 1.7047475576400757,
      "learning_rate": 1.6264708629062383e-05,
      "loss": 0.6063,
      "step": 29100
    },
    {
      "epoch": 2.0101552333147423,
      "grad_norm": 1.170533299446106,
      "learning_rate": 1.6235524841240197e-05,
      "loss": 0.7039,
      "step": 29125
    },
    {
      "epoch": 2.0107361963190185,
      "grad_norm": 1.6053370237350464,
      "learning_rate": 1.6206341053418007e-05,
      "loss": 1.0825,
      "step": 29150
    },
    {
      "epoch": 2.011317159323294,
      "grad_norm": 2.4272444248199463,
      "learning_rate": 1.6177157265595818e-05,
      "loss": 1.7842,
      "step": 29175
    },
    {
      "epoch": 2.0118981223275703,
      "grad_norm": 1.9315385818481445,
      "learning_rate": 1.6147973477773628e-05,
      "loss": 1.6022,
      "step": 29200
    },
    {
      "epoch": 2.0118981223275703,
      "eval_loss": 0.9050731062889099,
      "eval_runtime": 22.4942,
      "eval_samples_per_second": 177.823,
      "eval_steps_per_second": 44.456,
      "step": 29200
    },
    {
      "epoch": 2.012479085331846,
      "grad_norm": 1.4484970569610596,
      "learning_rate": 1.6118789689951438e-05,
      "loss": 1.581,
      "step": 29225
    },
    {
      "epoch": 2.013060048336122,
      "grad_norm": 2.6307625770568848,
      "learning_rate": 1.6089605902129252e-05,
      "loss": 1.5335,
      "step": 29250
    },
    {
      "epoch": 2.0136410113403977,
      "grad_norm": 2.227010726928711,
      "learning_rate": 1.6060422114307062e-05,
      "loss": 0.933,
      "step": 29275
    },
    {
      "epoch": 2.014221974344674,
      "grad_norm": 1.6779594421386719,
      "learning_rate": 1.6031238326484872e-05,
      "loss": 1.1821,
      "step": 29300
    },
    {
      "epoch": 2.0148029373489496,
      "grad_norm": 1.6145763397216797,
      "learning_rate": 1.6002054538662683e-05,
      "loss": 1.2296,
      "step": 29325
    },
    {
      "epoch": 2.0153839003532257,
      "grad_norm": 1.055922508239746,
      "learning_rate": 1.5972870750840493e-05,
      "loss": 1.0687,
      "step": 29350
    },
    {
      "epoch": 2.0159648633575014,
      "grad_norm": 1.6508703231811523,
      "learning_rate": 1.5943686963018307e-05,
      "loss": 1.2117,
      "step": 29375
    },
    {
      "epoch": 2.0165458263617775,
      "grad_norm": 1.390345811843872,
      "learning_rate": 1.5914503175196117e-05,
      "loss": 0.963,
      "step": 29400
    },
    {
      "epoch": 2.0165458263617775,
      "eval_loss": 0.89968341588974,
      "eval_runtime": 22.7929,
      "eval_samples_per_second": 175.493,
      "eval_steps_per_second": 43.873,
      "step": 29400
    },
    {
      "epoch": 2.017126789366053,
      "grad_norm": 0.9770889282226562,
      "learning_rate": 1.5885319387373927e-05,
      "loss": 0.5075,
      "step": 29425
    },
    {
      "epoch": 2.017707752370329,
      "grad_norm": 2.76843523979187,
      "learning_rate": 1.5856135599551738e-05,
      "loss": 0.6356,
      "step": 29450
    },
    {
      "epoch": 2.018288715374605,
      "grad_norm": 1.2725027799606323,
      "learning_rate": 1.5826951811729548e-05,
      "loss": 0.6338,
      "step": 29475
    },
    {
      "epoch": 2.0188696783788806,
      "grad_norm": 0.8051244616508484,
      "learning_rate": 1.579776802390736e-05,
      "loss": 0.7458,
      "step": 29500
    },
    {
      "epoch": 2.0194506413831568,
      "grad_norm": 1.151589035987854,
      "learning_rate": 1.5768584236085172e-05,
      "loss": 0.6771,
      "step": 29525
    },
    {
      "epoch": 2.0200316043874325,
      "grad_norm": 1.3803696632385254,
      "learning_rate": 1.5739400448262982e-05,
      "loss": 0.8501,
      "step": 29550
    },
    {
      "epoch": 2.0206125673917086,
      "grad_norm": 2.260122299194336,
      "learning_rate": 1.5710216660440792e-05,
      "loss": 0.7999,
      "step": 29575
    },
    {
      "epoch": 2.0211935303959843,
      "grad_norm": 1.6436514854431152,
      "learning_rate": 1.5681032872618603e-05,
      "loss": 0.903,
      "step": 29600
    },
    {
      "epoch": 2.0211935303959843,
      "eval_loss": 0.9044032096862793,
      "eval_runtime": 22.3757,
      "eval_samples_per_second": 178.765,
      "eval_steps_per_second": 44.691,
      "step": 29600
    },
    {
      "epoch": 2.0217744934002604,
      "grad_norm": 1.0573164224624634,
      "learning_rate": 1.5651849084796413e-05,
      "loss": 1.9036,
      "step": 29625
    },
    {
      "epoch": 2.022355456404536,
      "grad_norm": 1.6537054777145386,
      "learning_rate": 1.5622665296974227e-05,
      "loss": 0.9907,
      "step": 29650
    },
    {
      "epoch": 2.022936419408812,
      "grad_norm": 1.7082188129425049,
      "learning_rate": 1.5593481509152037e-05,
      "loss": 0.9038,
      "step": 29675
    },
    {
      "epoch": 2.023517382413088,
      "grad_norm": 1.4385994672775269,
      "learning_rate": 1.5564297721329847e-05,
      "loss": 0.8483,
      "step": 29700
    },
    {
      "epoch": 2.024098345417364,
      "grad_norm": 1.3958454132080078,
      "learning_rate": 1.5535113933507658e-05,
      "loss": 0.8763,
      "step": 29725
    },
    {
      "epoch": 2.0246793084216397,
      "grad_norm": 1.2166247367858887,
      "learning_rate": 1.5505930145685468e-05,
      "loss": 0.9689,
      "step": 29750
    },
    {
      "epoch": 2.025260271425916,
      "grad_norm": 4.178610324859619,
      "learning_rate": 1.547674635786328e-05,
      "loss": 0.9599,
      "step": 29775
    },
    {
      "epoch": 2.0258412344301915,
      "grad_norm": 3.077249050140381,
      "learning_rate": 1.5447562570041092e-05,
      "loss": 0.8473,
      "step": 29800
    },
    {
      "epoch": 2.0258412344301915,
      "eval_loss": 0.9079258441925049,
      "eval_runtime": 22.6927,
      "eval_samples_per_second": 176.268,
      "eval_steps_per_second": 44.067,
      "step": 29800
    },
    {
      "epoch": 2.026422197434467,
      "grad_norm": 2.158724308013916,
      "learning_rate": 1.5418378782218902e-05,
      "loss": 1.0607,
      "step": 29825
    },
    {
      "epoch": 2.0270031604387433,
      "grad_norm": 1.3708932399749756,
      "learning_rate": 1.5389194994396712e-05,
      "loss": 0.8377,
      "step": 29850
    },
    {
      "epoch": 2.027584123443019,
      "grad_norm": 1.5102345943450928,
      "learning_rate": 1.5360011206574523e-05,
      "loss": 0.4244,
      "step": 29875
    },
    {
      "epoch": 2.028165086447295,
      "grad_norm": 1.8967539072036743,
      "learning_rate": 1.5330827418752336e-05,
      "loss": 0.3505,
      "step": 29900
    },
    {
      "epoch": 2.0287460494515708,
      "grad_norm": 1.8567838668823242,
      "learning_rate": 1.5301643630930147e-05,
      "loss": 0.4198,
      "step": 29925
    },
    {
      "epoch": 2.029327012455847,
      "grad_norm": 2.428010940551758,
      "learning_rate": 1.5272459843107957e-05,
      "loss": 1.2417,
      "step": 29950
    },
    {
      "epoch": 2.0299079754601226,
      "grad_norm": 1.7262842655181885,
      "learning_rate": 1.5243276055285769e-05,
      "loss": 1.1923,
      "step": 29975
    },
    {
      "epoch": 2.0304889384643987,
      "grad_norm": 1.6827398538589478,
      "learning_rate": 1.5214092267463577e-05,
      "loss": 1.2376,
      "step": 30000
    },
    {
      "epoch": 2.0304889384643987,
      "eval_loss": 0.9080758094787598,
      "eval_runtime": 21.9716,
      "eval_samples_per_second": 182.053,
      "eval_steps_per_second": 45.513,
      "step": 30000
    },
    {
      "epoch": 2.0310699014686744,
      "grad_norm": 2.0632669925689697,
      "learning_rate": 1.5184908479641391e-05,
      "loss": 1.3066,
      "step": 30025
    },
    {
      "epoch": 2.0316508644729505,
      "grad_norm": 1.6386388540267944,
      "learning_rate": 1.5155724691819201e-05,
      "loss": 0.8396,
      "step": 30050
    },
    {
      "epoch": 2.032231827477226,
      "grad_norm": 1.1662036180496216,
      "learning_rate": 1.5126540903997013e-05,
      "loss": 0.7218,
      "step": 30075
    },
    {
      "epoch": 2.0328127904815023,
      "grad_norm": 1.9108680486679077,
      "learning_rate": 1.5097357116174824e-05,
      "loss": 0.8046,
      "step": 30100
    },
    {
      "epoch": 2.033393753485778,
      "grad_norm": 2.5771727561950684,
      "learning_rate": 1.5068173328352634e-05,
      "loss": 1.1263,
      "step": 30125
    },
    {
      "epoch": 2.033974716490054,
      "grad_norm": 1.4580610990524292,
      "learning_rate": 1.5038989540530446e-05,
      "loss": 0.983,
      "step": 30150
    },
    {
      "epoch": 2.03455567949433,
      "grad_norm": 1.5622029304504395,
      "learning_rate": 1.5009805752708256e-05,
      "loss": 0.9767,
      "step": 30175
    },
    {
      "epoch": 2.0351366424986055,
      "grad_norm": 1.4393177032470703,
      "learning_rate": 1.4980621964886068e-05,
      "loss": 0.8517,
      "step": 30200
    },
    {
      "epoch": 2.0351366424986055,
      "eval_loss": 0.9045572876930237,
      "eval_runtime": 22.7403,
      "eval_samples_per_second": 175.899,
      "eval_steps_per_second": 43.975,
      "step": 30200
    },
    {
      "epoch": 2.0357176055028816,
      "grad_norm": 1.6570290327072144,
      "learning_rate": 1.4951438177063879e-05,
      "loss": 0.9463,
      "step": 30225
    },
    {
      "epoch": 2.0362985685071573,
      "grad_norm": 1.5301120281219482,
      "learning_rate": 1.4922254389241689e-05,
      "loss": 0.9403,
      "step": 30250
    },
    {
      "epoch": 2.0368795315114334,
      "grad_norm": 1.8871220350265503,
      "learning_rate": 1.4893070601419501e-05,
      "loss": 0.8963,
      "step": 30275
    },
    {
      "epoch": 2.037460494515709,
      "grad_norm": 2.002467155456543,
      "learning_rate": 1.4863886813597311e-05,
      "loss": 0.6777,
      "step": 30300
    },
    {
      "epoch": 2.0380414575199852,
      "grad_norm": 1.2104495763778687,
      "learning_rate": 1.4834703025775123e-05,
      "loss": 0.6831,
      "step": 30325
    },
    {
      "epoch": 2.038622420524261,
      "grad_norm": 1.9135921001434326,
      "learning_rate": 1.4805519237952933e-05,
      "loss": 1.0501,
      "step": 30350
    },
    {
      "epoch": 2.039203383528537,
      "grad_norm": 2.7457337379455566,
      "learning_rate": 1.4776335450130744e-05,
      "loss": 1.447,
      "step": 30375
    },
    {
      "epoch": 2.0397843465328127,
      "grad_norm": 3.1667819023132324,
      "learning_rate": 1.4747151662308556e-05,
      "loss": 0.8027,
      "step": 30400
    },
    {
      "epoch": 2.0397843465328127,
      "eval_loss": 0.9079830050468445,
      "eval_runtime": 22.1078,
      "eval_samples_per_second": 180.931,
      "eval_steps_per_second": 45.233,
      "step": 30400
    },
    {
      "epoch": 2.040365309537089,
      "grad_norm": 0.9590616822242737,
      "learning_rate": 1.4717967874486366e-05,
      "loss": 0.6201,
      "step": 30425
    },
    {
      "epoch": 2.0409462725413645,
      "grad_norm": 2.1342082023620605,
      "learning_rate": 1.4688784086664176e-05,
      "loss": 1.0814,
      "step": 30450
    },
    {
      "epoch": 2.0415272355456406,
      "grad_norm": 2.8934438228607178,
      "learning_rate": 1.4659600298841988e-05,
      "loss": 1.052,
      "step": 30475
    },
    {
      "epoch": 2.0421081985499163,
      "grad_norm": 1.2684742212295532,
      "learning_rate": 1.4630416511019799e-05,
      "loss": 1.052,
      "step": 30500
    },
    {
      "epoch": 2.0426891615541924,
      "grad_norm": 2.328078508377075,
      "learning_rate": 1.460123272319761e-05,
      "loss": 1.4067,
      "step": 30525
    },
    {
      "epoch": 2.043270124558468,
      "grad_norm": 2.3726179599761963,
      "learning_rate": 1.457204893537542e-05,
      "loss": 1.1486,
      "step": 30550
    },
    {
      "epoch": 2.043851087562744,
      "grad_norm": 2.449660539627075,
      "learning_rate": 1.4542865147553231e-05,
      "loss": 1.0434,
      "step": 30575
    },
    {
      "epoch": 2.04443205056702,
      "grad_norm": 1.7450991868972778,
      "learning_rate": 1.4513681359731043e-05,
      "loss": 0.9539,
      "step": 30600
    },
    {
      "epoch": 2.04443205056702,
      "eval_loss": 0.9052243828773499,
      "eval_runtime": 22.0603,
      "eval_samples_per_second": 181.321,
      "eval_steps_per_second": 45.33,
      "step": 30600
    },
    {
      "epoch": 2.0450130135712956,
      "grad_norm": 2.615267753601074,
      "learning_rate": 1.4484497571908853e-05,
      "loss": 1.2995,
      "step": 30625
    },
    {
      "epoch": 2.0455939765755717,
      "grad_norm": 1.9756340980529785,
      "learning_rate": 1.4455313784086665e-05,
      "loss": 1.0528,
      "step": 30650
    },
    {
      "epoch": 2.0461749395798474,
      "grad_norm": 2.0306525230407715,
      "learning_rate": 1.4426129996264476e-05,
      "loss": 1.1464,
      "step": 30675
    },
    {
      "epoch": 2.0467559025841235,
      "grad_norm": 1.6690858602523804,
      "learning_rate": 1.4396946208442286e-05,
      "loss": 1.0845,
      "step": 30700
    },
    {
      "epoch": 2.0473368655883992,
      "grad_norm": 1.8934333324432373,
      "learning_rate": 1.4367762420620098e-05,
      "loss": 1.0138,
      "step": 30725
    },
    {
      "epoch": 2.0479178285926753,
      "grad_norm": 3.234809637069702,
      "learning_rate": 1.4338578632797908e-05,
      "loss": 1.0983,
      "step": 30750
    },
    {
      "epoch": 2.048498791596951,
      "grad_norm": 1.6314650774002075,
      "learning_rate": 1.430939484497572e-05,
      "loss": 1.466,
      "step": 30775
    },
    {
      "epoch": 2.049079754601227,
      "grad_norm": 1.8337160348892212,
      "learning_rate": 1.428021105715353e-05,
      "loss": 1.2607,
      "step": 30800
    },
    {
      "epoch": 2.049079754601227,
      "eval_loss": 0.8992613554000854,
      "eval_runtime": 22.3836,
      "eval_samples_per_second": 178.702,
      "eval_steps_per_second": 44.676,
      "step": 30800
    },
    {
      "epoch": 2.049660717605503,
      "grad_norm": 1.6452397108078003,
      "learning_rate": 1.425102726933134e-05,
      "loss": 1.1558,
      "step": 30825
    },
    {
      "epoch": 2.050241680609779,
      "grad_norm": 1.4779882431030273,
      "learning_rate": 1.4221843481509153e-05,
      "loss": 1.3558,
      "step": 30850
    },
    {
      "epoch": 2.0508226436140546,
      "grad_norm": 1.723393440246582,
      "learning_rate": 1.4192659693686963e-05,
      "loss": 1.2091,
      "step": 30875
    },
    {
      "epoch": 2.0514036066183303,
      "grad_norm": 1.8803175687789917,
      "learning_rate": 1.4163475905864775e-05,
      "loss": 1.2884,
      "step": 30900
    },
    {
      "epoch": 2.0519845696226064,
      "grad_norm": 1.3513708114624023,
      "learning_rate": 1.4134292118042585e-05,
      "loss": 1.2602,
      "step": 30925
    },
    {
      "epoch": 2.052565532626882,
      "grad_norm": 2.2713167667388916,
      "learning_rate": 1.4105108330220396e-05,
      "loss": 1.2708,
      "step": 30950
    },
    {
      "epoch": 2.0531464956311583,
      "grad_norm": 1.587100863456726,
      "learning_rate": 1.4075924542398208e-05,
      "loss": 0.9947,
      "step": 30975
    },
    {
      "epoch": 2.053727458635434,
      "grad_norm": 1.9769538640975952,
      "learning_rate": 1.4046740754576018e-05,
      "loss": 1.5985,
      "step": 31000
    },
    {
      "epoch": 2.053727458635434,
      "eval_loss": 0.897195041179657,
      "eval_runtime": 24.5036,
      "eval_samples_per_second": 163.241,
      "eval_steps_per_second": 40.81,
      "step": 31000
    },
    {
      "epoch": 2.05430842163971,
      "grad_norm": 1.8926445245742798,
      "learning_rate": 1.4017556966753832e-05,
      "loss": 1.7085,
      "step": 31025
    },
    {
      "epoch": 2.0548893846439857,
      "grad_norm": 1.1934528350830078,
      "learning_rate": 1.398837317893164e-05,
      "loss": 1.3687,
      "step": 31050
    },
    {
      "epoch": 2.055470347648262,
      "grad_norm": 1.2686355113983154,
      "learning_rate": 1.395918939110945e-05,
      "loss": 1.1714,
      "step": 31075
    },
    {
      "epoch": 2.0560513106525375,
      "grad_norm": 1.4199472665786743,
      "learning_rate": 1.3930005603287264e-05,
      "loss": 1.1953,
      "step": 31100
    },
    {
      "epoch": 2.0566322736568137,
      "grad_norm": 1.4489192962646484,
      "learning_rate": 1.3900821815465073e-05,
      "loss": 0.9458,
      "step": 31125
    },
    {
      "epoch": 2.0572132366610894,
      "grad_norm": 1.3698757886886597,
      "learning_rate": 1.3871638027642883e-05,
      "loss": 0.871,
      "step": 31150
    },
    {
      "epoch": 2.0577941996653655,
      "grad_norm": 1.1448695659637451,
      "learning_rate": 1.3842454239820695e-05,
      "loss": 1.2516,
      "step": 31175
    },
    {
      "epoch": 2.058375162669641,
      "grad_norm": 1.593259572982788,
      "learning_rate": 1.3813270451998505e-05,
      "loss": 1.3843,
      "step": 31200
    },
    {
      "epoch": 2.058375162669641,
      "eval_loss": 0.8957374095916748,
      "eval_runtime": 25.5515,
      "eval_samples_per_second": 156.546,
      "eval_steps_per_second": 39.137,
      "step": 31200
    },
    {
      "epoch": 2.0589561256739173,
      "grad_norm": 3.9216935634613037,
      "learning_rate": 1.3784086664176319e-05,
      "loss": 1.4602,
      "step": 31225
    },
    {
      "epoch": 2.059537088678193,
      "grad_norm": 1.418075680732727,
      "learning_rate": 1.3754902876354128e-05,
      "loss": 1.3518,
      "step": 31250
    },
    {
      "epoch": 2.0601180516824686,
      "grad_norm": 1.3146308660507202,
      "learning_rate": 1.3725719088531938e-05,
      "loss": 1.2287,
      "step": 31275
    },
    {
      "epoch": 2.0606990146867448,
      "grad_norm": 1.5016852617263794,
      "learning_rate": 1.3696535300709752e-05,
      "loss": 1.0124,
      "step": 31300
    },
    {
      "epoch": 2.0612799776910204,
      "grad_norm": 1.327275037765503,
      "learning_rate": 1.366735151288756e-05,
      "loss": 1.0499,
      "step": 31325
    },
    {
      "epoch": 2.0618609406952966,
      "grad_norm": 1.2521671056747437,
      "learning_rate": 1.3638167725065374e-05,
      "loss": 1.2217,
      "step": 31350
    },
    {
      "epoch": 2.0624419036995723,
      "grad_norm": 1.3948917388916016,
      "learning_rate": 1.3608983937243182e-05,
      "loss": 1.1277,
      "step": 31375
    },
    {
      "epoch": 2.0630228667038484,
      "grad_norm": 1.1154518127441406,
      "learning_rate": 1.3579800149420993e-05,
      "loss": 1.1601,
      "step": 31400
    },
    {
      "epoch": 2.0630228667038484,
      "eval_loss": 0.8953938484191895,
      "eval_runtime": 26.0152,
      "eval_samples_per_second": 153.756,
      "eval_steps_per_second": 38.439,
      "step": 31400
    },
    {
      "epoch": 2.063603829708124,
      "grad_norm": 1.646175503730774,
      "learning_rate": 1.3550616361598806e-05,
      "loss": 1.0184,
      "step": 31425
    },
    {
      "epoch": 2.0641847927124,
      "grad_norm": 1.7637109756469727,
      "learning_rate": 1.3521432573776615e-05,
      "loss": 0.806,
      "step": 31450
    },
    {
      "epoch": 2.064765755716676,
      "grad_norm": 1.7978211641311646,
      "learning_rate": 1.3492248785954429e-05,
      "loss": 1.4454,
      "step": 31475
    },
    {
      "epoch": 2.065346718720952,
      "grad_norm": 1.7094662189483643,
      "learning_rate": 1.3463064998132239e-05,
      "loss": 1.3557,
      "step": 31500
    },
    {
      "epoch": 2.0659276817252277,
      "grad_norm": 1.4020535945892334,
      "learning_rate": 1.3433881210310048e-05,
      "loss": 1.0833,
      "step": 31525
    },
    {
      "epoch": 2.066508644729504,
      "grad_norm": 1.513648509979248,
      "learning_rate": 1.3404697422487861e-05,
      "loss": 1.2565,
      "step": 31550
    },
    {
      "epoch": 2.0670896077337795,
      "grad_norm": 1.6821672916412354,
      "learning_rate": 1.337551363466567e-05,
      "loss": 1.2428,
      "step": 31575
    },
    {
      "epoch": 2.0676705707380556,
      "grad_norm": 1.6571974754333496,
      "learning_rate": 1.3346329846843484e-05,
      "loss": 1.2452,
      "step": 31600
    },
    {
      "epoch": 2.0676705707380556,
      "eval_loss": 0.8964085578918457,
      "eval_runtime": 25.2082,
      "eval_samples_per_second": 158.679,
      "eval_steps_per_second": 39.67,
      "step": 31600
    },
    {
      "epoch": 2.0682515337423313,
      "grad_norm": 1.053406000137329,
      "learning_rate": 1.3317146059021294e-05,
      "loss": 1.4969,
      "step": 31625
    },
    {
      "epoch": 2.068832496746607,
      "grad_norm": 2.008941650390625,
      "learning_rate": 1.3287962271199102e-05,
      "loss": 1.4551,
      "step": 31650
    },
    {
      "epoch": 2.069413459750883,
      "grad_norm": 1.7724146842956543,
      "learning_rate": 1.3258778483376916e-05,
      "loss": 1.2774,
      "step": 31675
    },
    {
      "epoch": 2.0699944227551588,
      "grad_norm": 1.5620150566101074,
      "learning_rate": 1.3229594695554726e-05,
      "loss": 1.3806,
      "step": 31700
    },
    {
      "epoch": 2.070575385759435,
      "grad_norm": 2.8707447052001953,
      "learning_rate": 1.3200410907732538e-05,
      "loss": 1.0947,
      "step": 31725
    },
    {
      "epoch": 2.0711563487637106,
      "grad_norm": 2.2712340354919434,
      "learning_rate": 1.3171227119910349e-05,
      "loss": 1.2354,
      "step": 31750
    },
    {
      "epoch": 2.0717373117679867,
      "grad_norm": 2.266981363296509,
      "learning_rate": 1.3142043332088157e-05,
      "loss": 1.2353,
      "step": 31775
    },
    {
      "epoch": 2.0723182747722624,
      "grad_norm": 1.2918305397033691,
      "learning_rate": 1.3112859544265971e-05,
      "loss": 1.0056,
      "step": 31800
    },
    {
      "epoch": 2.0723182747722624,
      "eval_loss": 0.8975569605827332,
      "eval_runtime": 21.396,
      "eval_samples_per_second": 186.95,
      "eval_steps_per_second": 46.738,
      "step": 31800
    },
    {
      "epoch": 2.0728992377765385,
      "grad_norm": 2.3788840770721436,
      "learning_rate": 1.3083675756443781e-05,
      "loss": 1.0787,
      "step": 31825
    },
    {
      "epoch": 2.073480200780814,
      "grad_norm": 2.462169885635376,
      "learning_rate": 1.3054491968621593e-05,
      "loss": 1.5108,
      "step": 31850
    },
    {
      "epoch": 2.0740611637850903,
      "grad_norm": 1.997799038887024,
      "learning_rate": 1.3025308180799404e-05,
      "loss": 1.3235,
      "step": 31875
    },
    {
      "epoch": 2.074642126789366,
      "grad_norm": 1.8403401374816895,
      "learning_rate": 1.2996124392977214e-05,
      "loss": 0.6511,
      "step": 31900
    },
    {
      "epoch": 2.075223089793642,
      "grad_norm": 1.1727951765060425,
      "learning_rate": 1.2966940605155026e-05,
      "loss": 0.2961,
      "step": 31925
    },
    {
      "epoch": 2.075804052797918,
      "grad_norm": 1.413551926612854,
      "learning_rate": 1.2937756817332836e-05,
      "loss": 0.6377,
      "step": 31950
    },
    {
      "epoch": 2.076385015802194,
      "grad_norm": 1.3381346464157104,
      "learning_rate": 1.2908573029510645e-05,
      "loss": 1.2589,
      "step": 31975
    },
    {
      "epoch": 2.0769659788064696,
      "grad_norm": 1.3809363842010498,
      "learning_rate": 1.2879389241688458e-05,
      "loss": 0.6204,
      "step": 32000
    },
    {
      "epoch": 2.0769659788064696,
      "eval_loss": 0.9014385342597961,
      "eval_runtime": 21.0669,
      "eval_samples_per_second": 189.872,
      "eval_steps_per_second": 47.468,
      "step": 32000
    },
    {
      "epoch": 2.0775469418107453,
      "grad_norm": 2.1998918056488037,
      "learning_rate": 1.2850205453866269e-05,
      "loss": 0.781,
      "step": 32025
    },
    {
      "epoch": 2.0781279048150214,
      "grad_norm": 1.869010329246521,
      "learning_rate": 1.282102166604408e-05,
      "loss": 1.4215,
      "step": 32050
    },
    {
      "epoch": 2.078708867819297,
      "grad_norm": 1.9452459812164307,
      "learning_rate": 1.2791837878221891e-05,
      "loss": 1.0205,
      "step": 32075
    },
    {
      "epoch": 2.079289830823573,
      "grad_norm": 2.812731981277466,
      "learning_rate": 1.2762654090399701e-05,
      "loss": 1.3888,
      "step": 32100
    },
    {
      "epoch": 2.079870793827849,
      "grad_norm": 1.0560768842697144,
      "learning_rate": 1.2733470302577513e-05,
      "loss": 1.6637,
      "step": 32125
    },
    {
      "epoch": 2.080451756832125,
      "grad_norm": 2.137572765350342,
      "learning_rate": 1.2704286514755323e-05,
      "loss": 1.0085,
      "step": 32150
    },
    {
      "epoch": 2.0810327198364007,
      "grad_norm": 1.4469178915023804,
      "learning_rate": 1.2675102726933135e-05,
      "loss": 1.0007,
      "step": 32175
    },
    {
      "epoch": 2.081613682840677,
      "grad_norm": 1.3050591945648193,
      "learning_rate": 1.2645918939110946e-05,
      "loss": 1.0086,
      "step": 32200
    },
    {
      "epoch": 2.081613682840677,
      "eval_loss": 0.8955578804016113,
      "eval_runtime": 22.0913,
      "eval_samples_per_second": 181.067,
      "eval_steps_per_second": 45.267,
      "step": 32200
    },
    {
      "epoch": 2.0821946458449525,
      "grad_norm": 1.3219701051712036,
      "learning_rate": 1.2616735151288756e-05,
      "loss": 0.7679,
      "step": 32225
    },
    {
      "epoch": 2.0827756088492286,
      "grad_norm": 1.3553249835968018,
      "learning_rate": 1.2587551363466568e-05,
      "loss": 0.86,
      "step": 32250
    },
    {
      "epoch": 2.0833565718535043,
      "grad_norm": 4.2567315101623535,
      "learning_rate": 1.2558367575644378e-05,
      "loss": 1.4165,
      "step": 32275
    },
    {
      "epoch": 2.0839375348577804,
      "grad_norm": 2.8854799270629883,
      "learning_rate": 1.252918378782219e-05,
      "loss": 1.3307,
      "step": 32300
    },
    {
      "epoch": 2.084518497862056,
      "grad_norm": 1.569906234741211,
      "learning_rate": 1.25e-05,
      "loss": 1.2182,
      "step": 32325
    },
    {
      "epoch": 2.0850994608663322,
      "grad_norm": 1.804574966430664,
      "learning_rate": 1.2470816212177813e-05,
      "loss": 0.4172,
      "step": 32350
    },
    {
      "epoch": 2.085680423870608,
      "grad_norm": 1.9561009407043457,
      "learning_rate": 1.2441632424355623e-05,
      "loss": 0.4273,
      "step": 32375
    },
    {
      "epoch": 2.0862613868748836,
      "grad_norm": 1.7151044607162476,
      "learning_rate": 1.2412448636533433e-05,
      "loss": 0.809,
      "step": 32400
    },
    {
      "epoch": 2.0862613868748836,
      "eval_loss": 0.8941969275474548,
      "eval_runtime": 20.9326,
      "eval_samples_per_second": 191.089,
      "eval_steps_per_second": 47.772,
      "step": 32400
    },
    {
      "epoch": 2.0868423498791597,
      "grad_norm": 0.9198356866836548,
      "learning_rate": 1.2383264848711245e-05,
      "loss": 0.9311,
      "step": 32425
    },
    {
      "epoch": 2.0874233128834354,
      "grad_norm": 1.271840214729309,
      "learning_rate": 1.2354081060889055e-05,
      "loss": 0.6494,
      "step": 32450
    },
    {
      "epoch": 2.0880042758877115,
      "grad_norm": 1.1932662725448608,
      "learning_rate": 1.2324897273066867e-05,
      "loss": 0.7734,
      "step": 32475
    },
    {
      "epoch": 2.088585238891987,
      "grad_norm": 1.3248391151428223,
      "learning_rate": 1.2295713485244678e-05,
      "loss": 0.7318,
      "step": 32500
    },
    {
      "epoch": 2.0891662018962633,
      "grad_norm": 1.7428343296051025,
      "learning_rate": 1.2266529697422488e-05,
      "loss": 0.8715,
      "step": 32525
    },
    {
      "epoch": 2.089747164900539,
      "grad_norm": 1.9817761182785034,
      "learning_rate": 1.22373459096003e-05,
      "loss": 0.8954,
      "step": 32550
    },
    {
      "epoch": 2.090328127904815,
      "grad_norm": 1.6440472602844238,
      "learning_rate": 1.220816212177811e-05,
      "loss": 0.8287,
      "step": 32575
    },
    {
      "epoch": 2.090909090909091,
      "grad_norm": 2.021854877471924,
      "learning_rate": 1.2178978333955922e-05,
      "loss": 1.0298,
      "step": 32600
    },
    {
      "epoch": 2.090909090909091,
      "eval_loss": 0.8967868685722351,
      "eval_runtime": 20.7017,
      "eval_samples_per_second": 193.221,
      "eval_steps_per_second": 48.305,
      "step": 32600
    },
    {
      "epoch": 2.091490053913367,
      "grad_norm": 1.5396692752838135,
      "learning_rate": 1.2149794546133733e-05,
      "loss": 1.0043,
      "step": 32625
    },
    {
      "epoch": 2.0920710169176426,
      "grad_norm": 1.7386939525604248,
      "learning_rate": 1.2120610758311543e-05,
      "loss": 0.8693,
      "step": 32650
    },
    {
      "epoch": 2.0926519799219188,
      "grad_norm": 1.7530909776687622,
      "learning_rate": 1.2091426970489355e-05,
      "loss": 0.6946,
      "step": 32675
    },
    {
      "epoch": 2.0932329429261944,
      "grad_norm": 2.220801830291748,
      "learning_rate": 1.2062243182667165e-05,
      "loss": 0.7888,
      "step": 32700
    },
    {
      "epoch": 2.09381390593047,
      "grad_norm": 2.791510581970215,
      "learning_rate": 1.2033059394844977e-05,
      "loss": 1.0185,
      "step": 32725
    },
    {
      "epoch": 2.0943948689347462,
      "grad_norm": 1.000379204750061,
      "learning_rate": 1.2003875607022787e-05,
      "loss": 0.7324,
      "step": 32750
    },
    {
      "epoch": 2.094975831939022,
      "grad_norm": 1.551021933555603,
      "learning_rate": 1.1974691819200598e-05,
      "loss": 0.4951,
      "step": 32775
    },
    {
      "epoch": 2.095556794943298,
      "grad_norm": 1.2508333921432495,
      "learning_rate": 1.194550803137841e-05,
      "loss": 0.6754,
      "step": 32800
    },
    {
      "epoch": 2.095556794943298,
      "eval_loss": 0.8989898562431335,
      "eval_runtime": 21.0482,
      "eval_samples_per_second": 190.04,
      "eval_steps_per_second": 47.51,
      "step": 32800
    },
    {
      "epoch": 2.0961377579475737,
      "grad_norm": 1.2902512550354004,
      "learning_rate": 1.191632424355622e-05,
      "loss": 0.9768,
      "step": 32825
    },
    {
      "epoch": 2.09671872095185,
      "grad_norm": 1.4038006067276,
      "learning_rate": 1.1887140455734032e-05,
      "loss": 0.8494,
      "step": 32850
    },
    {
      "epoch": 2.0972996839561255,
      "grad_norm": 1.1809320449829102,
      "learning_rate": 1.1857956667911842e-05,
      "loss": 0.7024,
      "step": 32875
    },
    {
      "epoch": 2.0978806469604017,
      "grad_norm": 1.4349002838134766,
      "learning_rate": 1.1828772880089653e-05,
      "loss": 1.0013,
      "step": 32900
    },
    {
      "epoch": 2.0984616099646773,
      "grad_norm": 1.590590238571167,
      "learning_rate": 1.1799589092267465e-05,
      "loss": 1.061,
      "step": 32925
    },
    {
      "epoch": 2.0990425729689535,
      "grad_norm": 1.7728757858276367,
      "learning_rate": 1.1770405304445275e-05,
      "loss": 1.0865,
      "step": 32950
    },
    {
      "epoch": 2.099623535973229,
      "grad_norm": 1.8918572664260864,
      "learning_rate": 1.1741221516623085e-05,
      "loss": 0.9432,
      "step": 32975
    },
    {
      "epoch": 2.1002044989775053,
      "grad_norm": 1.505232334136963,
      "learning_rate": 1.1712037728800897e-05,
      "loss": 1.0302,
      "step": 33000
    },
    {
      "epoch": 2.1002044989775053,
      "eval_loss": 0.9004780650138855,
      "eval_runtime": 20.9727,
      "eval_samples_per_second": 190.724,
      "eval_steps_per_second": 47.681,
      "step": 33000
    },
    {
      "epoch": 2.100785461981781,
      "grad_norm": 1.6225814819335938,
      "learning_rate": 1.1682853940978707e-05,
      "loss": 0.6455,
      "step": 33025
    },
    {
      "epoch": 2.101366424986057,
      "grad_norm": 1.916305422782898,
      "learning_rate": 1.165367015315652e-05,
      "loss": 0.674,
      "step": 33050
    },
    {
      "epoch": 2.1019473879903328,
      "grad_norm": 3.6274783611297607,
      "learning_rate": 1.1624486365334331e-05,
      "loss": 0.6209,
      "step": 33075
    },
    {
      "epoch": 2.102528350994609,
      "grad_norm": 1.3233481645584106,
      "learning_rate": 1.159530257751214e-05,
      "loss": 0.696,
      "step": 33100
    },
    {
      "epoch": 2.1031093139988846,
      "grad_norm": 1.5870866775512695,
      "learning_rate": 1.1566118789689952e-05,
      "loss": 0.6164,
      "step": 33125
    },
    {
      "epoch": 2.1036902770031602,
      "grad_norm": 1.5521609783172607,
      "learning_rate": 1.1536935001867762e-05,
      "loss": 0.6822,
      "step": 33150
    },
    {
      "epoch": 2.1042712400074364,
      "grad_norm": 1.8780306577682495,
      "learning_rate": 1.1507751214045574e-05,
      "loss": 1.2286,
      "step": 33175
    },
    {
      "epoch": 2.104852203011712,
      "grad_norm": 1.9419054985046387,
      "learning_rate": 1.1478567426223386e-05,
      "loss": 1.1668,
      "step": 33200
    },
    {
      "epoch": 2.104852203011712,
      "eval_loss": 0.8978772163391113,
      "eval_runtime": 21.6337,
      "eval_samples_per_second": 184.897,
      "eval_steps_per_second": 46.224,
      "step": 33200
    },
    {
      "epoch": 2.105433166015988,
      "grad_norm": 2.21337890625,
      "learning_rate": 1.1449383638401195e-05,
      "loss": 1.1401,
      "step": 33225
    },
    {
      "epoch": 2.106014129020264,
      "grad_norm": 1.7926461696624756,
      "learning_rate": 1.1420199850579007e-05,
      "loss": 1.0389,
      "step": 33250
    },
    {
      "epoch": 2.10659509202454,
      "grad_norm": 1.0928983688354492,
      "learning_rate": 1.1391016062756819e-05,
      "loss": 1.0162,
      "step": 33275
    },
    {
      "epoch": 2.1071760550288157,
      "grad_norm": 1.7089725732803345,
      "learning_rate": 1.1361832274934629e-05,
      "loss": 1.0214,
      "step": 33300
    },
    {
      "epoch": 2.107757018033092,
      "grad_norm": 1.5218405723571777,
      "learning_rate": 1.133264848711244e-05,
      "loss": 0.6929,
      "step": 33325
    },
    {
      "epoch": 2.1083379810373675,
      "grad_norm": 1.76500403881073,
      "learning_rate": 1.130346469929025e-05,
      "loss": 0.7103,
      "step": 33350
    },
    {
      "epoch": 2.1089189440416436,
      "grad_norm": 1.7688310146331787,
      "learning_rate": 1.1274280911468062e-05,
      "loss": 1.0243,
      "step": 33375
    },
    {
      "epoch": 2.1094999070459193,
      "grad_norm": 2.3647961616516113,
      "learning_rate": 1.1245097123645874e-05,
      "loss": 1.1847,
      "step": 33400
    },
    {
      "epoch": 2.1094999070459193,
      "eval_loss": 0.8998131155967712,
      "eval_runtime": 21.3703,
      "eval_samples_per_second": 187.176,
      "eval_steps_per_second": 46.794,
      "step": 33400
    },
    {
      "epoch": 2.1100808700501954,
      "grad_norm": 1.5487521886825562,
      "learning_rate": 1.1215913335823684e-05,
      "loss": 0.9252,
      "step": 33425
    },
    {
      "epoch": 2.110661833054471,
      "grad_norm": 2.433468818664551,
      "learning_rate": 1.1186729548001494e-05,
      "loss": 0.8379,
      "step": 33450
    },
    {
      "epoch": 2.1112427960587468,
      "grad_norm": 4.223728656768799,
      "learning_rate": 1.1157545760179306e-05,
      "loss": 0.8998,
      "step": 33475
    },
    {
      "epoch": 2.111823759063023,
      "grad_norm": 2.186049461364746,
      "learning_rate": 1.1128361972357116e-05,
      "loss": 0.8965,
      "step": 33500
    },
    {
      "epoch": 2.1124047220672986,
      "grad_norm": 1.5306439399719238,
      "learning_rate": 1.1099178184534928e-05,
      "loss": 1.4484,
      "step": 33525
    },
    {
      "epoch": 2.1129856850715747,
      "grad_norm": 1.701842188835144,
      "learning_rate": 1.1069994396712739e-05,
      "loss": 1.2038,
      "step": 33550
    },
    {
      "epoch": 2.1135666480758504,
      "grad_norm": 1.0357391834259033,
      "learning_rate": 1.1040810608890549e-05,
      "loss": 0.5114,
      "step": 33575
    },
    {
      "epoch": 2.1141476110801265,
      "grad_norm": 1.853553056716919,
      "learning_rate": 1.1011626821068361e-05,
      "loss": 0.9252,
      "step": 33600
    },
    {
      "epoch": 2.1141476110801265,
      "eval_loss": 0.8941598534584045,
      "eval_runtime": 20.9413,
      "eval_samples_per_second": 191.01,
      "eval_steps_per_second": 47.753,
      "step": 33600
    },
    {
      "epoch": 2.114728574084402,
      "grad_norm": 1.356675624847412,
      "learning_rate": 1.0982443033246171e-05,
      "loss": 0.8989,
      "step": 33625
    },
    {
      "epoch": 2.1153095370886783,
      "grad_norm": 1.157647728919983,
      "learning_rate": 1.0953259245423983e-05,
      "loss": 0.2625,
      "step": 33650
    },
    {
      "epoch": 2.115890500092954,
      "grad_norm": 1.2366688251495361,
      "learning_rate": 1.0924075457601794e-05,
      "loss": 0.3222,
      "step": 33675
    },
    {
      "epoch": 2.11647146309723,
      "grad_norm": 1.561398983001709,
      "learning_rate": 1.0894891669779604e-05,
      "loss": 0.4215,
      "step": 33700
    },
    {
      "epoch": 2.117052426101506,
      "grad_norm": 1.6603175401687622,
      "learning_rate": 1.0865707881957416e-05,
      "loss": 0.9452,
      "step": 33725
    },
    {
      "epoch": 2.117633389105782,
      "grad_norm": 1.2137672901153564,
      "learning_rate": 1.0836524094135226e-05,
      "loss": 1.0707,
      "step": 33750
    },
    {
      "epoch": 2.1182143521100576,
      "grad_norm": 2.081770181655884,
      "learning_rate": 1.0807340306313038e-05,
      "loss": 1.2154,
      "step": 33775
    },
    {
      "epoch": 2.1187953151143337,
      "grad_norm": 1.3577561378479004,
      "learning_rate": 1.0778156518490848e-05,
      "loss": 1.4,
      "step": 33800
    },
    {
      "epoch": 2.1187953151143337,
      "eval_loss": 0.8920469880104065,
      "eval_runtime": 20.8499,
      "eval_samples_per_second": 191.847,
      "eval_steps_per_second": 47.962,
      "step": 33800
    },
    {
      "epoch": 2.1193762781186094,
      "grad_norm": 2.286667823791504,
      "learning_rate": 1.0748972730668659e-05,
      "loss": 1.5422,
      "step": 33825
    },
    {
      "epoch": 2.119957241122885,
      "grad_norm": 1.2608269453048706,
      "learning_rate": 1.071978894284647e-05,
      "loss": 0.761,
      "step": 33850
    },
    {
      "epoch": 2.120538204127161,
      "grad_norm": 1.4874094724655151,
      "learning_rate": 1.0690605155024281e-05,
      "loss": 1.5497,
      "step": 33875
    },
    {
      "epoch": 2.121119167131437,
      "grad_norm": 1.794788122177124,
      "learning_rate": 1.0661421367202093e-05,
      "loss": 1.2366,
      "step": 33900
    },
    {
      "epoch": 2.121700130135713,
      "grad_norm": 1.189085602760315,
      "learning_rate": 1.0632237579379903e-05,
      "loss": 1.1196,
      "step": 33925
    },
    {
      "epoch": 2.1222810931399887,
      "grad_norm": 2.340471029281616,
      "learning_rate": 1.0603053791557714e-05,
      "loss": 1.0049,
      "step": 33950
    },
    {
      "epoch": 2.122862056144265,
      "grad_norm": 1.605919599533081,
      "learning_rate": 1.0573870003735526e-05,
      "loss": 1.2831,
      "step": 33975
    },
    {
      "epoch": 2.1234430191485405,
      "grad_norm": 1.9613467454910278,
      "learning_rate": 1.0544686215913336e-05,
      "loss": 1.0358,
      "step": 34000
    },
    {
      "epoch": 2.1234430191485405,
      "eval_loss": 0.8905466198921204,
      "eval_runtime": 20.8526,
      "eval_samples_per_second": 191.822,
      "eval_steps_per_second": 47.956,
      "step": 34000
    },
    {
      "epoch": 2.1240239821528166,
      "grad_norm": 1.4562207460403442,
      "learning_rate": 1.0515502428091148e-05,
      "loss": 0.9953,
      "step": 34025
    },
    {
      "epoch": 2.1246049451570923,
      "grad_norm": 1.4804984331130981,
      "learning_rate": 1.0486318640268958e-05,
      "loss": 1.0947,
      "step": 34050
    },
    {
      "epoch": 2.1251859081613684,
      "grad_norm": 1.2714449167251587,
      "learning_rate": 1.0457134852446768e-05,
      "loss": 1.1405,
      "step": 34075
    },
    {
      "epoch": 2.125766871165644,
      "grad_norm": 3.11423397064209,
      "learning_rate": 1.042795106462458e-05,
      "loss": 1.2187,
      "step": 34100
    },
    {
      "epoch": 2.1263478341699202,
      "grad_norm": 2.1157405376434326,
      "learning_rate": 1.0398767276802392e-05,
      "loss": 1.0508,
      "step": 34125
    },
    {
      "epoch": 2.126928797174196,
      "grad_norm": 3.6027965545654297,
      "learning_rate": 1.0369583488980201e-05,
      "loss": 0.8223,
      "step": 34150
    },
    {
      "epoch": 2.127509760178472,
      "grad_norm": 2.2934162616729736,
      "learning_rate": 1.0340399701158013e-05,
      "loss": 1.0645,
      "step": 34175
    },
    {
      "epoch": 2.1280907231827477,
      "grad_norm": 1.2131773233413696,
      "learning_rate": 1.0311215913335825e-05,
      "loss": 0.9903,
      "step": 34200
    },
    {
      "epoch": 2.1280907231827477,
      "eval_loss": 0.8949598670005798,
      "eval_runtime": 21.3718,
      "eval_samples_per_second": 187.162,
      "eval_steps_per_second": 46.791,
      "step": 34200
    },
    {
      "epoch": 2.1286716861870234,
      "grad_norm": 2.4257540702819824,
      "learning_rate": 1.0282032125513635e-05,
      "loss": 1.0526,
      "step": 34225
    },
    {
      "epoch": 2.1292526491912995,
      "grad_norm": 2.0612547397613525,
      "learning_rate": 1.0252848337691447e-05,
      "loss": 1.3954,
      "step": 34250
    },
    {
      "epoch": 2.129833612195575,
      "grad_norm": 1.355109453201294,
      "learning_rate": 1.0223664549869256e-05,
      "loss": 1.4258,
      "step": 34275
    },
    {
      "epoch": 2.1304145751998513,
      "grad_norm": 1.4072598218917847,
      "learning_rate": 1.0194480762047068e-05,
      "loss": 0.7272,
      "step": 34300
    },
    {
      "epoch": 2.130995538204127,
      "grad_norm": 1.1086450815200806,
      "learning_rate": 1.016529697422488e-05,
      "loss": 0.9277,
      "step": 34325
    },
    {
      "epoch": 2.131576501208403,
      "grad_norm": 1.5590547323226929,
      "learning_rate": 1.013611318640269e-05,
      "loss": 0.8797,
      "step": 34350
    },
    {
      "epoch": 2.132157464212679,
      "grad_norm": 1.2463334798812866,
      "learning_rate": 1.0106929398580502e-05,
      "loss": 0.9892,
      "step": 34375
    },
    {
      "epoch": 2.132738427216955,
      "grad_norm": 1.4596881866455078,
      "learning_rate": 1.0077745610758312e-05,
      "loss": 0.8793,
      "step": 34400
    },
    {
      "epoch": 2.132738427216955,
      "eval_loss": 0.892454206943512,
      "eval_runtime": 20.7847,
      "eval_samples_per_second": 192.449,
      "eval_steps_per_second": 48.112,
      "step": 34400
    },
    {
      "epoch": 2.1333193902212306,
      "grad_norm": 1.28465735912323,
      "learning_rate": 1.0048561822936123e-05,
      "loss": 0.813,
      "step": 34425
    },
    {
      "epoch": 2.1339003532255068,
      "grad_norm": 1.5796048641204834,
      "learning_rate": 1.0019378035113935e-05,
      "loss": 1.2125,
      "step": 34450
    },
    {
      "epoch": 2.1344813162297824,
      "grad_norm": 1.1526892185211182,
      "learning_rate": 9.990194247291745e-06,
      "loss": 1.3765,
      "step": 34475
    },
    {
      "epoch": 2.1350622792340586,
      "grad_norm": 1.1451025009155273,
      "learning_rate": 9.961010459469557e-06,
      "loss": 1.1587,
      "step": 34500
    },
    {
      "epoch": 2.1356432422383342,
      "grad_norm": 1.69688880443573,
      "learning_rate": 9.931826671647367e-06,
      "loss": 1.1386,
      "step": 34525
    },
    {
      "epoch": 2.13622420524261,
      "grad_norm": 1.0452404022216797,
      "learning_rate": 9.902642883825177e-06,
      "loss": 0.9618,
      "step": 34550
    },
    {
      "epoch": 2.136805168246886,
      "grad_norm": 1.7007319927215576,
      "learning_rate": 9.87345909600299e-06,
      "loss": 0.8275,
      "step": 34575
    },
    {
      "epoch": 2.1373861312511617,
      "grad_norm": 1.3449220657348633,
      "learning_rate": 9.8442753081808e-06,
      "loss": 0.7134,
      "step": 34600
    },
    {
      "epoch": 2.1373861312511617,
      "eval_loss": 0.8935362696647644,
      "eval_runtime": 20.8208,
      "eval_samples_per_second": 192.116,
      "eval_steps_per_second": 48.029,
      "step": 34600
    },
    {
      "epoch": 2.137967094255438,
      "grad_norm": 1.7039977312088013,
      "learning_rate": 9.81509152035861e-06,
      "loss": 0.6157,
      "step": 34625
    },
    {
      "epoch": 2.1385480572597135,
      "grad_norm": 1.7213207483291626,
      "learning_rate": 9.785907732536422e-06,
      "loss": 0.6579,
      "step": 34650
    },
    {
      "epoch": 2.1391290202639897,
      "grad_norm": 1.4688955545425415,
      "learning_rate": 9.756723944714232e-06,
      "loss": 0.5532,
      "step": 34675
    },
    {
      "epoch": 2.1397099832682653,
      "grad_norm": 1.1561279296875,
      "learning_rate": 9.727540156892044e-06,
      "loss": 0.6513,
      "step": 34700
    },
    {
      "epoch": 2.1402909462725415,
      "grad_norm": 1.4336283206939697,
      "learning_rate": 9.698356369069855e-06,
      "loss": 0.5701,
      "step": 34725
    },
    {
      "epoch": 2.140871909276817,
      "grad_norm": 1.4085174798965454,
      "learning_rate": 9.669172581247665e-06,
      "loss": 0.742,
      "step": 34750
    },
    {
      "epoch": 2.1414528722810933,
      "grad_norm": 1.4718384742736816,
      "learning_rate": 9.639988793425477e-06,
      "loss": 0.749,
      "step": 34775
    },
    {
      "epoch": 2.142033835285369,
      "grad_norm": 1.5647233724594116,
      "learning_rate": 9.610805005603287e-06,
      "loss": 0.7354,
      "step": 34800
    },
    {
      "epoch": 2.142033835285369,
      "eval_loss": 0.8902148008346558,
      "eval_runtime": 20.7827,
      "eval_samples_per_second": 192.468,
      "eval_steps_per_second": 48.117,
      "step": 34800
    },
    {
      "epoch": 2.142614798289645,
      "grad_norm": 1.791016936302185,
      "learning_rate": 9.581621217781099e-06,
      "loss": 0.633,
      "step": 34825
    },
    {
      "epoch": 2.1431957612939208,
      "grad_norm": 1.0849974155426025,
      "learning_rate": 9.552437429958911e-06,
      "loss": 0.6701,
      "step": 34850
    },
    {
      "epoch": 2.143776724298197,
      "grad_norm": 10.568408012390137,
      "learning_rate": 9.52325364213672e-06,
      "loss": 0.623,
      "step": 34875
    },
    {
      "epoch": 2.1443576873024726,
      "grad_norm": 1.585639476776123,
      "learning_rate": 9.494069854314532e-06,
      "loss": 0.6767,
      "step": 34900
    },
    {
      "epoch": 2.1449386503067487,
      "grad_norm": 1.4638426303863525,
      "learning_rate": 9.464886066492342e-06,
      "loss": 0.7881,
      "step": 34925
    },
    {
      "epoch": 2.1455196133110244,
      "grad_norm": 2.2449629306793213,
      "learning_rate": 9.435702278670154e-06,
      "loss": 0.7644,
      "step": 34950
    },
    {
      "epoch": 2.1461005763153,
      "grad_norm": 1.7379802465438843,
      "learning_rate": 9.406518490847964e-06,
      "loss": 0.6854,
      "step": 34975
    },
    {
      "epoch": 2.146681539319576,
      "grad_norm": 1.746079683303833,
      "learning_rate": 9.377334703025775e-06,
      "loss": 0.6555,
      "step": 35000
    },
    {
      "epoch": 2.146681539319576,
      "eval_loss": 0.8916500210762024,
      "eval_runtime": 20.8482,
      "eval_samples_per_second": 191.863,
      "eval_steps_per_second": 47.966,
      "step": 35000
    },
    {
      "epoch": 2.147262502323852,
      "grad_norm": 1.0204596519470215,
      "learning_rate": 9.348150915203587e-06,
      "loss": 0.7737,
      "step": 35025
    },
    {
      "epoch": 2.147843465328128,
      "grad_norm": 1.5310330390930176,
      "learning_rate": 9.318967127381399e-06,
      "loss": 0.7028,
      "step": 35050
    },
    {
      "epoch": 2.1484244283324037,
      "grad_norm": 1.9011906385421753,
      "learning_rate": 9.289783339559209e-06,
      "loss": 0.6149,
      "step": 35075
    },
    {
      "epoch": 2.14900539133668,
      "grad_norm": 1.2956886291503906,
      "learning_rate": 9.260599551737019e-06,
      "loss": 0.557,
      "step": 35100
    },
    {
      "epoch": 2.1495863543409555,
      "grad_norm": 2.4235012531280518,
      "learning_rate": 9.23141576391483e-06,
      "loss": 0.9755,
      "step": 35125
    },
    {
      "epoch": 2.1501673173452316,
      "grad_norm": 2.0870361328125,
      "learning_rate": 9.202231976092641e-06,
      "loss": 1.204,
      "step": 35150
    },
    {
      "epoch": 2.1507482803495073,
      "grad_norm": 1.53374183177948,
      "learning_rate": 9.173048188270453e-06,
      "loss": 0.9358,
      "step": 35175
    },
    {
      "epoch": 2.1513292433537834,
      "grad_norm": 2.4443600177764893,
      "learning_rate": 9.143864400448264e-06,
      "loss": 0.5549,
      "step": 35200
    },
    {
      "epoch": 2.1513292433537834,
      "eval_loss": 0.892058253288269,
      "eval_runtime": 21.7332,
      "eval_samples_per_second": 184.05,
      "eval_steps_per_second": 46.013,
      "step": 35200
    },
    {
      "epoch": 2.151910206358059,
      "grad_norm": 2.848484516143799,
      "learning_rate": 9.114680612626074e-06,
      "loss": 0.5884,
      "step": 35225
    },
    {
      "epoch": 2.152491169362335,
      "grad_norm": 1.0552842617034912,
      "learning_rate": 9.085496824803886e-06,
      "loss": 0.6303,
      "step": 35250
    },
    {
      "epoch": 2.153072132366611,
      "grad_norm": 1.5648587942123413,
      "learning_rate": 9.056313036981696e-06,
      "loss": 0.675,
      "step": 35275
    },
    {
      "epoch": 2.1536530953708866,
      "grad_norm": 2.57310152053833,
      "learning_rate": 9.027129249159508e-06,
      "loss": 0.5561,
      "step": 35300
    },
    {
      "epoch": 2.1542340583751627,
      "grad_norm": 1.1537578105926514,
      "learning_rate": 8.997945461337317e-06,
      "loss": 0.6393,
      "step": 35325
    },
    {
      "epoch": 2.1548150213794384,
      "grad_norm": 0.9837468862533569,
      "learning_rate": 8.968761673515129e-06,
      "loss": 0.6922,
      "step": 35350
    },
    {
      "epoch": 2.1553959843837145,
      "grad_norm": 1.5716755390167236,
      "learning_rate": 8.93957788569294e-06,
      "loss": 0.6253,
      "step": 35375
    },
    {
      "epoch": 2.15597694738799,
      "grad_norm": 1.3754026889801025,
      "learning_rate": 8.910394097870751e-06,
      "loss": 0.8035,
      "step": 35400
    },
    {
      "epoch": 2.15597694738799,
      "eval_loss": 0.889973521232605,
      "eval_runtime": 21.0333,
      "eval_samples_per_second": 190.175,
      "eval_steps_per_second": 47.544,
      "step": 35400
    },
    {
      "epoch": 2.1565579103922663,
      "grad_norm": 1.5071938037872314,
      "learning_rate": 8.881210310048563e-06,
      "loss": 0.6615,
      "step": 35425
    },
    {
      "epoch": 2.157138873396542,
      "grad_norm": 1.238100528717041,
      "learning_rate": 8.852026522226373e-06,
      "loss": 0.7095,
      "step": 35450
    },
    {
      "epoch": 2.157719836400818,
      "grad_norm": 1.4604363441467285,
      "learning_rate": 8.822842734404184e-06,
      "loss": 0.8153,
      "step": 35475
    },
    {
      "epoch": 2.158300799405094,
      "grad_norm": 1.5134871006011963,
      "learning_rate": 8.793658946581996e-06,
      "loss": 0.6618,
      "step": 35500
    },
    {
      "epoch": 2.15888176240937,
      "grad_norm": 1.3574150800704956,
      "learning_rate": 8.764475158759806e-06,
      "loss": 0.764,
      "step": 35525
    },
    {
      "epoch": 2.1594627254136456,
      "grad_norm": 1.4897452592849731,
      "learning_rate": 8.735291370937618e-06,
      "loss": 0.993,
      "step": 35550
    },
    {
      "epoch": 2.1600436884179217,
      "grad_norm": 2.554633140563965,
      "learning_rate": 8.706107583115428e-06,
      "loss": 1.4336,
      "step": 35575
    },
    {
      "epoch": 2.1606246514221974,
      "grad_norm": 1.2396260499954224,
      "learning_rate": 8.676923795293238e-06,
      "loss": 1.223,
      "step": 35600
    },
    {
      "epoch": 2.1606246514221974,
      "eval_loss": 0.8891034126281738,
      "eval_runtime": 20.8344,
      "eval_samples_per_second": 191.99,
      "eval_steps_per_second": 47.997,
      "step": 35600
    },
    {
      "epoch": 2.1612056144264735,
      "grad_norm": 2.7213356494903564,
      "learning_rate": 8.64774000747105e-06,
      "loss": 1.4446,
      "step": 35625
    },
    {
      "epoch": 2.161786577430749,
      "grad_norm": 8.274676322937012,
      "learning_rate": 8.61855621964886e-06,
      "loss": 1.6648,
      "step": 35650
    },
    {
      "epoch": 2.1623675404350253,
      "grad_norm": 1.3504942655563354,
      "learning_rate": 8.589372431826673e-06,
      "loss": 1.0012,
      "step": 35675
    },
    {
      "epoch": 2.162948503439301,
      "grad_norm": 2.5912935733795166,
      "learning_rate": 8.560188644004483e-06,
      "loss": 1.287,
      "step": 35700
    },
    {
      "epoch": 2.1635294664435767,
      "grad_norm": 3.0726914405822754,
      "learning_rate": 8.531004856182293e-06,
      "loss": 1.906,
      "step": 35725
    },
    {
      "epoch": 2.164110429447853,
      "grad_norm": 1.4143881797790527,
      "learning_rate": 8.501821068360105e-06,
      "loss": 1.8129,
      "step": 35750
    },
    {
      "epoch": 2.1646913924521285,
      "grad_norm": 1.2598669528961182,
      "learning_rate": 8.472637280537917e-06,
      "loss": 1.1888,
      "step": 35775
    },
    {
      "epoch": 2.1652723554564046,
      "grad_norm": 1.9252535104751587,
      "learning_rate": 8.443453492715726e-06,
      "loss": 0.9217,
      "step": 35800
    },
    {
      "epoch": 2.1652723554564046,
      "eval_loss": 0.8888974785804749,
      "eval_runtime": 20.8227,
      "eval_samples_per_second": 192.098,
      "eval_steps_per_second": 48.024,
      "step": 35800
    },
    {
      "epoch": 2.1658533184606803,
      "grad_norm": 1.522829532623291,
      "learning_rate": 8.414269704893538e-06,
      "loss": 0.9343,
      "step": 35825
    },
    {
      "epoch": 2.1664342814649564,
      "grad_norm": 1.0222963094711304,
      "learning_rate": 8.385085917071348e-06,
      "loss": 1.0416,
      "step": 35850
    },
    {
      "epoch": 2.167015244469232,
      "grad_norm": 1.2631011009216309,
      "learning_rate": 8.35590212924916e-06,
      "loss": 1.0415,
      "step": 35875
    },
    {
      "epoch": 2.1675962074735082,
      "grad_norm": 1.1288642883300781,
      "learning_rate": 8.326718341426972e-06,
      "loss": 1.0733,
      "step": 35900
    },
    {
      "epoch": 2.168177170477784,
      "grad_norm": 1.4306381940841675,
      "learning_rate": 8.29753455360478e-06,
      "loss": 1.0068,
      "step": 35925
    },
    {
      "epoch": 2.16875813348206,
      "grad_norm": 1.0957841873168945,
      "learning_rate": 8.268350765782593e-06,
      "loss": 1.0397,
      "step": 35950
    },
    {
      "epoch": 2.1693390964863357,
      "grad_norm": 1.0965906381607056,
      "learning_rate": 8.239166977960405e-06,
      "loss": 1.0564,
      "step": 35975
    },
    {
      "epoch": 2.169920059490612,
      "grad_norm": 1.886791467666626,
      "learning_rate": 8.209983190138215e-06,
      "loss": 1.0523,
      "step": 36000
    },
    {
      "epoch": 2.169920059490612,
      "eval_loss": 0.8873823285102844,
      "eval_runtime": 20.5723,
      "eval_samples_per_second": 194.436,
      "eval_steps_per_second": 48.609,
      "step": 36000
    },
    {
      "epoch": 2.1705010224948875,
      "grad_norm": 2.3374273777008057,
      "learning_rate": 8.180799402316027e-06,
      "loss": 1.0143,
      "step": 36025
    },
    {
      "epoch": 2.171081985499163,
      "grad_norm": 1.8132718801498413,
      "learning_rate": 8.151615614493836e-06,
      "loss": 1.3095,
      "step": 36050
    },
    {
      "epoch": 2.1716629485034393,
      "grad_norm": 1.7284128665924072,
      "learning_rate": 8.122431826671648e-06,
      "loss": 1.1144,
      "step": 36075
    },
    {
      "epoch": 2.172243911507715,
      "grad_norm": 1.5283159017562866,
      "learning_rate": 8.09324803884946e-06,
      "loss": 1.2209,
      "step": 36100
    },
    {
      "epoch": 2.172824874511991,
      "grad_norm": 1.805188775062561,
      "learning_rate": 8.06406425102727e-06,
      "loss": 1.3792,
      "step": 36125
    },
    {
      "epoch": 2.173405837516267,
      "grad_norm": 2.328674077987671,
      "learning_rate": 8.03488046320508e-06,
      "loss": 1.1966,
      "step": 36150
    },
    {
      "epoch": 2.173986800520543,
      "grad_norm": 4.422158241271973,
      "learning_rate": 8.005696675382892e-06,
      "loss": 0.9269,
      "step": 36175
    },
    {
      "epoch": 2.1745677635248186,
      "grad_norm": 1.5891109704971313,
      "learning_rate": 7.976512887560702e-06,
      "loss": 1.1663,
      "step": 36200
    },
    {
      "epoch": 2.1745677635248186,
      "eval_loss": 0.8894892334938049,
      "eval_runtime": 21.2737,
      "eval_samples_per_second": 188.026,
      "eval_steps_per_second": 47.006,
      "step": 36200
    },
    {
      "epoch": 2.1751487265290947,
      "grad_norm": 1.7062019109725952,
      "learning_rate": 7.947329099738514e-06,
      "loss": 0.8468,
      "step": 36225
    },
    {
      "epoch": 2.1757296895333704,
      "grad_norm": 1.9776984453201294,
      "learning_rate": 7.918145311916325e-06,
      "loss": 0.9257,
      "step": 36250
    },
    {
      "epoch": 2.1763106525376466,
      "grad_norm": 1.6238502264022827,
      "learning_rate": 7.888961524094135e-06,
      "loss": 0.9584,
      "step": 36275
    },
    {
      "epoch": 2.1768916155419222,
      "grad_norm": 3.577528953552246,
      "learning_rate": 7.859777736271947e-06,
      "loss": 0.904,
      "step": 36300
    },
    {
      "epoch": 2.1774725785461984,
      "grad_norm": 1.8979178667068481,
      "learning_rate": 7.830593948449757e-06,
      "loss": 0.9718,
      "step": 36325
    },
    {
      "epoch": 2.178053541550474,
      "grad_norm": 1.7565116882324219,
      "learning_rate": 7.80141016062757e-06,
      "loss": 1.084,
      "step": 36350
    },
    {
      "epoch": 2.1786345045547497,
      "grad_norm": 1.4663368463516235,
      "learning_rate": 7.77222637280538e-06,
      "loss": 0.8442,
      "step": 36375
    },
    {
      "epoch": 2.179215467559026,
      "grad_norm": 1.3591492176055908,
      "learning_rate": 7.74304258498319e-06,
      "loss": 1.049,
      "step": 36400
    },
    {
      "epoch": 2.179215467559026,
      "eval_loss": 0.8937778472900391,
      "eval_runtime": 20.5099,
      "eval_samples_per_second": 195.028,
      "eval_steps_per_second": 48.757,
      "step": 36400
    },
    {
      "epoch": 2.1797964305633015,
      "grad_norm": 8.676139831542969,
      "learning_rate": 7.713858797161002e-06,
      "loss": 1.3744,
      "step": 36425
    },
    {
      "epoch": 2.1803773935675776,
      "grad_norm": 1.7816541194915771,
      "learning_rate": 7.684675009338812e-06,
      "loss": 1.3534,
      "step": 36450
    },
    {
      "epoch": 2.1809583565718533,
      "grad_norm": 1.486030101776123,
      "learning_rate": 7.655491221516624e-06,
      "loss": 1.3021,
      "step": 36475
    },
    {
      "epoch": 2.1815393195761295,
      "grad_norm": 1.7499643564224243,
      "learning_rate": 7.626307433694435e-06,
      "loss": 0.9328,
      "step": 36500
    },
    {
      "epoch": 2.182120282580405,
      "grad_norm": 1.5308787822723389,
      "learning_rate": 7.597123645872245e-06,
      "loss": 0.7417,
      "step": 36525
    },
    {
      "epoch": 2.1827012455846813,
      "grad_norm": 3.2688751220703125,
      "learning_rate": 7.567939858050057e-06,
      "loss": 1.1807,
      "step": 36550
    },
    {
      "epoch": 2.183282208588957,
      "grad_norm": 1.7159429788589478,
      "learning_rate": 7.538756070227868e-06,
      "loss": 1.1538,
      "step": 36575
    },
    {
      "epoch": 2.183863171593233,
      "grad_norm": 1.0509164333343506,
      "learning_rate": 7.509572282405679e-06,
      "loss": 1.0154,
      "step": 36600
    },
    {
      "epoch": 2.183863171593233,
      "eval_loss": 0.8880484700202942,
      "eval_runtime": 20.6925,
      "eval_samples_per_second": 193.307,
      "eval_steps_per_second": 48.327,
      "step": 36600
    },
    {
      "epoch": 2.1844441345975087,
      "grad_norm": 2.1390373706817627,
      "learning_rate": 7.480388494583488e-06,
      "loss": 1.0661,
      "step": 36625
    },
    {
      "epoch": 2.185025097601785,
      "grad_norm": 1.5217779874801636,
      "learning_rate": 7.4512047067613e-06,
      "loss": 0.7864,
      "step": 36650
    },
    {
      "epoch": 2.1856060606060606,
      "grad_norm": 1.9350156784057617,
      "learning_rate": 7.4220209189391115e-06,
      "loss": 0.9684,
      "step": 36675
    },
    {
      "epoch": 2.1861870236103367,
      "grad_norm": 1.6046913862228394,
      "learning_rate": 7.392837131116923e-06,
      "loss": 1.0909,
      "step": 36700
    },
    {
      "epoch": 2.1867679866146124,
      "grad_norm": 1.6490823030471802,
      "learning_rate": 7.363653343294734e-06,
      "loss": 1.1008,
      "step": 36725
    },
    {
      "epoch": 2.1873489496188885,
      "grad_norm": 1.2893770933151245,
      "learning_rate": 7.334469555472544e-06,
      "loss": 0.741,
      "step": 36750
    },
    {
      "epoch": 2.187929912623164,
      "grad_norm": 1.2456881999969482,
      "learning_rate": 7.305285767650355e-06,
      "loss": 1.0313,
      "step": 36775
    },
    {
      "epoch": 2.18851087562744,
      "grad_norm": 1.2267799377441406,
      "learning_rate": 7.276101979828166e-06,
      "loss": 0.8753,
      "step": 36800
    },
    {
      "epoch": 2.18851087562744,
      "eval_loss": 0.8919826745986938,
      "eval_runtime": 20.6455,
      "eval_samples_per_second": 193.746,
      "eval_steps_per_second": 48.437,
      "step": 36800
    },
    {
      "epoch": 2.189091838631716,
      "grad_norm": 2.438248634338379,
      "learning_rate": 7.2469181920059775e-06,
      "loss": 1.1199,
      "step": 36825
    },
    {
      "epoch": 2.1896728016359917,
      "grad_norm": 2.9757561683654785,
      "learning_rate": 7.217734404183789e-06,
      "loss": 1.0162,
      "step": 36850
    },
    {
      "epoch": 2.1902537646402678,
      "grad_norm": 2.371075391769409,
      "learning_rate": 7.188550616361599e-06,
      "loss": 1.2723,
      "step": 36875
    },
    {
      "epoch": 2.1908347276445435,
      "grad_norm": 1.3491519689559937,
      "learning_rate": 7.15936682853941e-06,
      "loss": 1.0878,
      "step": 36900
    },
    {
      "epoch": 2.1914156906488196,
      "grad_norm": 1.098177433013916,
      "learning_rate": 7.130183040717221e-06,
      "loss": 1.4276,
      "step": 36925
    },
    {
      "epoch": 2.1919966536530953,
      "grad_norm": 1.849799633026123,
      "learning_rate": 7.100999252895032e-06,
      "loss": 1.2218,
      "step": 36950
    },
    {
      "epoch": 2.1925776166573714,
      "grad_norm": 1.9004071950912476,
      "learning_rate": 7.071815465072843e-06,
      "loss": 1.4272,
      "step": 36975
    },
    {
      "epoch": 2.193158579661647,
      "grad_norm": 2.166924238204956,
      "learning_rate": 7.042631677250654e-06,
      "loss": 1.7032,
      "step": 37000
    },
    {
      "epoch": 2.193158579661647,
      "eval_loss": 0.887997567653656,
      "eval_runtime": 20.7923,
      "eval_samples_per_second": 192.378,
      "eval_steps_per_second": 48.095,
      "step": 37000
    },
    {
      "epoch": 2.193739542665923,
      "grad_norm": 1.017516016960144,
      "learning_rate": 7.013447889428465e-06,
      "loss": 0.1782,
      "step": 37025
    },
    {
      "epoch": 2.194320505670199,
      "grad_norm": 1.586316704750061,
      "learning_rate": 6.984264101606276e-06,
      "loss": 0.9068,
      "step": 37050
    },
    {
      "epoch": 2.194901468674475,
      "grad_norm": 1.5427508354187012,
      "learning_rate": 6.955080313784087e-06,
      "loss": 0.9763,
      "step": 37075
    },
    {
      "epoch": 2.1954824316787507,
      "grad_norm": 1.1314138174057007,
      "learning_rate": 6.9258965259618974e-06,
      "loss": 1.0418,
      "step": 37100
    },
    {
      "epoch": 2.1960633946830264,
      "grad_norm": 1.5303453207015991,
      "learning_rate": 6.8967127381397086e-06,
      "loss": 1.1076,
      "step": 37125
    },
    {
      "epoch": 2.1966443576873025,
      "grad_norm": 2.134378671646118,
      "learning_rate": 6.86752895031752e-06,
      "loss": 1.0156,
      "step": 37150
    },
    {
      "epoch": 2.197225320691578,
      "grad_norm": 1.966001272201538,
      "learning_rate": 6.838345162495331e-06,
      "loss": 0.8938,
      "step": 37175
    },
    {
      "epoch": 2.1978062836958543,
      "grad_norm": 1.622472882270813,
      "learning_rate": 6.809161374673143e-06,
      "loss": 0.9656,
      "step": 37200
    },
    {
      "epoch": 2.1978062836958543,
      "eval_loss": 0.8891756534576416,
      "eval_runtime": 21.3814,
      "eval_samples_per_second": 187.078,
      "eval_steps_per_second": 46.77,
      "step": 37200
    },
    {
      "epoch": 2.19838724670013,
      "grad_norm": 1.739546537399292,
      "learning_rate": 6.779977586850952e-06,
      "loss": 1.0023,
      "step": 37225
    },
    {
      "epoch": 2.198968209704406,
      "grad_norm": 1.4477182626724243,
      "learning_rate": 6.750793799028763e-06,
      "loss": 1.0767,
      "step": 37250
    },
    {
      "epoch": 2.1995491727086818,
      "grad_norm": 1.3410758972167969,
      "learning_rate": 6.7216100112065745e-06,
      "loss": 1.0522,
      "step": 37275
    },
    {
      "epoch": 2.200130135712958,
      "grad_norm": 1.3702137470245361,
      "learning_rate": 6.6924262233843865e-06,
      "loss": 0.9808,
      "step": 37300
    },
    {
      "epoch": 2.2007110987172336,
      "grad_norm": 1.3304104804992676,
      "learning_rate": 6.663242435562196e-06,
      "loss": 1.0412,
      "step": 37325
    },
    {
      "epoch": 2.2012920617215097,
      "grad_norm": 2.519878387451172,
      "learning_rate": 6.634058647740007e-06,
      "loss": 1.1325,
      "step": 37350
    },
    {
      "epoch": 2.2018730247257854,
      "grad_norm": 2.0754683017730713,
      "learning_rate": 6.604874859917819e-06,
      "loss": 1.4188,
      "step": 37375
    },
    {
      "epoch": 2.2024539877300615,
      "grad_norm": 2.1306848526000977,
      "learning_rate": 6.57569107209563e-06,
      "loss": 0.7927,
      "step": 37400
    },
    {
      "epoch": 2.2024539877300615,
      "eval_loss": 0.8911487460136414,
      "eval_runtime": 21.8345,
      "eval_samples_per_second": 183.196,
      "eval_steps_per_second": 45.799,
      "step": 37400
    },
    {
      "epoch": 2.203034950734337,
      "grad_norm": 2.9800405502319336,
      "learning_rate": 6.546507284273441e-06,
      "loss": 0.6075,
      "step": 37425
    },
    {
      "epoch": 2.2036159137386133,
      "grad_norm": 1.7073596715927124,
      "learning_rate": 6.517323496451251e-06,
      "loss": 0.5592,
      "step": 37450
    },
    {
      "epoch": 2.204196876742889,
      "grad_norm": 1.6870665550231934,
      "learning_rate": 6.488139708629063e-06,
      "loss": 0.716,
      "step": 37475
    },
    {
      "epoch": 2.204777839747165,
      "grad_norm": 1.3952380418777466,
      "learning_rate": 6.458955920806874e-06,
      "loss": 0.5251,
      "step": 37500
    },
    {
      "epoch": 2.205358802751441,
      "grad_norm": 1.8500447273254395,
      "learning_rate": 6.429772132984685e-06,
      "loss": 0.5545,
      "step": 37525
    },
    {
      "epoch": 2.2059397657557165,
      "grad_norm": 1.0941768884658813,
      "learning_rate": 6.400588345162496e-06,
      "loss": 0.5047,
      "step": 37550
    },
    {
      "epoch": 2.2065207287599926,
      "grad_norm": 1.12136709690094,
      "learning_rate": 6.3714045573403065e-06,
      "loss": 0.6919,
      "step": 37575
    },
    {
      "epoch": 2.2071016917642683,
      "grad_norm": 0.8769212365150452,
      "learning_rate": 6.342220769518118e-06,
      "loss": 0.6346,
      "step": 37600
    },
    {
      "epoch": 2.2071016917642683,
      "eval_loss": 0.8891102075576782,
      "eval_runtime": 22.2712,
      "eval_samples_per_second": 179.604,
      "eval_steps_per_second": 44.901,
      "step": 37600
    },
    {
      "epoch": 2.2076826547685444,
      "grad_norm": 1.6084067821502686,
      "learning_rate": 6.313036981695929e-06,
      "loss": 0.5905,
      "step": 37625
    },
    {
      "epoch": 2.20826361777282,
      "grad_norm": 1.4796559810638428,
      "learning_rate": 6.28385319387374e-06,
      "loss": 0.8429,
      "step": 37650
    },
    {
      "epoch": 2.2088445807770962,
      "grad_norm": 1.71266508102417,
      "learning_rate": 6.254669406051551e-06,
      "loss": 0.783,
      "step": 37675
    },
    {
      "epoch": 2.209425543781372,
      "grad_norm": 1.6655305624008179,
      "learning_rate": 6.225485618229362e-06,
      "loss": 0.9426,
      "step": 37700
    },
    {
      "epoch": 2.210006506785648,
      "grad_norm": 2.431570529937744,
      "learning_rate": 6.1963018304071725e-06,
      "loss": 1.2539,
      "step": 37725
    },
    {
      "epoch": 2.2105874697899237,
      "grad_norm": 1.7112852334976196,
      "learning_rate": 6.167118042584984e-06,
      "loss": 1.4137,
      "step": 37750
    },
    {
      "epoch": 2.2111684327942,
      "grad_norm": 2.0650415420532227,
      "learning_rate": 6.137934254762794e-06,
      "loss": 1.7409,
      "step": 37775
    },
    {
      "epoch": 2.2117493957984755,
      "grad_norm": 1.473974585533142,
      "learning_rate": 6.108750466940606e-06,
      "loss": 0.5258,
      "step": 37800
    },
    {
      "epoch": 2.2117493957984755,
      "eval_loss": 0.8896191120147705,
      "eval_runtime": 21.4122,
      "eval_samples_per_second": 186.81,
      "eval_steps_per_second": 46.702,
      "step": 37800
    },
    {
      "epoch": 2.2123303588027516,
      "grad_norm": 1.1932742595672607,
      "learning_rate": 6.079566679118416e-06,
      "loss": 1.3302,
      "step": 37825
    },
    {
      "epoch": 2.2129113218070273,
      "grad_norm": 1.8092752695083618,
      "learning_rate": 6.050382891296227e-06,
      "loss": 0.9404,
      "step": 37850
    },
    {
      "epoch": 2.213492284811303,
      "grad_norm": 1.38889741897583,
      "learning_rate": 6.0211991034740385e-06,
      "loss": 0.6876,
      "step": 37875
    },
    {
      "epoch": 2.214073247815579,
      "grad_norm": 1.2637032270431519,
      "learning_rate": 5.99201531565185e-06,
      "loss": 0.7626,
      "step": 37900
    },
    {
      "epoch": 2.214654210819855,
      "grad_norm": 2.1114916801452637,
      "learning_rate": 5.962831527829661e-06,
      "loss": 1.0696,
      "step": 37925
    },
    {
      "epoch": 2.215235173824131,
      "grad_norm": 2.1368980407714844,
      "learning_rate": 5.933647740007471e-06,
      "loss": 1.1595,
      "step": 37950
    },
    {
      "epoch": 2.2158161368284066,
      "grad_norm": 1.8418550491333008,
      "learning_rate": 5.904463952185282e-06,
      "loss": 0.9514,
      "step": 37975
    },
    {
      "epoch": 2.2163970998326827,
      "grad_norm": 2.783998727798462,
      "learning_rate": 5.875280164363093e-06,
      "loss": 1.2282,
      "step": 38000
    },
    {
      "epoch": 2.2163970998326827,
      "eval_loss": 0.8909718990325928,
      "eval_runtime": 21.5678,
      "eval_samples_per_second": 185.462,
      "eval_steps_per_second": 46.366,
      "step": 38000
    },
    {
      "epoch": 2.2169780628369584,
      "grad_norm": 2.0301589965820312,
      "learning_rate": 5.8460963765409044e-06,
      "loss": 0.7428,
      "step": 38025
    },
    {
      "epoch": 2.2175590258412345,
      "grad_norm": 2.068053960800171,
      "learning_rate": 5.816912588718716e-06,
      "loss": 1.046,
      "step": 38050
    },
    {
      "epoch": 2.2181399888455102,
      "grad_norm": 2.2425830364227295,
      "learning_rate": 5.787728800896526e-06,
      "loss": 0.682,
      "step": 38075
    },
    {
      "epoch": 2.2187209518497863,
      "grad_norm": 0.9958399534225464,
      "learning_rate": 5.758545013074337e-06,
      "loss": 0.0757,
      "step": 38100
    },
    {
      "epoch": 2.219301914854062,
      "grad_norm": 0.9779673218727112,
      "learning_rate": 5.729361225252148e-06,
      "loss": 0.0405,
      "step": 38125
    },
    {
      "epoch": 2.219882877858338,
      "grad_norm": 1.5692505836486816,
      "learning_rate": 5.700177437429959e-06,
      "loss": 0.5449,
      "step": 38150
    },
    {
      "epoch": 2.220463840862614,
      "grad_norm": 1.534311056137085,
      "learning_rate": 5.6709936496077704e-06,
      "loss": 0.9039,
      "step": 38175
    },
    {
      "epoch": 2.22104480386689,
      "grad_norm": 2.3195481300354004,
      "learning_rate": 5.641809861785581e-06,
      "loss": 0.8784,
      "step": 38200
    },
    {
      "epoch": 2.22104480386689,
      "eval_loss": 0.8953123688697815,
      "eval_runtime": 21.6871,
      "eval_samples_per_second": 184.441,
      "eval_steps_per_second": 46.11,
      "step": 38200
    },
    {
      "epoch": 2.2216257668711656,
      "grad_norm": 2.1112825870513916,
      "learning_rate": 5.612626073963393e-06,
      "loss": 0.9579,
      "step": 38225
    },
    {
      "epoch": 2.2222067298754418,
      "grad_norm": 1.2097878456115723,
      "learning_rate": 5.583442286141203e-06,
      "loss": 0.8583,
      "step": 38250
    },
    {
      "epoch": 2.2227876928797174,
      "grad_norm": 1.9403620958328247,
      "learning_rate": 5.554258498319014e-06,
      "loss": 1.0412,
      "step": 38275
    },
    {
      "epoch": 2.223368655883993,
      "grad_norm": 2.0268781185150146,
      "learning_rate": 5.525074710496824e-06,
      "loss": 1.1298,
      "step": 38300
    },
    {
      "epoch": 2.2239496188882693,
      "grad_norm": 2.0023069381713867,
      "learning_rate": 5.495890922674636e-06,
      "loss": 0.6105,
      "step": 38325
    },
    {
      "epoch": 2.224530581892545,
      "grad_norm": 1.7512023448944092,
      "learning_rate": 5.4667071348524475e-06,
      "loss": 0.8145,
      "step": 38350
    },
    {
      "epoch": 2.225111544896821,
      "grad_norm": 2.096850872039795,
      "learning_rate": 5.437523347030258e-06,
      "loss": 0.6313,
      "step": 38375
    },
    {
      "epoch": 2.2256925079010967,
      "grad_norm": 1.233860731124878,
      "learning_rate": 5.408339559208069e-06,
      "loss": 0.6712,
      "step": 38400
    },
    {
      "epoch": 2.2256925079010967,
      "eval_loss": 0.8941705226898193,
      "eval_runtime": 21.5715,
      "eval_samples_per_second": 185.43,
      "eval_steps_per_second": 46.357,
      "step": 38400
    },
    {
      "epoch": 2.226273470905373,
      "grad_norm": 1.271432638168335,
      "learning_rate": 5.37915577138588e-06,
      "loss": 0.8255,
      "step": 38425
    },
    {
      "epoch": 2.2268544339096485,
      "grad_norm": 2.437962055206299,
      "learning_rate": 5.349971983563691e-06,
      "loss": 0.724,
      "step": 38450
    },
    {
      "epoch": 2.2274353969139247,
      "grad_norm": 1.8966319561004639,
      "learning_rate": 5.3207881957415015e-06,
      "loss": 0.8536,
      "step": 38475
    },
    {
      "epoch": 2.2280163599182004,
      "grad_norm": 1.299272894859314,
      "learning_rate": 5.291604407919313e-06,
      "loss": 0.692,
      "step": 38500
    },
    {
      "epoch": 2.2285973229224765,
      "grad_norm": 1.96540367603302,
      "learning_rate": 5.262420620097124e-06,
      "loss": 0.9464,
      "step": 38525
    },
    {
      "epoch": 2.229178285926752,
      "grad_norm": 2.701092004776001,
      "learning_rate": 5.233236832274935e-06,
      "loss": 0.9844,
      "step": 38550
    },
    {
      "epoch": 2.2297592489310283,
      "grad_norm": 1.1017892360687256,
      "learning_rate": 5.204053044452746e-06,
      "loss": 0.8382,
      "step": 38575
    },
    {
      "epoch": 2.230340211935304,
      "grad_norm": 3.4328410625457764,
      "learning_rate": 5.174869256630556e-06,
      "loss": 0.9875,
      "step": 38600
    },
    {
      "epoch": 2.230340211935304,
      "eval_loss": 0.895481288433075,
      "eval_runtime": 22.1657,
      "eval_samples_per_second": 180.459,
      "eval_steps_per_second": 45.115,
      "step": 38600
    },
    {
      "epoch": 2.2309211749395796,
      "grad_norm": 4.306039810180664,
      "learning_rate": 5.1456854688083675e-06,
      "loss": 1.145,
      "step": 38625
    },
    {
      "epoch": 2.2315021379438558,
      "grad_norm": 1.2878180742263794,
      "learning_rate": 5.116501680986179e-06,
      "loss": 1.3327,
      "step": 38650
    },
    {
      "epoch": 2.2320831009481314,
      "grad_norm": 1.9272406101226807,
      "learning_rate": 5.08731789316399e-06,
      "loss": 1.1997,
      "step": 38675
    },
    {
      "epoch": 2.2326640639524076,
      "grad_norm": 1.434251070022583,
      "learning_rate": 5.058134105341801e-06,
      "loss": 0.7409,
      "step": 38700
    },
    {
      "epoch": 2.2332450269566833,
      "grad_norm": 1.3506015539169312,
      "learning_rate": 5.028950317519611e-06,
      "loss": 0.7834,
      "step": 38725
    },
    {
      "epoch": 2.2338259899609594,
      "grad_norm": 1.6901257038116455,
      "learning_rate": 4.999766529697423e-06,
      "loss": 0.7191,
      "step": 38750
    },
    {
      "epoch": 2.234406952965235,
      "grad_norm": 1.5324381589889526,
      "learning_rate": 4.9705827418752335e-06,
      "loss": 0.6765,
      "step": 38775
    },
    {
      "epoch": 2.234987915969511,
      "grad_norm": 2.46256160736084,
      "learning_rate": 4.941398954053045e-06,
      "loss": 0.7917,
      "step": 38800
    },
    {
      "epoch": 2.234987915969511,
      "eval_loss": 0.8917960524559021,
      "eval_runtime": 21.3984,
      "eval_samples_per_second": 186.93,
      "eval_steps_per_second": 46.732,
      "step": 38800
    },
    {
      "epoch": 2.235568878973787,
      "grad_norm": 4.189239501953125,
      "learning_rate": 4.912215166230855e-06,
      "loss": 1.0983,
      "step": 38825
    },
    {
      "epoch": 2.236149841978063,
      "grad_norm": 1.7212601900100708,
      "learning_rate": 4.883031378408667e-06,
      "loss": 0.8604,
      "step": 38850
    },
    {
      "epoch": 2.2367308049823387,
      "grad_norm": 3.2327418327331543,
      "learning_rate": 4.853847590586478e-06,
      "loss": 1.2422,
      "step": 38875
    },
    {
      "epoch": 2.237311767986615,
      "grad_norm": 2.198385238647461,
      "learning_rate": 4.824663802764288e-06,
      "loss": 0.933,
      "step": 38900
    },
    {
      "epoch": 2.2378927309908905,
      "grad_norm": 2.4808461666107178,
      "learning_rate": 4.7954800149420995e-06,
      "loss": 0.9943,
      "step": 38925
    },
    {
      "epoch": 2.238473693995166,
      "grad_norm": 1.722039818763733,
      "learning_rate": 4.766296227119911e-06,
      "loss": 1.3946,
      "step": 38950
    },
    {
      "epoch": 2.2390546569994423,
      "grad_norm": 2.4030697345733643,
      "learning_rate": 4.737112439297722e-06,
      "loss": 1.2625,
      "step": 38975
    },
    {
      "epoch": 2.239635620003718,
      "grad_norm": 4.772388935089111,
      "learning_rate": 4.707928651475532e-06,
      "loss": 1.3203,
      "step": 39000
    },
    {
      "epoch": 2.239635620003718,
      "eval_loss": 0.89254230260849,
      "eval_runtime": 21.0907,
      "eval_samples_per_second": 189.657,
      "eval_steps_per_second": 47.414,
      "step": 39000
    },
    {
      "epoch": 2.240216583007994,
      "grad_norm": 1.249350905418396,
      "learning_rate": 4.678744863653343e-06,
      "loss": 1.0283,
      "step": 39025
    },
    {
      "epoch": 2.2407975460122698,
      "grad_norm": 1.2722101211547852,
      "learning_rate": 4.649561075831154e-06,
      "loss": 0.9807,
      "step": 39050
    },
    {
      "epoch": 2.241378509016546,
      "grad_norm": 2.3141872882843018,
      "learning_rate": 4.6203772880089655e-06,
      "loss": 0.7163,
      "step": 39075
    },
    {
      "epoch": 2.2419594720208216,
      "grad_norm": 1.4361217021942139,
      "learning_rate": 4.591193500186777e-06,
      "loss": 1.0699,
      "step": 39100
    },
    {
      "epoch": 2.2425404350250977,
      "grad_norm": 1.2411540746688843,
      "learning_rate": 4.562009712364587e-06,
      "loss": 0.8445,
      "step": 39125
    },
    {
      "epoch": 2.2431213980293734,
      "grad_norm": 2.40834379196167,
      "learning_rate": 4.532825924542399e-06,
      "loss": 0.8186,
      "step": 39150
    },
    {
      "epoch": 2.2437023610336495,
      "grad_norm": 1.7484465837478638,
      "learning_rate": 4.50364213672021e-06,
      "loss": 0.6799,
      "step": 39175
    },
    {
      "epoch": 2.244283324037925,
      "grad_norm": 1.8951301574707031,
      "learning_rate": 4.47445834889802e-06,
      "loss": 0.5976,
      "step": 39200
    },
    {
      "epoch": 2.244283324037925,
      "eval_loss": 0.8924028873443604,
      "eval_runtime": 21.4536,
      "eval_samples_per_second": 186.449,
      "eval_steps_per_second": 46.612,
      "step": 39200
    },
    {
      "epoch": 2.2448642870422013,
      "grad_norm": 2.872147798538208,
      "learning_rate": 4.4452745610758314e-06,
      "loss": 0.5659,
      "step": 39225
    },
    {
      "epoch": 2.245445250046477,
      "grad_norm": 2.512406349182129,
      "learning_rate": 4.416090773253643e-06,
      "loss": 0.5869,
      "step": 39250
    },
    {
      "epoch": 2.246026213050753,
      "grad_norm": 1.5975888967514038,
      "learning_rate": 4.386906985431454e-06,
      "loss": 0.6453,
      "step": 39275
    },
    {
      "epoch": 2.246607176055029,
      "grad_norm": 2.053603172302246,
      "learning_rate": 4.357723197609264e-06,
      "loss": 0.8026,
      "step": 39300
    },
    {
      "epoch": 2.247188139059305,
      "grad_norm": 2.1060492992401123,
      "learning_rate": 4.328539409787075e-06,
      "loss": 0.7067,
      "step": 39325
    },
    {
      "epoch": 2.2477691020635806,
      "grad_norm": 1.973265528678894,
      "learning_rate": 4.299355621964886e-06,
      "loss": 1.109,
      "step": 39350
    },
    {
      "epoch": 2.2483500650678563,
      "grad_norm": 1.7147608995437622,
      "learning_rate": 4.270171834142697e-06,
      "loss": 1.0495,
      "step": 39375
    },
    {
      "epoch": 2.2489310280721324,
      "grad_norm": 1.6810176372528076,
      "learning_rate": 4.2409880463205086e-06,
      "loss": 1.0509,
      "step": 39400
    },
    {
      "epoch": 2.2489310280721324,
      "eval_loss": 0.8898521661758423,
      "eval_runtime": 21.0352,
      "eval_samples_per_second": 190.157,
      "eval_steps_per_second": 47.539,
      "step": 39400
    },
    {
      "epoch": 2.249511991076408,
      "grad_norm": 1.3428460359573364,
      "learning_rate": 4.211804258498319e-06,
      "loss": 1.1907,
      "step": 39425
    },
    {
      "epoch": 2.250092954080684,
      "grad_norm": 1.2270557880401611,
      "learning_rate": 4.18262047067613e-06,
      "loss": 0.8623,
      "step": 39450
    },
    {
      "epoch": 2.25067391708496,
      "grad_norm": 1.4139147996902466,
      "learning_rate": 4.153436682853941e-06,
      "loss": 0.9983,
      "step": 39475
    },
    {
      "epoch": 2.251254880089236,
      "grad_norm": 1.3352197408676147,
      "learning_rate": 4.124252895031752e-06,
      "loss": 1.0315,
      "step": 39500
    },
    {
      "epoch": 2.2518358430935117,
      "grad_norm": 0.8791221976280212,
      "learning_rate": 4.095069107209563e-06,
      "loss": 0.9776,
      "step": 39525
    },
    {
      "epoch": 2.252416806097788,
      "grad_norm": 2.0290286540985107,
      "learning_rate": 4.065885319387374e-06,
      "loss": 1.2785,
      "step": 39550
    },
    {
      "epoch": 2.2529977691020635,
      "grad_norm": 1.3283989429473877,
      "learning_rate": 4.036701531565186e-06,
      "loss": 1.1661,
      "step": 39575
    },
    {
      "epoch": 2.2535787321063396,
      "grad_norm": 1.7714788913726807,
      "learning_rate": 4.007517743742996e-06,
      "loss": 0.9708,
      "step": 39600
    },
    {
      "epoch": 2.2535787321063396,
      "eval_loss": 0.8902812600135803,
      "eval_runtime": 21.1067,
      "eval_samples_per_second": 189.513,
      "eval_steps_per_second": 47.378,
      "step": 39600
    },
    {
      "epoch": 2.2541596951106153,
      "grad_norm": 1.2036525011062622,
      "learning_rate": 3.978333955920807e-06,
      "loss": 0.9306,
      "step": 39625
    },
    {
      "epoch": 2.2547406581148914,
      "grad_norm": 1.4805572032928467,
      "learning_rate": 3.949150168098617e-06,
      "loss": 0.9556,
      "step": 39650
    },
    {
      "epoch": 2.255321621119167,
      "grad_norm": 1.3436286449432373,
      "learning_rate": 3.919966380276429e-06,
      "loss": 0.8882,
      "step": 39675
    },
    {
      "epoch": 2.255902584123443,
      "grad_norm": 1.0917396545410156,
      "learning_rate": 3.8907825924542405e-06,
      "loss": 0.8429,
      "step": 39700
    },
    {
      "epoch": 2.256483547127719,
      "grad_norm": 2.5022614002227783,
      "learning_rate": 3.861598804632051e-06,
      "loss": 0.8779,
      "step": 39725
    },
    {
      "epoch": 2.2570645101319946,
      "grad_norm": 2.3340039253234863,
      "learning_rate": 3.832415016809862e-06,
      "loss": 0.8689,
      "step": 39750
    },
    {
      "epoch": 2.2576454731362707,
      "grad_norm": 1.3378924131393433,
      "learning_rate": 3.8032312289876727e-06,
      "loss": 0.8459,
      "step": 39775
    },
    {
      "epoch": 2.2582264361405464,
      "grad_norm": 1.6222175359725952,
      "learning_rate": 3.774047441165484e-06,
      "loss": 1.0639,
      "step": 39800
    },
    {
      "epoch": 2.2582264361405464,
      "eval_loss": 0.8890895843505859,
      "eval_runtime": 20.9141,
      "eval_samples_per_second": 191.258,
      "eval_steps_per_second": 47.815,
      "step": 39800
    },
    {
      "epoch": 2.2588073991448225,
      "grad_norm": 1.8617708683013916,
      "learning_rate": 3.7448636533432945e-06,
      "loss": 0.8369,
      "step": 39825
    },
    {
      "epoch": 2.259388362149098,
      "grad_norm": 1.671991229057312,
      "learning_rate": 3.715679865521106e-06,
      "loss": 0.9611,
      "step": 39850
    },
    {
      "epoch": 2.2599693251533743,
      "grad_norm": 2.0180866718292236,
      "learning_rate": 3.6864960776989172e-06,
      "loss": 0.898,
      "step": 39875
    },
    {
      "epoch": 2.26055028815765,
      "grad_norm": 3.7136435508728027,
      "learning_rate": 3.657312289876728e-06,
      "loss": 1.5984,
      "step": 39900
    },
    {
      "epoch": 2.261131251161926,
      "grad_norm": 2.0039374828338623,
      "learning_rate": 3.628128502054539e-06,
      "loss": 1.053,
      "step": 39925
    },
    {
      "epoch": 2.261712214166202,
      "grad_norm": 1.6432238817214966,
      "learning_rate": 3.5989447142323498e-06,
      "loss": 0.9582,
      "step": 39950
    },
    {
      "epoch": 2.262293177170478,
      "grad_norm": 1.036239743232727,
      "learning_rate": 3.569760926410161e-06,
      "loss": 1.0709,
      "step": 39975
    },
    {
      "epoch": 2.2628741401747536,
      "grad_norm": 2.4932689666748047,
      "learning_rate": 3.5405771385879716e-06,
      "loss": 1.0288,
      "step": 40000
    },
    {
      "epoch": 2.2628741401747536,
      "eval_loss": 0.8898361325263977,
      "eval_runtime": 21.0078,
      "eval_samples_per_second": 190.405,
      "eval_steps_per_second": 47.601,
      "step": 40000
    },
    {
      "epoch": 2.2634551031790293,
      "grad_norm": 2.7811458110809326,
      "learning_rate": 3.5113933507657828e-06,
      "loss": 1.9938,
      "step": 40025
    },
    {
      "epoch": 2.2640360661833054,
      "grad_norm": 0.8765571117401123,
      "learning_rate": 3.482209562943594e-06,
      "loss": 0.8583,
      "step": 40050
    },
    {
      "epoch": 2.2646170291875816,
      "grad_norm": 1.371622085571289,
      "learning_rate": 3.4530257751214046e-06,
      "loss": 0.661,
      "step": 40075
    },
    {
      "epoch": 2.2651979921918572,
      "grad_norm": 2.190197229385376,
      "learning_rate": 3.4238419872992158e-06,
      "loss": 0.7218,
      "step": 40100
    },
    {
      "epoch": 2.265778955196133,
      "grad_norm": 1.8683466911315918,
      "learning_rate": 3.3946581994770265e-06,
      "loss": 0.8778,
      "step": 40125
    },
    {
      "epoch": 2.266359918200409,
      "grad_norm": 2.6350700855255127,
      "learning_rate": 3.3654744116548376e-06,
      "loss": 0.8997,
      "step": 40150
    },
    {
      "epoch": 2.2669408812046847,
      "grad_norm": 1.589296579360962,
      "learning_rate": 3.336290623832649e-06,
      "loss": 1.4441,
      "step": 40175
    },
    {
      "epoch": 2.267521844208961,
      "grad_norm": 1.6351784467697144,
      "learning_rate": 3.3071068360104595e-06,
      "loss": 1.0425,
      "step": 40200
    },
    {
      "epoch": 2.267521844208961,
      "eval_loss": 0.8911798000335693,
      "eval_runtime": 21.6229,
      "eval_samples_per_second": 184.989,
      "eval_steps_per_second": 46.247,
      "step": 40200
    },
    {
      "epoch": 2.2681028072132365,
      "grad_norm": 1.3089704513549805,
      "learning_rate": 3.277923048188271e-06,
      "loss": 0.7883,
      "step": 40225
    },
    {
      "epoch": 2.2686837702175127,
      "grad_norm": 1.8563158512115479,
      "learning_rate": 3.2487392603660813e-06,
      "loss": 0.9784,
      "step": 40250
    },
    {
      "epoch": 2.2692647332217883,
      "grad_norm": 1.4839849472045898,
      "learning_rate": 3.219555472543893e-06,
      "loss": 0.7024,
      "step": 40275
    },
    {
      "epoch": 2.2698456962260645,
      "grad_norm": 1.6201804876327515,
      "learning_rate": 3.190371684721703e-06,
      "loss": 0.558,
      "step": 40300
    },
    {
      "epoch": 2.27042665923034,
      "grad_norm": 2.361424207687378,
      "learning_rate": 3.1611878968995147e-06,
      "loss": 0.6805,
      "step": 40325
    },
    {
      "epoch": 2.2710076222346163,
      "grad_norm": 1.9581055641174316,
      "learning_rate": 3.132004109077326e-06,
      "loss": 0.7404,
      "step": 40350
    },
    {
      "epoch": 2.271588585238892,
      "grad_norm": 2.33441424369812,
      "learning_rate": 3.1028203212551366e-06,
      "loss": 0.7763,
      "step": 40375
    },
    {
      "epoch": 2.272169548243168,
      "grad_norm": 1.3852591514587402,
      "learning_rate": 3.0736365334329473e-06,
      "loss": 0.7047,
      "step": 40400
    },
    {
      "epoch": 2.272169548243168,
      "eval_loss": 0.8904455304145813,
      "eval_runtime": 21.0543,
      "eval_samples_per_second": 189.985,
      "eval_steps_per_second": 47.496,
      "step": 40400
    },
    {
      "epoch": 2.2727505112474438,
      "grad_norm": 1.4560341835021973,
      "learning_rate": 3.0444527456107584e-06,
      "loss": 0.6507,
      "step": 40425
    },
    {
      "epoch": 2.2733314742517194,
      "grad_norm": 1.6793349981307983,
      "learning_rate": 3.0152689577885696e-06,
      "loss": 0.5861,
      "step": 40450
    },
    {
      "epoch": 2.2739124372559956,
      "grad_norm": 1.7263044118881226,
      "learning_rate": 2.9860851699663803e-06,
      "loss": 0.7377,
      "step": 40475
    },
    {
      "epoch": 2.2744934002602712,
      "grad_norm": 1.1384719610214233,
      "learning_rate": 2.9569013821441914e-06,
      "loss": 0.7267,
      "step": 40500
    },
    {
      "epoch": 2.2750743632645474,
      "grad_norm": 6.867496013641357,
      "learning_rate": 2.927717594322002e-06,
      "loss": 0.7223,
      "step": 40525
    },
    {
      "epoch": 2.275655326268823,
      "grad_norm": 1.4284287691116333,
      "learning_rate": 2.8985338064998133e-06,
      "loss": 0.7008,
      "step": 40550
    },
    {
      "epoch": 2.276236289273099,
      "grad_norm": 0.9985365867614746,
      "learning_rate": 2.869350018677624e-06,
      "loss": 0.6959,
      "step": 40575
    },
    {
      "epoch": 2.276817252277375,
      "grad_norm": 1.429430603981018,
      "learning_rate": 2.8401662308554356e-06,
      "loss": 0.6557,
      "step": 40600
    },
    {
      "epoch": 2.276817252277375,
      "eval_loss": 0.8903964161872864,
      "eval_runtime": 21.301,
      "eval_samples_per_second": 187.785,
      "eval_steps_per_second": 46.946,
      "step": 40600
    },
    {
      "epoch": 2.277398215281651,
      "grad_norm": 1.8088600635528564,
      "learning_rate": 2.8109824430332463e-06,
      "loss": 1.0561,
      "step": 40625
    },
    {
      "epoch": 2.2779791782859267,
      "grad_norm": 1.5202553272247314,
      "learning_rate": 2.7817986552110574e-06,
      "loss": 1.1011,
      "step": 40650
    },
    {
      "epoch": 2.278560141290203,
      "grad_norm": 2.0523431301116943,
      "learning_rate": 2.752614867388868e-06,
      "loss": 0.9327,
      "step": 40675
    },
    {
      "epoch": 2.2791411042944785,
      "grad_norm": 1.3911643028259277,
      "learning_rate": 2.7234310795666793e-06,
      "loss": 0.9833,
      "step": 40700
    },
    {
      "epoch": 2.2797220672987546,
      "grad_norm": 1.953092336654663,
      "learning_rate": 2.69424729174449e-06,
      "loss": 0.6628,
      "step": 40725
    },
    {
      "epoch": 2.2803030303030303,
      "grad_norm": 1.5767520666122437,
      "learning_rate": 2.665063503922301e-06,
      "loss": 0.5662,
      "step": 40750
    },
    {
      "epoch": 2.280883993307306,
      "grad_norm": 1.503562092781067,
      "learning_rate": 2.6358797161001122e-06,
      "loss": 0.8791,
      "step": 40775
    },
    {
      "epoch": 2.281464956311582,
      "grad_norm": 1.69679594039917,
      "learning_rate": 2.6066959282779234e-06,
      "loss": 0.8345,
      "step": 40800
    },
    {
      "epoch": 2.281464956311582,
      "eval_loss": 0.8900980949401855,
      "eval_runtime": 21.0721,
      "eval_samples_per_second": 189.825,
      "eval_steps_per_second": 47.456,
      "step": 40800
    },
    {
      "epoch": 2.282045919315858,
      "grad_norm": 1.278735637664795,
      "learning_rate": 2.577512140455734e-06,
      "loss": 0.9529,
      "step": 40825
    },
    {
      "epoch": 2.282626882320134,
      "grad_norm": 1.3328211307525635,
      "learning_rate": 2.5483283526335452e-06,
      "loss": 1.2243,
      "step": 40850
    },
    {
      "epoch": 2.2832078453244096,
      "grad_norm": 1.3764477968215942,
      "learning_rate": 2.519144564811356e-06,
      "loss": 1.0202,
      "step": 40875
    },
    {
      "epoch": 2.2837888083286857,
      "grad_norm": 2.4873545169830322,
      "learning_rate": 2.489960776989167e-06,
      "loss": 1.05,
      "step": 40900
    },
    {
      "epoch": 2.2843697713329614,
      "grad_norm": 4.196146011352539,
      "learning_rate": 2.4607769891669782e-06,
      "loss": 1.371,
      "step": 40925
    },
    {
      "epoch": 2.2849507343372375,
      "grad_norm": 2.083570718765259,
      "learning_rate": 2.4315932013447894e-06,
      "loss": 1.4403,
      "step": 40950
    },
    {
      "epoch": 2.285531697341513,
      "grad_norm": 2.030616521835327,
      "learning_rate": 2.4024094135226e-06,
      "loss": 1.0029,
      "step": 40975
    },
    {
      "epoch": 2.2861126603457893,
      "grad_norm": 1.993028998374939,
      "learning_rate": 2.3732256257004112e-06,
      "loss": 0.9282,
      "step": 41000
    },
    {
      "epoch": 2.2861126603457893,
      "eval_loss": 0.8900817036628723,
      "eval_runtime": 21.0087,
      "eval_samples_per_second": 190.398,
      "eval_steps_per_second": 47.599,
      "step": 41000
    },
    {
      "epoch": 2.286693623350065,
      "grad_norm": 1.2013312578201294,
      "learning_rate": 2.344041837878222e-06,
      "loss": 0.8868,
      "step": 41025
    },
    {
      "epoch": 2.287274586354341,
      "grad_norm": 2.2480413913726807,
      "learning_rate": 2.314858050056033e-06,
      "loss": 1.0648,
      "step": 41050
    },
    {
      "epoch": 2.287855549358617,
      "grad_norm": 1.1230947971343994,
      "learning_rate": 2.2856742622338438e-06,
      "loss": 0.9345,
      "step": 41075
    },
    {
      "epoch": 2.288436512362893,
      "grad_norm": 1.7130916118621826,
      "learning_rate": 2.256490474411655e-06,
      "loss": 1.1824,
      "step": 41100
    },
    {
      "epoch": 2.2890174753671686,
      "grad_norm": 1.7393434047698975,
      "learning_rate": 2.227306686589466e-06,
      "loss": 1.1501,
      "step": 41125
    },
    {
      "epoch": 2.2895984383714447,
      "grad_norm": 1.3619019985198975,
      "learning_rate": 2.1981228987672768e-06,
      "loss": 0.9932,
      "step": 41150
    },
    {
      "epoch": 2.2901794013757204,
      "grad_norm": 2.241292953491211,
      "learning_rate": 2.168939110945088e-06,
      "loss": 0.8518,
      "step": 41175
    },
    {
      "epoch": 2.290760364379996,
      "grad_norm": 1.7907178401947021,
      "learning_rate": 2.1397553231228986e-06,
      "loss": 0.9501,
      "step": 41200
    },
    {
      "epoch": 2.290760364379996,
      "eval_loss": 0.8906989693641663,
      "eval_runtime": 21.4271,
      "eval_samples_per_second": 186.68,
      "eval_steps_per_second": 46.67,
      "step": 41200
    },
    {
      "epoch": 2.291341327384272,
      "grad_norm": 2.0275378227233887,
      "learning_rate": 2.1105715353007098e-06,
      "loss": 1.1192,
      "step": 41225
    },
    {
      "epoch": 2.291922290388548,
      "grad_norm": 1.4567447900772095,
      "learning_rate": 2.0813877474785205e-06,
      "loss": 0.6161,
      "step": 41250
    },
    {
      "epoch": 2.292503253392824,
      "grad_norm": 2.6867189407348633,
      "learning_rate": 2.052203959656332e-06,
      "loss": 0.5989,
      "step": 41275
    },
    {
      "epoch": 2.2930842163970997,
      "grad_norm": 2.503628969192505,
      "learning_rate": 2.0230201718341428e-06,
      "loss": 1.073,
      "step": 41300
    },
    {
      "epoch": 2.293665179401376,
      "grad_norm": 2.2325379848480225,
      "learning_rate": 1.993836384011954e-06,
      "loss": 1.2119,
      "step": 41325
    },
    {
      "epoch": 2.2942461424056515,
      "grad_norm": 3.378007411956787,
      "learning_rate": 1.9646525961897646e-06,
      "loss": 1.074,
      "step": 41350
    },
    {
      "epoch": 2.2948271054099276,
      "grad_norm": 2.4579379558563232,
      "learning_rate": 1.9354688083675757e-06,
      "loss": 1.9295,
      "step": 41375
    },
    {
      "epoch": 2.2954080684142033,
      "grad_norm": 1.8550738096237183,
      "learning_rate": 1.9062850205453867e-06,
      "loss": 1.5034,
      "step": 41400
    },
    {
      "epoch": 2.2954080684142033,
      "eval_loss": 0.8901718854904175,
      "eval_runtime": 20.8286,
      "eval_samples_per_second": 192.044,
      "eval_steps_per_second": 48.011,
      "step": 41400
    },
    {
      "epoch": 2.2959890314184794,
      "grad_norm": 1.2146910429000854,
      "learning_rate": 1.8771012327231978e-06,
      "loss": 1.6798,
      "step": 41425
    },
    {
      "epoch": 2.296569994422755,
      "grad_norm": 1.5119802951812744,
      "learning_rate": 1.8479174449010087e-06,
      "loss": 1.2292,
      "step": 41450
    },
    {
      "epoch": 2.2971509574270312,
      "grad_norm": 2.4784348011016846,
      "learning_rate": 1.8187336570788197e-06,
      "loss": 1.1735,
      "step": 41475
    },
    {
      "epoch": 2.297731920431307,
      "grad_norm": 1.3292194604873657,
      "learning_rate": 1.7895498692566306e-06,
      "loss": 0.9635,
      "step": 41500
    },
    {
      "epoch": 2.2983128834355826,
      "grad_norm": 2.2062594890594482,
      "learning_rate": 1.7603660814344415e-06,
      "loss": 1.2873,
      "step": 41525
    },
    {
      "epoch": 2.2988938464398587,
      "grad_norm": 1.9562327861785889,
      "learning_rate": 1.7311822936122524e-06,
      "loss": 0.9672,
      "step": 41550
    },
    {
      "epoch": 2.2994748094441344,
      "grad_norm": 1.4383578300476074,
      "learning_rate": 1.7019985057900634e-06,
      "loss": 0.7802,
      "step": 41575
    },
    {
      "epoch": 2.3000557724484105,
      "grad_norm": 2.1247050762176514,
      "learning_rate": 1.6728147179678747e-06,
      "loss": 0.3706,
      "step": 41600
    },
    {
      "epoch": 2.3000557724484105,
      "eval_loss": 0.8909265398979187,
      "eval_runtime": 21.0896,
      "eval_samples_per_second": 189.667,
      "eval_steps_per_second": 47.417,
      "step": 41600
    },
    {
      "epoch": 2.300636735452686,
      "grad_norm": 2.7088463306427,
      "learning_rate": 1.6436309301456856e-06,
      "loss": 0.348,
      "step": 41625
    },
    {
      "epoch": 2.3012176984569623,
      "grad_norm": 3.110365152359009,
      "learning_rate": 1.6144471423234966e-06,
      "loss": 0.4724,
      "step": 41650
    },
    {
      "epoch": 2.301798661461238,
      "grad_norm": 2.0316662788391113,
      "learning_rate": 1.5852633545013075e-06,
      "loss": 0.8281,
      "step": 41675
    },
    {
      "epoch": 2.302379624465514,
      "grad_norm": 1.995855689048767,
      "learning_rate": 1.5560795666791184e-06,
      "loss": 0.7629,
      "step": 41700
    },
    {
      "epoch": 2.30296058746979,
      "grad_norm": 1.2318235635757446,
      "learning_rate": 1.5268957788569296e-06,
      "loss": 0.6874,
      "step": 41725
    },
    {
      "epoch": 2.303541550474066,
      "grad_norm": 1.3070123195648193,
      "learning_rate": 1.4977119910347405e-06,
      "loss": 0.6863,
      "step": 41750
    },
    {
      "epoch": 2.3041225134783416,
      "grad_norm": 0.8333545327186584,
      "learning_rate": 1.4685282032125514e-06,
      "loss": 0.7444,
      "step": 41775
    },
    {
      "epoch": 2.3047034764826178,
      "grad_norm": 1.5034024715423584,
      "learning_rate": 1.4393444153903625e-06,
      "loss": 0.7304,
      "step": 41800
    },
    {
      "epoch": 2.3047034764826178,
      "eval_loss": 0.8907883763313293,
      "eval_runtime": 21.2881,
      "eval_samples_per_second": 187.899,
      "eval_steps_per_second": 46.975,
      "step": 41800
    },
    {
      "epoch": 2.3052844394868934,
      "grad_norm": 1.5707404613494873,
      "learning_rate": 1.4101606275681735e-06,
      "loss": 0.7673,
      "step": 41825
    },
    {
      "epoch": 2.305865402491169,
      "grad_norm": 1.449276089668274,
      "learning_rate": 1.3809768397459844e-06,
      "loss": 0.828,
      "step": 41850
    },
    {
      "epoch": 2.3064463654954452,
      "grad_norm": 1.090811014175415,
      "learning_rate": 1.3517930519237953e-06,
      "loss": 0.794,
      "step": 41875
    },
    {
      "epoch": 2.3070273284997214,
      "grad_norm": 1.5220974683761597,
      "learning_rate": 1.3226092641016065e-06,
      "loss": 0.8674,
      "step": 41900
    },
    {
      "epoch": 2.307608291503997,
      "grad_norm": 1.6357918977737427,
      "learning_rate": 1.2934254762794174e-06,
      "loss": 0.996,
      "step": 41925
    },
    {
      "epoch": 2.3081892545082727,
      "grad_norm": 2.3639073371887207,
      "learning_rate": 1.2642416884572283e-06,
      "loss": 0.7365,
      "step": 41950
    },
    {
      "epoch": 2.308770217512549,
      "grad_norm": 1.9143916368484497,
      "learning_rate": 1.2350579006350394e-06,
      "loss": 1.0081,
      "step": 41975
    },
    {
      "epoch": 2.3093511805168245,
      "grad_norm": 0.9701414108276367,
      "learning_rate": 1.2058741128128504e-06,
      "loss": 0.9962,
      "step": 42000
    },
    {
      "epoch": 2.3093511805168245,
      "eval_loss": 0.8907513618469238,
      "eval_runtime": 20.6272,
      "eval_samples_per_second": 193.919,
      "eval_steps_per_second": 48.48,
      "step": 42000
    },
    {
      "epoch": 2.3099321435211007,
      "grad_norm": 1.4249688386917114,
      "learning_rate": 1.1766903249906613e-06,
      "loss": 1.0785,
      "step": 42025
    },
    {
      "epoch": 2.3105131065253763,
      "grad_norm": 1.9513907432556152,
      "learning_rate": 1.1475065371684722e-06,
      "loss": 1.1694,
      "step": 42050
    },
    {
      "epoch": 2.3110940695296525,
      "grad_norm": 2.532832622528076,
      "learning_rate": 1.1183227493462832e-06,
      "loss": 1.185,
      "step": 42075
    },
    {
      "epoch": 2.311675032533928,
      "grad_norm": 3.072087526321411,
      "learning_rate": 1.089138961524094e-06,
      "loss": 2.0823,
      "step": 42100
    },
    {
      "epoch": 2.3122559955382043,
      "grad_norm": 1.7028658390045166,
      "learning_rate": 1.059955173701905e-06,
      "loss": 1.2622,
      "step": 42125
    },
    {
      "epoch": 2.31283695854248,
      "grad_norm": 0.9224106073379517,
      "learning_rate": 1.0307713858797161e-06,
      "loss": 0.9056,
      "step": 42150
    },
    {
      "epoch": 2.313417921546756,
      "grad_norm": 1.9910118579864502,
      "learning_rate": 1.001587598057527e-06,
      "loss": 0.9734,
      "step": 42175
    },
    {
      "epoch": 2.3139988845510318,
      "grad_norm": 1.9547514915466309,
      "learning_rate": 9.72403810235338e-07,
      "loss": 0.7916,
      "step": 42200
    },
    {
      "epoch": 2.3139988845510318,
      "eval_loss": 0.8926109671592712,
      "eval_runtime": 21.0585,
      "eval_samples_per_second": 189.947,
      "eval_steps_per_second": 47.487,
      "step": 42200
    },
    {
      "epoch": 2.314579847555308,
      "grad_norm": 2.007965087890625,
      "learning_rate": 9.432200224131491e-07,
      "loss": 1.2189,
      "step": 42225
    },
    {
      "epoch": 2.3151608105595836,
      "grad_norm": 4.6621222496032715,
      "learning_rate": 9.140362345909601e-07,
      "loss": 0.9549,
      "step": 42250
    },
    {
      "epoch": 2.3157417735638592,
      "grad_norm": 2.165571928024292,
      "learning_rate": 8.84852446768771e-07,
      "loss": 1.5335,
      "step": 42275
    },
    {
      "epoch": 2.3163227365681354,
      "grad_norm": 2.243054151535034,
      "learning_rate": 8.556686589465821e-07,
      "loss": 1.126,
      "step": 42300
    },
    {
      "epoch": 2.316903699572411,
      "grad_norm": 2.4227468967437744,
      "learning_rate": 8.26484871124393e-07,
      "loss": 1.0824,
      "step": 42325
    },
    {
      "epoch": 2.317484662576687,
      "grad_norm": 1.7941406965255737,
      "learning_rate": 7.97301083302204e-07,
      "loss": 0.9481,
      "step": 42350
    },
    {
      "epoch": 2.318065625580963,
      "grad_norm": 2.5740206241607666,
      "learning_rate": 7.68117295480015e-07,
      "loss": 1.6686,
      "step": 42375
    },
    {
      "epoch": 2.318646588585239,
      "grad_norm": 2.0360898971557617,
      "learning_rate": 7.389335076578259e-07,
      "loss": 2.062,
      "step": 42400
    },
    {
      "epoch": 2.318646588585239,
      "eval_loss": 0.8920559287071228,
      "eval_runtime": 20.7553,
      "eval_samples_per_second": 192.722,
      "eval_steps_per_second": 48.181,
      "step": 42400
    },
    {
      "epoch": 2.3192275515895147,
      "grad_norm": 1.8522666692733765,
      "learning_rate": 7.09749719835637e-07,
      "loss": 1.1553,
      "step": 42425
    },
    {
      "epoch": 2.319808514593791,
      "grad_norm": 1.7000250816345215,
      "learning_rate": 6.80565932013448e-07,
      "loss": 1.2264,
      "step": 42450
    },
    {
      "epoch": 2.3203894775980665,
      "grad_norm": 2.0365052223205566,
      "learning_rate": 6.513821441912589e-07,
      "loss": 1.1957,
      "step": 42475
    },
    {
      "epoch": 2.3209704406023426,
      "grad_norm": 1.329519271850586,
      "learning_rate": 6.221983563690698e-07,
      "loss": 0.8842,
      "step": 42500
    },
    {
      "epoch": 2.3215514036066183,
      "grad_norm": 1.4212617874145508,
      "learning_rate": 5.930145685468808e-07,
      "loss": 0.5641,
      "step": 42525
    },
    {
      "epoch": 2.3221323666108944,
      "grad_norm": 1.3803714513778687,
      "learning_rate": 5.638307807246918e-07,
      "loss": 0.6556,
      "step": 42550
    },
    {
      "epoch": 2.32271332961517,
      "grad_norm": 1.71510648727417,
      "learning_rate": 5.346469929025028e-07,
      "loss": 0.4288,
      "step": 42575
    },
    {
      "epoch": 2.3232942926194458,
      "grad_norm": 1.297781229019165,
      "learning_rate": 5.054632050803138e-07,
      "loss": 0.2949,
      "step": 42600
    },
    {
      "epoch": 2.3232942926194458,
      "eval_loss": 0.8916493058204651,
      "eval_runtime": 20.7676,
      "eval_samples_per_second": 192.608,
      "eval_steps_per_second": 48.152,
      "step": 42600
    },
    {
      "epoch": 2.323875255623722,
      "grad_norm": 1.719722867012024,
      "learning_rate": 4.762794172581248e-07,
      "loss": 0.5858,
      "step": 42625
    },
    {
      "epoch": 2.324456218627998,
      "grad_norm": 1.684397578239441,
      "learning_rate": 4.470956294359357e-07,
      "loss": 1.3052,
      "step": 42650
    },
    {
      "epoch": 2.3250371816322737,
      "grad_norm": 3.354585886001587,
      "learning_rate": 4.1791184161374676e-07,
      "loss": 0.8504,
      "step": 42675
    },
    {
      "epoch": 2.3256181446365494,
      "grad_norm": 1.375336766242981,
      "learning_rate": 3.8872805379155773e-07,
      "loss": 1.1322,
      "step": 42700
    },
    {
      "epoch": 2.3261991076408255,
      "grad_norm": 1.3090617656707764,
      "learning_rate": 3.595442659693687e-07,
      "loss": 0.8568,
      "step": 42725
    },
    {
      "epoch": 2.326780070645101,
      "grad_norm": 1.8208253383636475,
      "learning_rate": 3.303604781471797e-07,
      "loss": 0.8446,
      "step": 42750
    },
    {
      "epoch": 2.3273610336493773,
      "grad_norm": 2.0402145385742188,
      "learning_rate": 3.0117669032499067e-07,
      "loss": 0.6657,
      "step": 42775
    },
    {
      "epoch": 2.327941996653653,
      "grad_norm": 1.8027596473693848,
      "learning_rate": 2.7199290250280165e-07,
      "loss": 0.0897,
      "step": 42800
    },
    {
      "epoch": 2.327941996653653,
      "eval_loss": 0.8924208283424377,
      "eval_runtime": 20.8987,
      "eval_samples_per_second": 191.4,
      "eval_steps_per_second": 47.85,
      "step": 42800
    },
    {
      "epoch": 2.328522959657929,
      "grad_norm": 2.3747286796569824,
      "learning_rate": 2.4280911468061263e-07,
      "loss": 0.4159,
      "step": 42825
    },
    {
      "epoch": 2.329103922662205,
      "grad_norm": 1.5658494234085083,
      "learning_rate": 2.1362532685842363e-07,
      "loss": 0.8906,
      "step": 42850
    },
    {
      "epoch": 2.329684885666481,
      "grad_norm": 2.1405322551727295,
      "learning_rate": 1.844415390362346e-07,
      "loss": 1.0265,
      "step": 42875
    },
    {
      "epoch": 2.3302658486707566,
      "grad_norm": 1.6410361528396606,
      "learning_rate": 1.552577512140456e-07,
      "loss": 0.9553,
      "step": 42900
    },
    {
      "epoch": 2.3308468116750327,
      "grad_norm": 3.275287628173828,
      "learning_rate": 1.2607396339185655e-07,
      "loss": 0.7858,
      "step": 42925
    },
    {
      "epoch": 2.3314277746793084,
      "grad_norm": 3.2279975414276123,
      "learning_rate": 9.689017556966754e-08,
      "loss": 1.1402,
      "step": 42950
    },
    {
      "epoch": 2.3320087376835845,
      "grad_norm": 1.797991156578064,
      "learning_rate": 6.770638774747853e-08,
      "loss": 0.8688,
      "step": 42975
    },
    {
      "epoch": 2.33258970068786,
      "grad_norm": 3.4287819862365723,
      "learning_rate": 3.852259992528951e-08,
      "loss": 1.2309,
      "step": 43000
    },
    {
      "epoch": 2.33258970068786,
      "eval_loss": 0.8926140666007996,
      "eval_runtime": 20.2272,
      "eval_samples_per_second": 197.753,
      "eval_steps_per_second": 49.438,
      "step": 43000
    }
  ],
  "logging_steps": 25,
  "max_steps": 43032,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.669906175696077e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
